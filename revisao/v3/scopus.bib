
@ARTICLE{Yu20191917,
author={Yu, Y. and Da, F. and Guo, Y.},
title={Sparse ICP with Resampling and Denoising for 3D Face Verification},
journal={IEEE Transactions on Information Forensics and Security},
year={2019},
volume={14},
number={7},
pages={1917-1927},
doi={10.1109/TIFS.2018.2889255},
art_number={8585047},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059045736&doi=10.1109%2fTIFS.2018.2889255&partnerID=40&md5=3d2e20cdc9894c8986e4bdf7a1fdd2d0},
affiliation={School of Automation, Southeast University, Nanjing, 210096, China},
abstract={Three-dimensional face recognition has shown its potential to obtain higher recognition accuracy than 2D methods. Among numerous face recognition methods, registration of two faces is comparatively intuitive. We propose a rigid registration method using surface resampling and denoising, which lowers the impact on registration residuals caused by sampling difference and noise, significantly improving the accuracy. While sparsityinducing norms reduce sensitivity to outliers and missing data, with preprocessing and region segmentation methods, our registration method is applied to face verification. Without datadriven learning or training, only residuals of rigid registration are utilized, and verification rates at 0.1% FAR are as follows: 100% for n versus n, 96.9% for n versus all, and 98.6% for ROC III experiment on FRGC v2.0 database, and 100% for n versus n and 95.7% for n versus all on Bosphorus database. Experiments show that the proposed algorithm outperforms the state-of-theart algorithms and is preferable in a verification scenario. © 2018 IEEE.},
author_keywords={3D face recognition;  3D face verification;  ICP},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xue2019,
author={Xue, J. and Zhang, Q. and Li, C. and Lang, W. and Wang, M. and Hu, Y.},
title={3D face profilometry based on galvanometer scanner with infrared fringe projection in high speed},
journal={Applied Sciences (Switzerland)},
year={2019},
volume={9},
number={7},
doi={10.3390/app9071458},
art_number={1458},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064123307&doi=10.3390%2fapp9071458&partnerID=40&md5=eb750afb2ce9eab954e95d4d1239d456},
affiliation={School of Aeronautics and Astronautics, Sichuan University, Chengdu, 610065, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, 610065, China; Artificial Intelligence Key Laboratory of Sichuan Province, Sichuan University of Science and Engineering, Zigong, 643000, China},
abstract={Structured light 3D shape metrology has become a very important technique and one of the hot research topics in 3D face recognition. However, it is still very challenging to use the digital light projector (DLP) in a 3D scanner and achieve high-speed, low-cost, small-size, and infrared-illuminated measurements. Instead of using a DLP, this paper proposes to use a galvanometer scanner to project phase-shifted fringes with a projection speed of infrared fringes up to 500 fps. Moreover, the measurement accuracy of multi-frequency (hierarchical) and multi-wavelength (heterodyne) temporal phase unwrapping approaches implemented in this system is analyzed. The measurement accuracy of the two methods is better than 0.2 mm. Comparisons are made between this method and the classical DLP approach. This method can achieve a similar accuracy and repeatability compared to the classical DLP method when a face mask is measured. The experiments on real human face indicate that this proposed method can improve the field of 3D scanning applications at a lower cost. © 2019 by the authors.},
author_keywords={3D face recognition;  Galvanometer scanner;  Infrared fringe projection;  Low-cost projector;  Optical 3D measurement},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Yang2019,
author={Yang, F. and Shao, Q. and Cai, Z.},
title={Joint Identification Method Research of Access System Base on RFID and 3D Face Recognition},
journal={IOP Conference Series: Earth and Environmental Science},
year={2019},
volume={234},
number={1},
doi={10.1088/1755-1315/234/1/012099},
art_number={012099},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063400103&doi=10.1088%2f1755-1315%2f234%2f1%2f012099&partnerID=40&md5=578f666082074af503fded62a0165b27},
affiliation={School of Electrical Information Engineering, Foshan University, Foshan, 528000, China},
abstract={In this paper, the main contents of radio frequency identification, 3D(three-dimensional) face recognition, associative recognition algorithm based on radio frequency and 3D face recognition. The associative recognition method combined with radio frequency identification and 3D face recognition proposed in the paper, It can combine the advantages of stable radio frequency identification and high recognition rate and the advantages of 3D face recognition identity security to achieve the purpose of security, high recognition rate and strong operability of the entrance guard system. Therefore, it has broad application prospects in the access control system. © Published under licence by IOP Publishing Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shi2019455,
author={Shi, B. and Zang, H. and Zheng, R. and Zhan, S.},
title={An efficient 3D face recognition approach using Frenet feature of iso-geodesic curves},
journal={Journal of Visual Communication and Image Representation},
year={2019},
volume={59},
pages={455-460},
doi={10.1016/j.jvcir.2019.02.002},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061129042&doi=10.1016%2fj.jvcir.2019.02.002&partnerID=40&md5=8f0fe3cd51ff2049c71bfe756a9bf6d6},
affiliation={School of Computer and Information, Hefei University of Technology, Hefei, 230009, China},
abstract={Extracting efficient features from the large volume of 3D facial data directly is extremely difficult in 3D face recognition (3D-FR) with the latest methods, which mostly require heavy computations and manual processing steps. This paper presents a computationally efficient 3D-FR system based on a novel Frenet frame-based feature that is derived from the 3D facial iso-geodesic curves. In terms of the evaluation of the proposed method, we conducted a number of experiments on the CASIA 3D face database, and a superior recognition performance has been achieved. The performance evaluation suggests that the pose invariance attribute of the features relieves the need of an expensive 3D face registration in the face preprocessing procedure, where we take less time to process conversely. Our experiments further demonstrate that the proposed method not only achieves competitive recognition performance when compared with some existing techniques for 3D-FR, but also is computationally efficient. © 2019 Elsevier Inc.},
author_keywords={3D face recognition;  Facial curves;  Frenet framework;  Iso-geodesic;  Pose invariant},
document_type={Article},
source={Scopus},
}

@ARTICLE{Neto2019594,
author={Neto, J.B.C. and Marana, A.N.},
title={3D face recognition with reconstructed faces from a collection of 2D images},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11401 LNCS},
pages={594-601},
doi={10.1007/978-3-030-13469-3_69},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063066921&doi=10.1007%2f978-3-030-13469-3_69&partnerID=40&md5=ae38ed3a54a47df05e22f1ec3db64720},
affiliation={São Carlos Federal University - UFSCAR, São Carlos, SP  13565-905, Brazil; UNESP - São Paulo State University, Bauru, SP  17033-360, Brazil},
abstract={Nowadays, there is an increasing need for systems that can accurately and quickly identify a person. Traditional identification methods utilize something a person knows or something a person has. This kind of methods has several drawbacks, being the main one the fact that it is impossible to detect an imposter who uses genuine credentials to pass as a genuine person. One way to solve these kinds of problems is to utilize biometric identification. The face is one of the biometric features that best suits the covert identification. However, in general, biometric systems based on 2D face recognition perform very poorly in unconstrained environments, common in covert identification scenarios, since the input images present variations in pose, illumination, and facial expressions. One way to mitigate this problem is to use 3D face data, but the current 3D scanners are expensive and require a lot of cooperation from people being identified. Therefore, in this work, we propose an approach based on local descriptors for 3D Face Recognition based on 3D face models reconstructed from collections of 2D images. Initial results show 95% in a subset of the LFW Face dataset. © Springer Nature Switzerland AG 2019.},
author_keywords={3D face recognition;  3DLBP;  Biometrics;  Face reconstruction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hajati2019936,
author={Hajati, F. and Cheraghian, A. and Ameri Sianaki, O. and Zeinali, B. and Gheisari, S.},
title={Polar Topographic Derivatives for 3D Face Recognition: Application to Internet of Things Security},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={927},
pages={936-945},
doi={10.1007/978-3-030-15035-8_92},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064875340&doi=10.1007%2f978-3-030-15035-8_92&partnerID=40&md5=a1997efd234042ace42c04b05607ab05},
affiliation={College of Engineering and Science, Victoria University Sydney, Sydney, Australia; College of Engineering and Computer Science, The Australian National University, Canberra, Australia; Electrical Engineering Department, Iran University of Science and Technology, Tehran, Iran; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia},
abstract={We propose Polar Topographic Derivatives (PTD) to fuse the shape and texture information of a facial surface for 3D face recognition. Polar Average Absolute Deviations (PAADs) of the Gabor topography maps are extracted as features. High-order polar derivative patterns are obtained by encoding texture variations in a polar neighborhood. By using the and Bosphorus 3D face database, our method shows that it is robust to expression and pose variations comparing to existing state-of-the-art benchmark approaches. © 2019, Springer Nature Switzerland AG.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Peter201977,
author={Peter, M. and Minoi, J.-L. and Hipiny, I.H.M.},
title={3D face recognition using kernel-based PCA approach},
journal={Lecture Notes in Electrical Engineering},
year={2019},
volume={481},
pages={77-86},
doi={10.1007/978-981-13-2622-6_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053242189&doi=10.1007%2f978-981-13-2622-6_8&partnerID=40&md5=c4b90626b4453034107d227cbd63ef3d},
affiliation={Faculty of Computer Science and Information Technology, Universiti Malaysia SarawakSarawak, Malaysia},
abstract={Face recognition is commonly used for biometric security purposes in video surveillance and user authentications. The nature of face exhibits non-linear shapes due to appearance deformations, and face variations presented by facial expressions. Recognizing faces reliably across changes in facial expression has proved to be a more difficult problem leading to low recognition rates in many face recognition experiments. This is mainly due to the tens degree-of-freedom in a non-linear space. Recently, non-linear PCA has been revived as it posed a significant advantage for data representation in high dimensionality space. In this paper, we experimented the use of non-linear kernel approach in 3D face recognition and the results of the recognition rates have shown that the kernel method outperformed the standard PCA. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={3D face;  Facial recognition;  Kernel PCA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dutta2019175,
author={Dutta, K. and Bhattacharjee, D. and Nasipuri, M. and Poddar, A.},
title={3D face recognition based on volumetric representation of range image},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={883},
pages={175-189},
doi={10.1007/978-981-13-3702-4_11},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061157145&doi=10.1007%2f978-981-13-3702-4_11&partnerID=40&md5=2543d63ceec9074d39578ea3320cdfbd},
affiliation={Department of Computer Science and Engineering, Jadavpur University, Kolkata, West Bengal, India; Computer Science Engineering, Birla Institute of Technology, Mesra, Ranchi, India},
abstract={In this paper, a 3D face recognition system has been developed based on the volumetric representation of 3D range image. The main approach to build this system is to calculate volume on some distinct region of 3D range face data. The system has mainly three steps. In the very first step, seven significant facial landmarks are identified on the face. Secondly, six distinct triangular regions A to F are created on the face using any three individual landmarks where nose tip is common to all regions. Further 3D volumes of all the respective triangular regions have been calculated based on plane fitting on the input range images. Finally, KNN and SVM classifiers are considered for classification. Initially, the classification and recognition are carried out on the different volumetric region, and a further combination of all the regions is considered. The proposed approach is tested on three useful challenging databases, namely Frav3D, Bosphorous, and GavabDB. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={3D range image;  Classification;  Facial landmark;  Plane fitting;  Volumetric representation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Feng2019123,
author={Feng, J. and Guo, Q. and Guan, Y. and Wu, M. and Zhang, X. and Ti, C.},
title={3D face recognition method based on deep convolutional neural network},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={670},
pages={123-130},
doi={10.1007/978-981-10-8971-8_12},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050385395&doi=10.1007%2f978-981-10-8971-8_12&partnerID=40&md5=09db62184dc8c481f3e4cfdd015290df},
affiliation={School of Electronics and Information Engineering, Harbin Institute of Technology, Xidazhi Street. 92, Harbin, 150001, China; Beijing Automation Control Equipment Research Institute, Beijing, 100074, China; School of Information Engineering Branch, Yangling Vocational & Technical College, Weihuilu. 24, Yangling, Shanxi  712100, China},
abstract={In 2D face recognition, result may suffer from the impact of varying pose, expression, and illumination conditions. However, 3D face recognition utilizes depth information to enhance systematic robustness. Thus, an improved deep convolutional neural network (DCNN) combined with softmax classifier to identify face is trained. First, the preprocessing of color image and depth map is different in removing redundant information. Then, the feature extraction networks for 2D face image and depth map are, respectively, build with the principle of recognition rate maximization, and parameters about neural networks reset by a series of tests, in order to acquire higher recognition rate. At last, the fusion of two feature layers is the final input of artificial neural network (ANN) recognition system, which is followed by a 64-way softmax output. Experimental results demonstrate that it is effective in improving recognition rate. © Springer Nature Singapore Pte Ltd 2019.},
author_keywords={3D face recognition;  Deep convolutional neural network;  Depth map;  Feature extraction;  Feature fusion},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cirrincione2019253,
author={Cirrincione, G. and Marcolin, F. and Spada, S. and Vezzetti, E.},
title={Intelligent quality assessment of geometrical features for 3D face recognition},
journal={Smart Innovation, Systems and Technologies},
year={2019},
volume={103},
pages={253-264},
doi={10.1007/978-3-319-95095-2_24},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051862957&doi=10.1007%2f978-3-319-95095-2_24&partnerID=40&md5=3eb73efa9d500b19b1f7a6291f6d10d3},
affiliation={DIGEP, Politecnico di Torino, Turin, Italy; Laboratory of LTI, Université de Picardie Jules Verne, Amiens, France; University of South Pacific, Suva, Fiji},
abstract={This paper proposes a methodology to assess the discriminative capabilities of geometrical descriptors referring to the public Bosphorus 3D facial database as testing dataset. The investigated descriptors include histogram versions of Shape Index and Curvedness, Euclidean and geodesic distances between facial soft-tissue landmarks. The discriminability of these features is evaluated through the analysis of single block of features and their meanings with different techniques. Multilayer perceptron neural network methodology is adopted to evaluate the relevance of the features, examined in different test combinations. Principle component analysis (PCA) is applied for dimensionality reduction. © Springer International Publishing AG, part of Springer Nature 2019.},
author_keywords={3D face recognition;  Dimensionality reduction;  Geometrical descriptors;  Neural network;  Principal component analysis},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Cirrincione2019153,
author={Cirrincione, G. and Marcolin, F. and Spada, S. and Vezzetti, E.},
title={Intelligent quality assessment of geometrical features for 3D face recognition},
journal={Smart Innovation, Systems and Technologies},
year={2019},
volume={102},
pages={153-164},
doi={10.1007/978-3-319-95098-3_14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050746846&doi=10.1007%2f978-3-319-95098-3_14&partnerID=40&md5=19f63a5d1f6f7e44a5e0130cf4ebeaf0},
affiliation={DIGEP, Politecnico Di Torino, Turin, Italy; Laboratory LTI, Université de Picardie Jules Verne, Amiens, France; University of South Pacific, Suva, Fiji},
abstract={This paper proposes a methodology to assess the discriminative capabilities of geometrical descriptors referring to the public Bosphorus 3D facial database as testing dataset. The investigated descriptors include histogram versions of Shape Index and Curvedness, Euclidean and geodesic distances between facial soft-tissue landmarks. The discriminability of these features is evaluated through the analysis of single block of features and their meanings with different techniques. Multilayer perceptron neural network methodology is adopted to evaluate the relevance of the features, examined in different test combinations. Principle Component Analysis (PCA) is applied for dimensionality reduction. © 2019, Springer International Publishing AG, part of Springer Nature.},
author_keywords={3D face recognition;  Dimensionality reduction;  Geometrical descriptors;  Neural network;  Principal component analysis},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Pala2019,
author={Pala, P. and Berretti, S.},
title={Reconstructing 3D face models by incremental aggregation and refinement of depth frames},
journal={ACM Transactions on Multimedia Computing, Communications and Applications},
year={2019},
volume={15},
number={1},
doi={10.1145/3287309},
art_number={23},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061189013&doi=10.1145%2f3287309&partnerID=40&md5=b14174ca209c1c0dde3f8e3b04c0bfad},
affiliation={University of Florence, Via Santa Marta 3, Florence, 50139, Italy},
abstract={Face recognition from two-dimensional (2D) still images and videos is quite successful even with "in the wild" conditions. Instead, less consolidated results are available for the cases in which face data come from non-conventional cameras, such as infrared or depth. In this article, we investigate this latter scenario assuming that a low-resolution depth camera is used to perform face recognition in an uncooperative context. To this end, we propose, first, to automatically select a set of frames from the depth sequence of the camera because they provide a good view of the face in terms of pose and distance. Then, we design a progressive refinement approach to reconstruct a higher-resolution model from the selected low-resolution frames. This process accounts for the anisotropic error of the existing points in the current 3D model and the points in a newly acquired frame so that the refinement step can progressively adjust the point positions in the model using a Kalman-like estimation. The quality of the reconstructed model is evaluated by considering the error between the reconstructed models and their corresponding high-resolution scans used as ground truth. In addition, we performed face recognition using the reconstructed models as probes against a gallery of reconstructed models and a gallery with high-resolution scans. The obtained results confirm the possibility to effectively use the reconstructed models for the face recognition task. © 2019 Copyright held by the owner/author(s).},
author_keywords={3D face recognition;  3D reconstruction;  Anisotropic error;  Depth data},
document_type={Article},
source={Scopus},
}

@CONFERENCE{ZulqarnainGilani20181896,
author={Zulqarnain Gilani, S. and Mian, A.},
title={Learning from Millions of 3D Scans for Large-Scale 3D Face Recognition},
journal={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
year={2018},
pages={1896-1905},
doi={10.1109/CVPR.2018.00203},
art_number={8578301},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060207182&doi=10.1109%2fCVPR.2018.00203&partnerID=40&md5=7a2227c884147feae86f1d25240e9a7a},
affiliation={Computer Science and Software Engineering, University of Western Australia, Australia},
abstract={Deep networks trained on millions of facial images are believed to be closely approaching human-level performance in face recognition. However, open world face recognition still remains a challenge. Although, 3D face recognition has an inherent edge over its 2D counterpart, it has not benefited from the recent developments in deep learning due to the unavailability of large training as well as large test datasets. Recognition accuracies have already saturated on existing 3D face datasets due to their small gallery sizes. Unlike 2D photographs, 3D facial scans cannot be sourced from the web causing a bottleneck in the development of deep 3D face recognition networks and datasets. In this backdrop, we propose a method for generating a large corpus of labeled 3D face identities and their multiple instances for training and a protocol for merging the most challenging existing 3D datasets for testing. We also propose the first deep CNN model designed specifically for 3D face recognition and trained on 3.1 Million 3D facial scans of 100K identities. Our test dataset comprises 1,853 identities with a single 3D scan in the gallery and another 31K scans as probes, which is several orders of magnitude larger than existing ones. Without fine tuning on this dataset, our network already outperforms state of the art face recognition by over 10%. We fine tune our network on the gallery set to perform end-to-end large scale 3D face recognition which further improves accuracy. Finally, we show the efficacy of our method for the open world face recognition problem. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhou2018,
author={Zhou, S. and Xiao, S.},
title={3D face recognition: a survey},
journal={Human-centric Computing and Information Sciences},
year={2018},
volume={8},
number={1},
doi={10.1186/s13673-018-0157-2},
art_number={35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057339588&doi=10.1186%2fs13673-018-0157-2&partnerID=40&md5=b87148e43a6001284a758168a66ede05},
affiliation={College of Computer Science and Electronic Engineering, Hunan University, South Lushan Road, Yuelu District, Changsha, 410082, China; National Collaborative Innovation Center for High Performance Computing, Beijing, China},
abstract={3D face recognition has become a trending research direction in both industry and academia. It inherits advantages from traditional 2D face recognition, such as the natural recognition process and a wide range of applications. Moreover, 3D face recognition systems could accurately recognize human faces even under dim lights and with variant facial positions and expressions, in such conditions 2D face recognition systems would have immense difficulty to operate. This paper summarizes the history and the most recent progresses in 3D face recognition research domain. The frontier research results are introduced in three categories: pose-invariant recognition, expression-invariant recognition, and occlusion-invariant recognition. To promote future research, this paper collects information about publicly available 3D face databases. This paper also lists important open problems. © 2018, The Author(s).},
author_keywords={3D face database;  3D face recognition;  Expression-invariant face recognition;  Occlusion-invariant face recognition;  Pose-invariant face recognition},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Reji2018,
author={Reji, R. and Sojanlal, P.},
title={Region Based 3D Face Recognition},
journal={2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
year={2018},
doi={10.1109/ICCIC.2017.8524581},
art_number={8524581},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057946157&doi=10.1109%2fICCIC.2017.8524581&partnerID=40&md5=92c092fa4e2838ab444fcc0356fcdb75},
affiliation={Mahatma Gandhi University, School of Computer Sciences, Kottayam, Kerala, India; Mar-Baselious Institute of Technology Science, Kothamangalam, Kerala, India},
abstract={This paper focuses on a region based methodology for expression in sensitive 3D face recognition process. Considering facial regions that are comparatively unchanging during expressions, results shows that using fifteen sub regions on the face can attain high 3D face recognition. We use a modified face recognition algorithm along with hierarchical contour based image registration for finding the similarity score. Our method operates in two modes: verification mode and confirmation mode. Crop 100 mm of frontal face region, apply preprocessing and automatically detect nose tip, translate the face image to origin and crop fifteen sub regions. The cropped sub regions are defined by cuboids which occupy more volumetric data, Nose Tip is the most projecting point of the face with the highest value along Z-axis so consider it as origin. The modified face recognition algorithm reduces the effects caused by facial expressions and artifacts. Finally a Hierarchical contour based image registration technique is applied which yields better results. The approach is applied on Bosphorus 3D datasets and achieved a verification rate of 95.3% at 0.1% false acceptance rate. In the identification scenario 99.3% rank one recognition is achieved. © 2017 IEEE.},
author_keywords={3D face recognition;  Biometrics;  Contour based image registration;  MFRA;  Rank based Score},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen2018,
author={Chen, X. and Lu, Y. and Fang, R.},
title={3D face recognition based on empirical mode decomposition and sparse representation},
journal={ACM International Conference Proceeding Series},
year={2018},
doi={10.1145/3207677.3278100},
art_number={a78},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056823589&doi=10.1145%2f3207677.3278100&partnerID=40&md5=f9c74fb6ca6e983205b3b33030481b84},
affiliation={Jilin University, Changchun, China},
abstract={With 1 the research interest increasing in 3D face recognition, many methods for 3D face recognition have emerged in recent years. In this paper, a novel method named as decomposition-based face classification (DFC) is proposed to recognize a 3D face by using empirical mode decomposition (EMD) and sparse representation. A 3D face scan is firstly decomposed into several surfaces by a 3D EMD algorithm, then for each decomposed surface, meshSIFT is used for detecting salient points and extracting the local descriptor, and the dictionary is constructed by concatenating all the local descriptors. Finally, the identification of a probe face can be determined by the multitask sparse representation classification. Experimental results demonstrate that our decomposition-based method can achieve state-of-the-art performance on two benchmark databases, Bosphorus and FRGC2.0. © 2018 Association for Computing Machinery. ACM.},
author_keywords={EMD;  Face Recognition;  MeshSIFT;  SRC},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Siqueira20183513,
author={Siqueira, R.S. and Alexandre, G.R. and Soares, J.M. and The, G.A.P.},
title={Triaxial slicing for 3-D face recognition from adapted rotational invariants spatial moments and minimal keypoints dependence},
journal={IEEE Robotics and Automation Letters},
year={2018},
volume={3},
number={4},
pages={3513-3520},
doi={10.1109/LRA.2018.2854295},
art_number={8408720},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063307357&doi=10.1109%2fLRA.2018.2854295&partnerID=40&md5=5205595c202573ef77808eaf4aee1626},
affiliation={Faculty of Electrical Engineering, Instituto Federal de Educação, Ciência e Tecnologia Do Ceará, Fortaleza, CE 60410-42, Brazil; Department of Teleinformatics Engineering, Universidade Federal Do Ceará, Fortaleza, CE 60020-181, Brazil},
abstract={This letter presents a multiple slicing model for three-dimensional (3-D) images of human face, using the frontal, sagittal, and transverse orthogonal planes. The definition of the segments depends on just one key point, the nose tip, which makes it simple and independent of the detection of several key points. For facial recognition, attributes based on adapted 2-D spatial moments of Hu and 3-D spatial invariant rotation moments are extracted from each segment. Tests with the proposed model using the Bosphorus Database for neutral vs nonneutral ROC I experiment, applying linear discriminant analysis as classifier and more than one sample for training, achieved 98.7% of verification rate at 0.1% of false acceptance rate. By using the support vector machine as classifier the rank1 experiment recognition rates of 99% and 95.4% have been achieved for a neutral vs neutral and for a neutral vs non-neutral, respectively. These results approach the state-of-the-art using Bosphorus Database and even surpasses it when anger and disgust expressions are evaluated. In addition, we also evaluate the generalization of our method using the FRGC v2.0 database and achieve competitive results, making the technique promising, especially for its simplicity. © 2016 IEEE.},
author_keywords={Computer vision for automation;  recognition;  surveillance systems},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fei2018139,
author={Fei, H. and Tu, B. and Chen, Q. and He, D. and Zhou, C. and Peng, Y.},
title={An overview of face-related technologies},
journal={Journal of Visual Communication and Image Representation},
year={2018},
volume={56},
pages={139-143},
doi={10.1016/j.jvcir.2018.09.012},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053774931&doi=10.1016%2fj.jvcir.2018.09.012&partnerID=40&md5=ddfc4618812dd5bf104f59915ffc5af0},
affiliation={College of Information and Communication Engineering, School of Information Science and Technology, Hunan Institute of Science and Technology, Yueyang, China; School of Computer and Information, Hefei University of Technology, Hefei, China},
abstract={In recent years, information technology is developing continuously and set off a burst of artificial intelligence boom in the field of science. The development of advanced technologies such as unmanned driving and AI chips, is the extensive application of artificial intelligence. Face-related technologies have a wide range of applications because of intuitive results and good concealment. Since 3D face information can provide more comprehensive facial information than 2D face information, and it can solve many difficulties that cannot be solved in 2D face recognition. Therefore, more and more researchers have studied 3D face recognition in recent years. Under the new circumstances, the research on face are experiencing all kinds of challenges. With the tireless of many scientists, the new technology is also making a constant progress, and in the development of many technologies it still maintained its leading position. In this paper, we simply sort out the present development process of facial correlation technology, and the general evolution of this technology is outlined. Finally, the practical significance of this technology development is briefly discussed. © 2018},
author_keywords={3D face reconstruction;  Deep learning;  Face enhancement;  Face recognition},
document_type={Article},
source={Scopus},
}

@ARTICLE{Abbad2018525,
author={Abbad, A. and Abbad, K. and Tairi, H.},
title={3D face recognition: Multi-scale strategy based on geometric and local descriptors},
journal={Computers and Electrical Engineering},
year={2018},
volume={70},
pages={525-537},
doi={10.1016/j.compeleceng.2017.08.017},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028606046&doi=10.1016%2fj.compeleceng.2017.08.017&partnerID=40&md5=5414b01946f345f018c49654dff50957},
affiliation={LIIAN, Department of Computer Science, Faculty of Sciences Dhar El Mahraz University Sidi Mohamed Ben Abdelah, Fez, Morocco; LISA, Department of Computer Science, Faculty of Science and Technology University Sidi Mohamed Ben Abdelah, Fez, Morocco},
abstract={Most human expression variations cause a non-rigid deformation of face scans, which is a challenge today. In this article, we present a novel framework for 3D face recognition that uses a geometry and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. This algorithm consists of four major components. First, the 3D face model is presented at different scales. Second, isometric-invariant features on each scale are extracted. Third, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Fourth, the feature vectors on each scale are concatenated with their corresponding geometric information. We conducted a number of experiments using two well-known and challenging datasets, namely, the GavabDB and Bosphorus datasets, and superior recognition performance has been achieved. The new system displays an overall rank-1 identification rate of 98.9% for all faces with neutral and non-neutral expressions on the GavabDB database. © 2017 Elsevier Ltd},
author_keywords={3D face recognition;  Expression;  Facial curves;  Geometric features;  Local features},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kumar201811,
author={Kumar, S. and Tripathi, B.K.},
title={On the root-power mean aggregation based neuron in quaternionic domain},
journal={International Journal of Intelligent Systems and Applications},
year={2018},
volume={10},
number={7},
pages={11-26},
doi={10.5815/ijisa.2018.07.02},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049396089&doi=10.5815%2fijisa.2018.07.02&partnerID=40&md5=b120b1db1c45a14ead152da69668d3b1},
affiliation={Harcourt Butler Technical University, Department of Computer Science and Engineering, Kanpur, 208002, India},
abstract={This paper illustrates the new structure of artificial neuron based on root-power means (RPM) for quaternionic-valued signals and also presented an efficient learning process of neural networks with quaternionic-valued root-power means neurons (H-RPMN). The main aim of this neuron is to present the potential capability of a nonlinear aggregation operation on the quaternionic-valued signals in neuron cell. A wide spectrum of aggregation ability of RPM in between minima and maxima has a beautiful property of changing its degree of compensation in the natural way which emulates the various existing neuron models as its special cases. Further, the quaternionic resilient propagation algorithm (H-RPROP) with error-dependent weight backtracking step significantly accelerates the training speed and exhibits better approximation accuracy. The wide spectrums of benchmark problems are considered to evaluate the performance of proposed quaternionic root-power mean neuron with H-RPROP learning algorithm. © 2018 MECS.},
author_keywords={3D face recognition;  Quasi-arithmetic means;  Quaternionic resilient propagation;  Quaternionic-valued backpropagation;  Quaternionic-valued multilayer perceptron;  Root-power means in quaternionic domain (H)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gao2018120,
author={Gao, J. and Evans, A.N.},
title={Expression robust 3D face landmarking using thresholded surface normals},
journal={Pattern Recognition},
year={2018},
volume={78},
pages={120-132},
doi={10.1016/j.patcog.2018.01.011},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042375361&doi=10.1016%2fj.patcog.2018.01.011&partnerID=40&md5=a93105edc5d4f49296e9c43d397e9898},
affiliation={Department of Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden; Department of Electronic and Electrical Engineering, University of Bath, Bath, United Kingdom},
abstract={3D face recognition is an increasing popular modality for biometric authentication, for example in the iPhoneX. Landmarking plays a significant role in region based face recognition algorithms. The accuracy and consistency of the landmarking will directly determine the effectiveness of feature extraction and hence the overall recognition performance. While surface normals have been shown to provide high performing features for face recognition, their use in landmarking has not been widely explored. To this end, a new 3D facial landmarking algorithm based on thresholded surface normal maps is proposed, which is applicable to widely used 3D face databases. The benefits of employing surface normals are demonstrated for both facial roll and yaw rotation calibration and nasal landmarks localization. Results on the Bosphorus, FRGC and BU-3DFE databases show that the detected landmarks possess high within-class consistency and accuracy under different expressions. For several key landmarks the performance achieved surpasses that of state-of-the-art techniques and is also training free and computationally efficient. The use of surface normals therefore provides a useful representation of the 3D surface and the proposed landmarking algorithm provides an effective approach to localising the key nasal landmarks. © 2018 Elsevier Ltd},
author_keywords={3D face landmarking;  Surface normals},
document_type={Article},
source={Scopus},
}

@ARTICLE{Truong2018119,
author={Truong, K.T. and Le, T.H.},
title={Video-based face recognition using shape and texture information in 3D Morphable Model},
journal={JP Journal of Heat and Mass Transfer},
year={2018},
volume={15},
number={Special Issue 1},
pages={119-124},
doi={10.17654/HMSI118119},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050083363&doi=10.17654%2fHMSI118119&partnerID=40&md5=0d768b750e9373900b4773eec844cfbf},
affiliation={Department of Computer Science, University of Science, VNU-HCM, Ho Chi Minh City, Viet Nam},
abstract={In this paper, a novel approach, based on combining 3D Morphable Model (3DMM) to shape vector and texture variance, is proposed for face recognition in video (called 3DMM-S-TV). In detail, the system fits a face video to a 3DMM, then utilizes shape fitting coefficients and texture info to recognize face. For this purpose: (1) apply 3DMM to reconstruct 3D face; (2) form a shape vector to present each face in video; (3) calculate texture variance of each face; (4) use shape vector to estimate a face gallery in training data similar to faces in test data; (5) use minimum texture variance to identify objects from the gallery. Proposed methods are evaluated on two face video databases (YouTube Celebrities and FAMED). © 2018 Pushpa Publishing House, Allahabad, India.},
author_keywords={3D face recognition;  Face recognition using 3DMM},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ahdid201873,
author={Ahdid, R. and Taifi, K. and Said, S. and Fakir, M. and Manaut, B.},
title={Automatic face recognition system using iso-geodesic curves in riemanian manifold},
journal={Proceedings - 2017 14th International Conference on Computer Graphics, Imaging and Visualization, CGiV 2017},
year={2018},
pages={73-78},
doi={10.1109/CGiV.2017.25},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048323921&doi=10.1109%2fCGiV.2017.25&partnerID=40&md5=73b9e65d367cee00cdcb28e7b5ef55cb},
affiliation={Sultan Moulay Slimane University, Beni Mellal, Morocco},
abstract={In this paper, we present an automatic 3D face recognition system. This system is based on the representation of human faces surfaces as collections of Iso-Geodesic Curves (IGC) using 3D Fast Marching algorithm. To compare two facial surfaces, we compute a geodesic distance between a pair of facial curves using a Riemannian geometry. In the classifying step, we use: Neural Networks (NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this method and evaluate its performance, a simulation series of experiments were performed on 3D Shape REtrieval Contest 2008 database (SHREC2008). © 2017 IEEE.},
author_keywords={3D face recognition;  facial surfaces;  geodesic distance;  iso-geodesic curves;  Riemannian geometry},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ahdid201844,
author={Ahdid, R. and Said, S. and Fakir, M. and Manaut, B. and Ouadid, Y. and Taifi, K.},
title={Three dimensional face surface recognition by geodesic distance using jacobi iterations},
journal={Proceedings - 2017 14th International Conference on Computer Graphics, Imaging and Visualization, CGiV 2017},
year={2018},
pages={44-48},
doi={10.1109/CGiV.2017.28},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048323143&doi=10.1109%2fCGiV.2017.28&partnerID=40&md5=325b8a88194db0d808a9ef00987e1535},
affiliation={Sultan Moulay Slimane University, Beni Mellal, Morocco},
abstract={In this paper, we present an automatic application of 3D face recognition system using geodesic distance in Riemannian geometry. We consider, in this approach, the three dimensional face images as residing in Riemannian manifold and we compute the geodesic distance using the Jacobi iterations as a solution of the Eikonal equation. The problem of solving the Eikonal equation, unstructured simplified meshes of 3D face surface, such as tetrahedral and triangles are important for accurately modeling material interfaces and curved domains, which are approximations to curved surfaces in R3. In the classifying step, we use: Neural Networks (NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this method and evaluate its performance, a simulation series of experiments were performed on 3D Shape REtrieval Contest 2008 database (SHREC2008). © 2017 IEEE.},
author_keywords={3D face recognition;  Eikonal equation;  geodesic distance;  Jacobi iterations;  Riemannian geometry},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ramalingam201825,
author={Ramalingam, S.},
title={Fuzzy interval-valued multi criteria based decision making for ranking features in multi-modal 3D face recognition},
journal={Fuzzy Sets and Systems},
year={2018},
volume={337},
pages={25-51},
doi={10.1016/j.fss.2017.06.002},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024108581&doi=10.1016%2fj.fss.2017.06.002&partnerID=40&md5=903332f6c0cb447ada7cd083cb5492cd},
affiliation={Division of Electronics and Communications Engineering, School of Engineering and Technology, University of Hertfordshire, Hatfield, WD6 4UB, United Kingdom},
abstract={This paper describes an application of multi-criteria decision making (MCDM) for multi-modal fusion of features in a 3D face recognition system. A decision making process is outlined that is based on the performance of multi-modal features in a face recognition task involving a set of 3D face databases. In particular, the fuzzy interval valued MCDM technique called TOPSIS is applied for ranking and deciding on the best choice of multi-modal features at the decision stage. It provides a formal mechanism of benchmarking their performances against a set of criteria. The technique demonstrates its ability in scaling up the multi-modal features. © 2017},
author_keywords={3D face recognition;  Evidential reasoning under uncertainty;  Fuzzy fusion;  Interval values;  MCDM;  Multi-modal features;  TOPSIS},
document_type={Article},
source={Scopus},
}

@ARTICLE{NourbakhshKaashki201866,
author={Nourbakhsh Kaashki, N. and Safabakhsh, R.},
title={RGB-D face recognition under various conditions via 3D constrained local model},
journal={Journal of Visual Communication and Image Representation},
year={2018},
volume={52},
pages={66-85},
doi={10.1016/j.jvcir.2018.02.003},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042322207&doi=10.1016%2fj.jvcir.2018.02.003&partnerID=40&md5=2b91afeff8a19c987036cf8a30b610dc},
affiliation={Department of Computer Engineering, Amirkabir University of Technology, Tehran, Iran},
abstract={This research proposes a method for 3D face recognition in various conditions using 3D constrained local model (CLM-Z). In this method, a combination of 2D images (RGBs) and depth images (Ds) captured by Kinect has been used. After detecting the face and smoothing the depth image, CLM-Z model has been used to model and detect the important points of the face. These points are described using Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and 3D Local Binary Patterns (3DLBP). Finally, each face is recognized by a Support Vector Machine (SVM). The challenging situations are changes of lighting, facial expression and head pose. The results on CurtinFaces and IIIT-D datasets demonstrate that the proposed method outperformed state-of-the-art methods under illumination, expression and pitch pose conditions and comparable results were obtained in other cases. Additionally, our proposed method is robust even when the training data has not been carefully collected. © 2018 Elsevier Inc.},
author_keywords={3D constrained local model;  3D face recognition;  Depth image;  Face model;  Facial expression;  Feature descriptor;  Head pose;  Kinect;  Lighting},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Abbad20181,
author={Abbad, A. and Abbad, K. and Tairi, H.},
title={3D face recognition in the presence of facial expressions based on empirical mode decomposition},
journal={ACM International Conference Proceeding Series},
year={2018},
volume={2018-March},
pages={1-6},
doi={10.1145/3177148.3180087},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047112949&doi=10.1145%2f3177148.3180087&partnerID=40&md5=93db67c347fc7dadc31256f7eb69e983},
affiliation={Laboratory LIIAN, Faculty of Science, Dhar EL Mahraz, Morocco; Laboratory ISA, Faculty of Science and Technology, Morocco},
abstract={This paper presents an efficient 3D face recognition method to handle facial expression. The proposed method uses the Surfaces Empirical Mode Decomposition (SEMD), facial curves and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. The basic idea is that, the face is presented at different scales by SEMD. Then the isometric-invariant features on each scale are extracted. After that, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Finally, the feature vectors on each scale are associated with their corresponding geometric information. The presented method is validated on GavabDB database resulting a rank 1 recognition rate (RR) of 98.9% for all faces with neutral and non-neutral expressions. This result outperforms other 3D expression-invariant face recognition methods on the same database. © 2018 Association for Computing Machinery.},
author_keywords={3D face recognition;  EMD;  Expression;  Facial curves;  Geometric features;  Local features},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guo2018,
author={Guo, Y. and Wei, R. and Liu, Y.},
title={Weighted gradient feature extraction based on multiscale sub-blocks for 3d facial recognition in bimodal images},
journal={Information (Switzerland)},
year={2018},
volume={9},
number={3},
doi={10.3390/info9030048},
art_number={48},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042711391&doi=10.3390%2finfo9030048&partnerID=40&md5=fe75121af64143005ff6ec84435ed59d},
affiliation={School of Computer Science and Engineering, Hebei University of Technology, Tianjin, 300400, China},
abstract={In this paper, we propose a bimodal 3D facial recognition method aimed at increasing the recognition rate and reducing the effect of illumination, pose, expression, ages, and occlusion on facial recognition. There are two features extracted from the multiscale sub-blocks in both the 3D mode depth map and 2D mode intensity map, which are the local gradient pattern (LGP) feature and the weighted histogram of gradient orientation (WHGO) feature. LGP and WHGO features are cascaded to form the 3D facial feature vector LGP-WHGO, and are further trained and identified by the support vector machine (SVM). Experiments on the CASIA database, FRGC v2.0 database, and Bosphorus database show that, the proposed method can efficiently extract the structure information and texture information of the facial image, and have a robustness to illumination, expression, occlusion and pose. © 2018 by the authors.},
author_keywords={3D face recognition;  Bimodal;  Depth map;  Intensitymap;  LGP-WHGO;  Multiscale sub-blocks},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Soltanpour20182811,
author={Soltanpour, S. and Wu, Q.M.J.},
title={High-order local normal derivative pattern (LNDP) for 3D face recognition},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2018},
volume={2017-September},
pages={2811-2815},
doi={10.1109/ICIP.2017.8296795},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045292850&doi=10.1109%2fICIP.2017.8296795&partnerID=40&md5=12c33512c432220af4c4c49f5116433e},
affiliation={University of Windsor, Department of Electrical and Computer Engineering, Windsor, Canada},
abstract={This paper proposes a novel descriptor based on the local derivative pattern (LDP) for 3D face recognition. Compared to the local binary pattern (LBP), LDP can capture more detailed information by encoding directional pattern features. It is based on the local derivative variations that extract high-order local information. We propose a novel discriminative facial shape descriptor, local normal derivative pattern (LNDP) that extracts LDP from the surface normal. Using surface normal, the orientation of a surface at each point is determined as a first-order surface differential. Three normal component images are extracted by estimating three components of normal vectors in x, y, and z channels. Each normal component is divided into several patches and encoded using LDP. The final descriptor is created by concatenating histograms of the LNDP on each patch. Experimental results on two famous 3D face databases, FRGC v2.0 and Bosphorus illustrate the effectiveness of the proposed descriptor. © 2017 IEEE.},
author_keywords={3D face;  High-order local pattern;  Local derivative pattern;  Surface normal},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li20181295,
author={Li, Y. and Wang, Y. and Liu, J. and Hao, W.},
title={Expression-insensitive 3D face recognition by the fusion of multiple subject-specific curves},
journal={Neurocomputing},
year={2018},
volume={275},
pages={1295-1307},
doi={10.1016/j.neucom.2017.09.070},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040674183&doi=10.1016%2fj.neucom.2017.09.070&partnerID=40&md5=ecfea39a1b4d26ab1e33c34b50b87558},
affiliation={Institute of Computer Science & Engineering, Xi'an University of Technology, No.5 South Jinhua Road, Xi'an, 710048, China},
abstract={This study proposes a 3D face recognition method using multiple subject-specific curves insensitive to intra-subject distortions caused by expression variations. Considering that most sharp variances in facial convex regions are closely related to the bone structure, the convex crest curves are first extracted as the most vital subject-specific facial curves based on the principal curvature extrema in convex local surfaces. Then, the central profile curve and the horizontal contour curve passing through the nose tip are detected by using the precise localization of the nose tip and symmetry plane. Based on their discriminative power and robustness to expression changes, the three types of curves are fused with appropriate weights at the feature-level and used for matching 3D faces with the iterative closest point algorithm. The combination of multiple expression-insensitive curves is complementary and provides sufficient and stable facial surface features for face recognition. In addition, for each convex crest curve, an expression-irrelevant factor is assigned as the adaptive weight to improve the face matching performance. The results of experiments using two public 3D databases, GavabDB and BU-3DFE, demonstrate the effectiveness of the proposed method, and its recognition rates on both databases reflect an encouraging performance. © 2017 Elsevier B.V.},
author_keywords={3D face recognition;  Expression-insensitive;  Feature-level;  Fusion;  Subject-specific curve},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kim2018133,
author={Kim, D. and Hernandez, M. and Choi, J. and Medioni, G.},
title={Deep 3D face identification},
journal={IEEE International Joint Conference on Biometrics, IJCB 2017},
year={2018},
volume={2018-January},
pages={133-142},
doi={10.1109/BTAS.2017.8272691},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046247920&doi=10.1109%2fBTAS.2017.8272691&partnerID=40&md5=9660021125b86249b9768912252c19ff},
affiliation={USC Institute for Robotics and Intelligent Systems (IRIS), University of Southern California, United States},
abstract={We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D face expression augmentation technique. The performance of 2D face recognition algorithms has significantly increased by leveraging the representational power of deep neural networks and the use of large-scale labeled training data. In this paper, we show that transfer learning from a CNN trained on 2D face images can effectively work for 3D face recognition by fine-tuning the CNN with an extremely small number of 3D facial scans. We also propose a 3D face expression augmentation technique which synthesizes a number of different facial expressions from a single 3D face scan. Our proposed method shows excellent recognition results on Bosphorus, BU-3DFE, and 3D-TEC datasets without using hand-crafted features. The 3D face identification using our deep features also scales well for large databases. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2018234,
author={Li, H. and Sun, J. and Chen, L.},
title={Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition},
journal={IEEE International Joint Conference on Biometrics, IJCB 2017},
year={2018},
volume={2018-January},
pages={234-242},
doi={10.1109/BTAS.2017.8272703},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046291057&doi=10.1109%2fBTAS.2017.8272703&partnerID=40&md5=e5c4065442f8bc899597efdc443ed01c},
affiliation={School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, 710049, China; Department of Mathematics and Informatics, Ecole Centrale de Lyon, Lyon, 69134, France},
abstract={This paper presents a straight-forward yet efficient, and expression-robust 3D face recognition approach by exploring location sensitive sparse representation of deep normal patterns (DNP). In particular, given raw 3D facial surfaces, we first run 3D face pre-processing pipeline, including nose tip detection, face region cropping, and pose normalization. The 3D coordinates of each normalized 3D facial surface are then projected into 2D plane to generate geometry images, from which three images of facial surface normal components are estimated. Each normal image is then fed into a pre-trained deep face net to generate deep representations of facial surface normals, i.e., deep normal patterns. Considering the importance of different facial locations, we propose a location sensitive sparse representation classifier (LS-SRC) for similarity measure among deep normal patterns associated with different 3D faces. Finally, simple score-level fusion of different normal components are used for the final decision. The proposed approach achieves significantly high performance, and reporting rank-one scores of 98.01%, 97.60%, and 96.13% on the FRGC v2.0, Bosphorus, and BU-3DFE databases when only one sample per subject is used in the gallery. These experimental results reveals that the performance of 3D face recognition would be constantly improved with the aid of training deep models from massive 2D face images, which opens the door for future directions of 3D face recognition. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhao2018207,
author={Zhao, J.-L. and Wu, Z.-K. and Pan, Z.-K. and Duan, F.-Q. and Li, J.-H. and Lv, Z.-H. and Wang, K. and Chen, Y.-C.},
title={3D Face Similarity Measure by Fréchet Distances of Geodesics},
journal={Journal of Computer Science and Technology},
year={2018},
volume={33},
number={1},
pages={207-222},
doi={10.1007/s11390-018-1814-7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041342736&doi=10.1007%2fs11390-018-1814-7&partnerID=40&md5=8478bdecdc0eeeb6cb4dda3bb1ecda52},
affiliation={School of Data Science and Software Engineering, Qingdao University, Qingdao, 266071, China; College of Automation and Electrical Engineering, Qingdao University, Qingdao, 266071, China; College of Information Science and Technology, Beijing Normal University, Beijing, 100087, China; College of Computer Science and Technology, Qingdao University, Qingdao, 266071, China; School of Management, Capital Normal University, Beijing, 100048, China},
abstract={3D face similarity is a critical issue in computer vision, computer graphics and face recognition and so on. Since Fréchet distance is an effective metric for measuring curve similarity, a novel 3D face similarity measure method based on Fréchet distances of geodesics is proposed in this paper. In our method, the surface similarity between two 3D faces is measured by the similarity between two sets of 3D curves on them. Due to the intrinsic property of geodesics, we select geodesics as the comparison curves. Firstly, the geodesics on each 3D facial model emanating from the nose tip point are extracted in the same initial direction with equal angular increment. Secondly, the Fréchet distances between the two sets of geodesics on the two compared facial models are computed. At last, the similarity between the two facial models is computed based on the Fréchet distances of the geodesics obtained in the second step. We verify our method both theoretically and practically. In theory, we prove that the similarity of our method satisfies three properties: reflexivity, symmetry, and triangle inequality. And in practice, experiments are conducted on the open 3D face database GavaDB, Texas 3D Face Recognition database, and our 3D face database. After the comparison with iso-geodesic and Hausdorff distance method, the results illustrate that our method has good discrimination ability and can not only identify the facial models of the same person, but also distinguish the facial models of any two different persons. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={3D face;  Fréchet distance;  geodesic;  similarity measure},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lv2018,
author={Lv, C. and Zhao, J.},
title={3D Face Recognition based on Local Conformal Parameterization and Iso-Geodesic Stripes Analysis},
journal={Mathematical Problems in Engineering},
year={2018},
volume={2018},
doi={10.1155/2018/4707954},
art_number={4707954},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056267138&doi=10.1155%2f2018%2f4707954&partnerID=40&md5=6b9608dc984f786b68071250cc5e66cb},
affiliation={College of Information Science and Technology, Beijing Normal University, Beijing, China; Engineering Research Center of Virtual Reality and Applications, Ministry of Education, Beijing Key Laboratory of Digital Preservation, Beijing, 100875, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; College of Automation and Electrical Engineering, Qingdao University, Qingdao, China},
abstract={3D face recognition is an important topic in the field of pattern recognition and computer graphic. We propose a novel approach for 3D face recognition using local conformal parameterization and iso-geodesic stripes. In our framework, the 3D facial surface is considered as a Riemannian 2-manifold. The surface is mapped into the 2D circle parameter domain using local conformal parameterization. In the parameter domain, the geometric features are extracted from the iso-geodesic stripes. Combining the relative position measure, Chain 2D Weighted Walkthroughs (C2DWW), the 3D face matching results can be obtained. The geometric features from iso-geodesic stripes in parameter domain are robust in terms of head poses, facial expressions, and some occlusions. In the experiments, our method achieves a high recognition accuracy of 3D facial data from the Texas3D and Bosphorus3D face database. © 2018 Chenlei Lv and Junli Zhao.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang2018141,
author={Wang, X.},
title={3D face recognition based on regional shape maps},
journal={Journal of Advanced Computational Intelligence and Intelligent Informatics},
year={2018},
volume={22},
number={1},
pages={141-146},
doi={10.20965/jaciii.2018.p0141},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041116479&doi=10.20965%2fjaciii.2018.p0141&partnerID=40&md5=6ea7a6070e2cb83b72ff696c4d5c6c18},
affiliation={School of Applied Science, Beijing Information Science and Technology University, No. 12, Qing He Xiao Ying East Road, Haidian District, Beijing, China},
abstract={This study proposes an iterative closest shape point (ICSP) registration method based on regional shape maps for 3D face recognition. A neutral expression image randomly selected from a face database is considered as the reference face. The point-to-point correspondences between the input face and the reference face are achieved by constructing the points' regional shape maps. The distance between corresponding point pairs is then minimized by iterating through the correspondence findings and coordinate transformations. The vectors composed of the closest shape points obtained in the last iteration are regarded as the feature vectors of the input face. These 3D face feature vectors are finally used for both training and recognition using the Fisherface method. Experiments are conducted using the 3D face database maintained by the Chinese Academy of Science Institute of Automation (CASIA). The results show that the proposed method can effectively improve 3D face recognition performance.},
author_keywords={3D face recognition;  Corresponding point;  Iterative closest shape point;  Regional shape map},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ratyal20184903,
author={Ratyal, N. and Taj, I. and Bajwa, U. and Sajid, M.},
title={Pose and expression invariant alignment based multi-view 3d face recognition},
journal={KSII Transactions on Internet and Information Systems},
year={2018},
volume={12},
number={10},
pages={4903-4929},
doi={10.3837/tiis.2018.10.016},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057280833&doi=10.3837%2ftiis.2018.10.016&partnerID=40&md5=b7937933dbf1206dd6e5a81101a545c0},
affiliation={Vision and Pattern Recognition Systems Research Group, Capital University of Science and Technology (CUST), Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan},
abstract={In this study, a fully automatic pose and expression invariant 3D face alignment algorithm is proposed to handle frontal and profile face images which is based on a two pass course to fine alignment strategy. The first pass of the algorithm coarsely aligns the face images to an intrinsic coordinate system (ICS) through a single 3D rotation and the second pass aligns them at fine level using a minimum nose tip-scanner distance (MNSD) approach. For facial recognition, multi-view faces are synthesized to exploit real 3D information and test the efficacy of the proposed system. Due to optimal separating hyper plane (OSH), Support Vector Machine (SVM) is employed in multi-view face verification (FV) task. In addition, a multi stage unified classifier based face identification (FI) algorithm is employed which combines results from seven base classifiers, two parallel face recognition algorithms and an exponential rank combiner, all in a hierarchical manner. The performance figures of the proposed methodology are corroborated by extensive experiments performed on four benchmark datasets: GavabDB, Bosphorus, UMB-DB and FRGC v2.0. Results show mark improvement in alignment accuracy and recognition rates. Moreover, a computational complexity analysis has been carried out for the proposed algorithm which reveals its superiority in terms of computational efficiency as well. © 2018 KSII.},
author_keywords={3D alignment;  3D FR;  Profile face;  SVM;  Unified classifier},
document_type={Article},
source={Scopus},
}

@ARTICLE{Khan2018220,
author={Khan, M.S. and Jehanzeb, M. and Babar, M.I. and Faisal, S. and Ullah, Z. and Amin, S.Z.B.M.},
title={Face recognition analysis using 3D model},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2018},
volume={200},
pages={220-236},
doi={10.1007/978-3-319-95450-9_19},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051123902&doi=10.1007%2f978-3-319-95450-9_19&partnerID=40&md5=3b4f204837bae6e24de550e8aa4fd707},
affiliation={College of Computer Science, Sichuan University, Chengdu, 610065, China; Department of Computer Science, Army Public College of Management & Sciences (APCOMS), Rawalpindi, Punjab, Pakistan; Department of Computer Science, University of Haripur, Hattar Road Near Swat Chowk, Haripur, Khyber Pakhtunkhwa  22620, Pakistan; Federation University Australia, Mt Helen, Ballarat, VIC  3350, Australia; Western China Earthquake and Hazards Mitigation Research Centre, College of Architecture and Environment, Sichuan University, Chengdu, 610065, China},
abstract={Facial Recognition is a commonly used technology in security-related applications. It has been thoroughly studied and scrutinized for its number of practical real-world applications. On the road ahead of understanding this technology, there remain several obstacles. In this paper, methods of 3D face recognition are examined by measuring quantifiable applications and results. In facial recognition, three Dimensional Morphable Model (3DMM) techniques have attracted more and more attention as effectiveness in use increases over time. 3DMM provides automation and more accurate image rendering when compared to other traditional techniques. The accuracy in image rendering comes at a cost; as 3DMM requires more focus on texture estimation, shape-controlling limits, and extrinsic variations, accurately matching fitting models, feature tracking and precision identification. We have underlined different issues in comparison based on these methods. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.},
author_keywords={3D model;  Morphable model;  Recognition;  Reconstruction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{CardiaNeto2018135,
author={Cardia Neto, J.B. and Marana, A.N.},
title={Utilizing deep learning and 3DLBP for 3D Face recognition},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10657 LNCS},
pages={135-142},
doi={10.1007/978-3-319-75193-1_17},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042219158&doi=10.1007%2f978-3-319-75193-1_17&partnerID=40&md5=62334ac9f49d30280414a4356fe20dc0},
affiliation={São Carlos Federal University - UFSCAR, São Carlos, SP  13565-905, Brazil; UNESP - São Paulo State University, Bauru, SP  17033-360, Brazil},
abstract={Methods based on biometrics can help prevent frauds and do personal identification in day-to-day activities. Automated Face Recognition is one of the most popular research subjects since it has several important properties, such as universality, acceptability, low costs, and covert identification. In constrained environments methods based on 2D features can outperform the human capacity for face recognition but, once occlusion and other types of challenges are presented, the aforementioned methods do not perform so well. To deal with such problems 3D data and deep learning based methods can be a solution. In this paper we propose the utilization of Convolutional Neural Networks (CNN) with low-level 3D local features (3DLBP) for face recognition. The 3D local features are extracted from depth maps captured by a Kinect sensor. Experimental results on Eurecom database show that this proposal is promising, since, in average, almost 90% of the faces were correctly recognized. © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={3D face recognition;  3D local features;  Biometrics;  Convolutional neural networks;  Deep learning;  Depth maps;  Kinect},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Banita20182325,
author={Banita and Tanwar, P.},
title={Evaluation of 3d facial paralysis using fuzzy logic},
journal={International Journal of Engineering and Technology(UAE)},
year={2018},
volume={7},
number={4},
pages={2325-2331},
doi={10.14419/ijet.v7i4.13619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053901681&doi=10.14419%2fijet.v7i4.13619&partnerID=40&md5=f68480ef298793b35ad707b17c64ab59},
affiliation={Lingaya's University, Faridabad, India; Manav Rachana University, Faridabad, India},
abstract={Face recognition are of great interest to researchers in terms of Image processing and Computer Graphics. In recent years, various factors become popular which clearly affect the face model. Which are ageing, universal facial expressions, and muscle movement. Similarly in terms of medical terminology the facial paralysis can be peripheral or central depending on the level of motor neuron lesion which can be below the nucleus of the nerve or supra nuclear. The various medical therapy used for facial paralysis are electroaccupunture, electro-therapy, laser acupuncture, manual acupuncture which is a traditional form of acupuncture. Imaging plays a great role in evaluation of degree of paralysis and also for faces recognition. There is a wide research in terms of facial expressions and facial recognition but lim-ited research work is available in facial paralysis. House- Brackmann Grading system is one of the simplest and easiest method to evalu-ate the degree of facial paralysis. During evaluation common facial expressions are recorded and are further evaluated by considering the focal points of the left or the right side of the face. This paper presents the classification of face recognition and its respective fuzzy rules to remove uncertainty in the result after evaluation of facial paralysis. © 2018 Banita, Dr. Poonam Tanwar.},
author_keywords={3D face recognition;  CNN;  Evaluation of facial paralysis;  MAMDANI model;  Stages of face recognition},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kalake2018226,
author={Kalake, L. and Yoshida, C.},
title={Designing an Electronic Health Security System Framework for Authentication with Wi-Fi, Smartphone and 3D Face Recognition Technology},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2018},
volume={206},
pages={226-232},
doi={10.1007/978-3-319-67837-5_22},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032688156&doi=10.1007%2f978-3-319-67837-5_22&partnerID=40&md5=9b0b8b2e9d152fca97568c24ab9ca0b6},
affiliation={Graduate School of Technology, Kobe Institute of Computing, Kano-cho 2-7-7, Chuo-ku, Kobe, 6500001, Japan},
abstract={Information technology for development is the tool that has been around for ages and it is now mainly focusing on making people lives easy including of those in a health sector. However, health practitioners and patients are somehow had not fully experienced this benefits due to sensitive information distribution and security concerns around the distribution of electronic health records. There have been various issues and challenges on security breaches, leakage of confidential patient records and computer attacks which have been raised on security and privacy concerns in electronic health records. The unauthorized access, denial of services, lack of standardization of the system increases mistrust on electronic health record system and makes it very difficult for the parties involved in handling and transmission of patients’ record. Therefore the aim of this paper is to propose an efficient and cost-effective face recognition security framework through Wi-Fi to enable the monitoring and access control on patient record in developing countries. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
author_keywords={3D face recognition;  Authentication and security;  Biometric;  International mobile station equipment identity;  Mac address;  Mobile device encryption;  Patient electronic health record;  Serial number;  Wi-Fi},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hu2017133,
author={Hu, H. and Shah, S.A.A. and Bennamoun, M. and Molton, M.},
title={2D and 3D face recognition using convolutional neural network},
journal={IEEE Region 10 Annual International Conference, Proceedings/TENCON},
year={2017},
volume={2017-December},
pages={133-138},
doi={10.1109/TENCON.2017.8227850},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044210743&doi=10.1109%2fTENCON.2017.8227850&partnerID=40&md5=12f531513eddb3716404e891cd002a29},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA  6009, Australia},
abstract={Face recognition remains a challenge today as recognition performance is strongly affected by variability such as illumination, expressions and poses. In this work we apply Convolutional Neural Networks (CNNs) on the challenging task of both 2D and 3D face recognition. We constructed two CNN models, namely CNN-1 (two convolutional layers) and CNN-2 (one convolutional layer) for testing on 2D and 3D dataset. A comprehensive parametric study of two CNN models on face recognition is represented in which different combinations of activation function, learning rate and filter size are investigated. We find that CNN-2 has a better accuracy performance on both 2D and 3D face recognition. Our experimental results show that an accuracy of 85.15% was accomplished using CNN-2 on depth images with FRGCv2.0 dataset (4950 images with 557 objectives). An accuracy of 95% was achieved using CNN-2 on 2D raw image with the AT&T dataset (400 images with 40 objectives). The results indicate that the proposed CNN model is capable to handle complex information from facial images in different dimensions. These results provide valuable insights into further application of CNN on 3D face recognition. © 2017 IEEE.},
author_keywords={Convolutional Neural Networks;  Depth Image;  Face Recognition},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Soltanpour2017391,
author={Soltanpour, S. and Boufama, B. and Jonathan Wu, Q.M.},
title={A survey of local feature methods for 3D face recognition},
journal={Pattern Recognition},
year={2017},
volume={72},
pages={391-406},
doi={10.1016/j.patcog.2017.08.003},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027498785&doi=10.1016%2fj.patcog.2017.08.003&partnerID=40&md5=170ec9f0f1db0dc82a019bf4eb78253f},
affiliation={Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, N9B 3P4, Canada; School of Computer Science, University of Windsor, Windsor, ON, N9B 3P4, Canada},
abstract={One of the main modules in a face recognition system is feature extraction, which has a significant effect on the whole system performance. In the past decades, various types of feature extractors and descriptors have been proposed for 3D face recognition. Although several literature reviews have been carried out on 3D face recognition algorithms, only a few studies have been performed on feature extraction methods. The latter have a vital role to overcome degradation conditions, such as face expression variations and occlusions. Depending on the types of features used in 3D face recognition, these methods can be divided into two categories: global and local feature-based methods. Local feature-based methods have been effectively applied in the literature, as they are more robust to occlusions and missing data. This survey presents a state-of-the-art for 3D face recognition using local features, with the main focus being the extraction of these features. © 2017},
author_keywords={3-D;  Face recognition;  Feature extraction;  Local features;  Survey},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Soltanpour2017560,
author={Soltanpour, S. and Wu, Q.M.J.},
title={Multiscale depth local derivative pattern for sparse representation based 3D face recognition},
journal={2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017},
year={2017},
volume={2017-January},
pages={560-565},
doi={10.1109/SMC.2017.8122665},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044201680&doi=10.1109%2fSMC.2017.8122665&partnerID=40&md5=5918c06bbe0b6cc90d03ba306b0d1258},
affiliation={Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada},
abstract={3D face recognition is a popular research area due to its vast application in biometrics and security. Local featurebased methods gain importance in the recent years due to their robustness under degradation conditions. In this paper, a novel high-order local pattern descriptor in combination with sparse representation based classifier (SRC) is proposed for expression robust 3D face recognition. 3D point clouds are converted to depth maps after preprocessing. Multi-directional derivatives are applied in spatial space to encode the depth maps based on the local derivative pattern (LDP) scheme. Directional pattern features are calculated according to local derivative variations. Since LDP computes spatial relationship of neighbors in a local region, it extracts distinct information from the depth map. Multiscale depth-LDP is presented as a novel descriptor for 3D face recognition. The descriptor is employed along with the SRC to increase the range data distinctiveness. A histogram on the derivative pattern creates a spatial feature descriptor that represents the distinctive micro-patterns from 3D data. We evaluate the proposed algorithm on two famous 3D face databases, FRGC v2.0 and Bosphorus. The experimental results demonstrate that the proposed approach achieves acceptable performance under facial expression. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2017,
author={Liu, Z. and Cohen, F.},
title={Synthesis and identification of three-dimensional faces from image(s) and three-dimensional generic models},
journal={Journal of Electronic Imaging},
year={2017},
volume={26},
number={6},
doi={10.1117/1.JEI.26.6.063005},
art_number={063005},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034836161&doi=10.1117%2f1.JEI.26.6.063005&partnerID=40&md5=cbf0b712fa254c1cccec3850f657b1dd},
affiliation={Kepler Group LLC, New York, NY, United States; Drexel University, Electrical and Computer Engineering, Philadelphia, PA, United States},
abstract={We describe an approach for synthesizing a three-dimensional (3-D) face structure from an image or images of a human face taken at a priori unknown poses using gender and ethnicity specific 3-D generic models. The synthesis process starts with a generic model, which is personalized as images of the person become available using preselected landmark points that are tessellated to form a high-resolution triangular mesh. From a single image, two of the three coordinates of the model are reconstructed in accordance with the given image of the person, while the third coordinate is sampled from the generic model, and the appearance is made in accordance with the image. With multiple images, all coordinates and appearance are reconstructed in accordance with the observed images. This method allows for accurate pose estimation as well as face identification in 3-D rendering of a difficult two-dimensional (2-D) face recognition problem into a much simpler 3-D surface matching problem. The estimation of the unknown pose is achieved using the Levenberg-Marquardt optimization process. Encouraging experimental results are obtained in a controlled environment with high-resolution images under a good illumination condition, as well as for images taken in an uncontrolled environment under arbitrary illumination with low-resolution cameras. © 2017 SPIE and IS&T.},
author_keywords={3-D face recognition;  3-D face synthesis;  iterative personalization;  pose estimation;  ray tracing;  subdivision},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Frikha2017,
author={Frikha, T. and Chaabane, F. and Said, B. and Drira, H. and Abid, M. and Ben Amar, C. and Lille, L.},
title={Embedded approach for a Riemannian-based framework of analyzing 3D faces},
journal={Proceedings - 3rd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2017},
year={2017},
doi={10.1109/ATSIP.2017.8075548},
art_number={8075548},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035335463&doi=10.1109%2fATSIP.2017.8075548&partnerID=40&md5=f9c92873ac16b26563e98ecaba5f6bba},
affiliation={REGIM-Lab: REsearch Groups in Intelligent Machines, University of Sfax, ENIS, BP 1173, Gabes University, Higher Institute of Computer Science and Multimedia of Gabes, Sfax, 3038, Tunisia; REGIM-Lab, Sfax, 3038, Tunisia; Multimedia of Gabes, Sfax, 3038, Tunisia; CES-Laboratory Sfax Sud University, National Engineering School of Sfax, Sfax, Tunisia},
abstract={Developing multimedia embedded applications continues to flourish. In fact, a biometric facial recognition system can be used not only on PCs abut also in embedded systems, it is a potential enhancer to meet security and surveillance needs. The analysis of facial recognition consists offoursteps: face analysis, face expressions' recognition, missing data completion and full face recognition. This paper proposes a hardware architecture based on an adaptation approach foran algorithm which has proven good face detection and recognition in 3D space. The proposed application was tested using a co design technique based on a mixed Hardware Software architecture: the FPGA platform. © 2017 IEEE.},
author_keywords={3D face recognition;  Curve analysis;  elastic analysis algorithm;  embedded architecture;  face detection;  Facial analysis;  Facial expressions;  Riemann geometry},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sui201719575,
author={Sui, D. and Hou, D. and Duan, X.},
title={An interpolation algorithm fitted for dynamic 3D face reconstruction},
journal={Multimedia Tools and Applications},
year={2017},
volume={76},
number={19},
pages={19575-19589},
doi={10.1007/s11042-015-3233-x},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954425638&doi=10.1007%2fs11042-015-3233-x&partnerID=40&md5=78e6cc2a30fcda0f0eb7e4d7fd616c46},
affiliation={School of Information Science and Technology, Wuhan University of Technology, Hubei, 430070, China; School of Software Engineering, Anyang Normal University, Anyang, Henan  455000, China; Department of Computer, College of Science California State Polytecnic University-Pomona, California, United States},
abstract={In order to solve the problem of low recognition accuracy in later period which is caused by the too few extracted parameters in the 3D face recognition, and the incapable formation of completed point cloud structure. An automatic iterative interpolation algorithm is proposed. The new and more accurate 3D face data points are obtained by automatic iteration. This algorithm can be used to restore the data point cloud information of 3D facial feature in 2D images by means of facial three-legged structure formed by 3D face and automatic interpolation. Thus, it can realize to shape the 3D facial dynamic model which can be recognized and has high saturability. Experimental results show that the interpolation algorithm can achieve the complete the construction of facial feature based on the facial feature after 3D dynamic reconstruction, and the validity is higher. © 2016, Springer Science+Business Media New York.},
author_keywords={3D face dynamic recognition;  Iterative interpolation algorithm;  Point cloud structure},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng20171305,
author={Deng, X. and Da, F. and Shao, H.},
title={Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition},
journal={Signal, Image and Video Processing},
year={2017},
volume={11},
number={7},
pages={1305-1312},
doi={10.1007/s11760-017-1087-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017095710&doi=10.1007%2fs11760-017-1087-6&partnerID=40&md5=fc06247cc3ca7870221563a085266269},
affiliation={School of Automation, Southeast University, Nanjing, Jiangsu  210096, China; Key Laboratory of Measurement and Control for Complex System, Ministry of Education, Southeast University, Nanjing, Jiangsu  210096, China},
abstract={A novel adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition is proposed in this paper. Firstly, the novel facial coarse-to-fine landmarks localization method based on Active Shape Model and Gabor wavelets transformation is proposed to exactly and automatically locate facial landmarks in range image. Secondly, the multi-scale fusion of the pyramid local binary patterns (F-PLBP) based on the irregular segmentation associated with the located landmarks is proposed to extract the discriminative feature. Thirdly, a sparse representation-based classifier based on the adaptive feature selection (A-SRC) using the distribution of the reconstruction residual is presented to select the expression-robust feature and identify the faces. Finally, the experimental evaluation based on FRGC v2.0 indicates that the adaptive feature selection method using F-PLBP combined with the A-SRC can obtain the high recognition accuracy by performing the higher discriminative power to overcome the influence from the facial expression variations. © 2017, Springer-Verlag London.},
author_keywords={3D face recognition;  Adaptive feature selection;  Facial landmark localization;  Multi-scale fusion},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liang201784,
author={Liang, Y. and Zhang, Y. and Zeng, X.-X.},
title={Pose-invariant 3D face recognition using half face},
journal={Signal Processing: Image Communication},
year={2017},
volume={57},
pages={84-90},
doi={10.1016/j.image.2017.05.004},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020037210&doi=10.1016%2fj.image.2017.05.004&partnerID=40&md5=88180b3e1c893d79c59e39647f3ee0a2},
affiliation={Guangdong University of Technology, School of Automation, No.100, Waihuan Xi Road, Guangzhou Higher Education Mega Centre, Guangzhou, 510006, China; South China Normal University, School of Software, Nanhai Information Technology Park, Foshan, 528225, China},
abstract={Pose variations are still challenging problems in 3D face recognition because large pose variations will cause self-occlusion and result in missing data. In this paper, a new method for pose-invariant 3D face recognition is proposed to handle significant pose variations. For pose estimation and registration, a coarse-to-fine strategy is proposed to detect landmarks under large yaw variations. At the coarse search step, candidate landmarks are detected using HK curvature analysis and subdivided according to a facial geometrical structure-based classification strategy. At the fine search step, candidate landmarks are identified and labeled by comparing with a Facial Landmark Model. By using the half face matching, we perform the matching step with respect to frontal scans and side scans. Experiments carried out on the Bosphorus and UND/FRGC v2.0 databases show that our method has high accuracy and robustness to pose variations. © 2017 Elsevier B.V.},
author_keywords={3D face recognition;  Facial landmark localization;  Half face;  Iso-geodesic stripes;  Pose variation},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang20171141,
author={Wang, X.-Q. and Yuan, J.-Z. and Li, Q.},
title={3D face recognition using spherical vector norms map},
journal={Journal of Information Science and Engineering},
year={2017},
volume={33},
number={5},
pages={1141-1161},
doi={10.6688/JISE.2017.33.5.3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049875700&doi=10.6688%2fJISE.2017.33.5.3&partnerID=40&md5=cd82489caa82b30e6bb8b05ea1dbaae9},
affiliation={Beijing Key Laboratory of Information Service Engineering, China; Computer Technology Institute, Beijing Union University, Beijing, 100101, China; Beijing Advanced Innovation Center for Imaging Technology Capital Normal University, Beijing, 100048, China},
abstract={In this paper, we introduce a novel, automatic method for 3D face recognition. A new feature called a spherical vector norms map of a 3D face is created using the normal vector of each point. This feature contains more detailed information than the original depth image in regions such as the eyes and nose. For certain flat areas of 3D face, such as the forehead and cheeks, this map could increase the distinguishability of different points. In addition, this feature is robust to facial expression due to an adjustment that is made in the mouth region. Then, the facial representations, which are based on Histograms of Oriented Gradients, are extracted from the spherical vector norms map and the original depth image. A new partitioning strategy is proposed to produce the histogram of eight patches of a given image, in which all of the pixels are binned based on the magnitude and direction of their gradients. In this study, SVNs map and depth image are represented compactly with two histograms of oriented gradients; this approach is completed by Linear Discriminant Analysis and a Nearest Neighbor classifier. © 2017 Institute of Information Science. All Rights Reserved.},
author_keywords={3D face recognition;  Face recognition grand challenge database;  Histograms of oriented gradients;  Linear discriminant analysis;  Spherical vector norms map},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng201781,
author={Deng, X. and Da, F. and Shao, H.},
title={Efficient 3D face recognition using local covariance descriptor and Riemannian kernel sparse coding},
journal={Computers and Electrical Engineering},
year={2017},
volume={62},
pages={81-91},
doi={10.1016/j.compeleceng.2017.01.028},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011588375&doi=10.1016%2fj.compeleceng.2017.01.028&partnerID=40&md5=0a8b76ccd56a100449319171e3925d83},
affiliation={School of Automation, Southeast University, Nanjing 210096, China; Key Laboratory of Measurement and Control for Complex System, Ministry of Education, Southeast University, Nanjing 210096, China},
abstract={This paper proposes a novel 3D face recognition method using the local covariance descriptor and Riemannian kernel sparse coding in order to accurately evaluate the intrinsic correlation of the extracted features and further improve the 3D face recognition accuracy. Firstly, the keypoints are detected by the farthest point sampling method, and the corresponding keypoint neighborhood is extracted by the specified radius associated with geodesic distance. Then, different types of the efficient features are selected to construct the local covariance descriptor with inherent property. Finally, the appropriate Riemannian kernel sparse coding is used to identify the faces in probe. Experimental evaluation has been performed on two challenging 3D face datasets, FRGC v2.0 and Bosphorus, which indicates that the proposed approach can significantly improve the identification accuracy comparing with other state-of-the-art methods. © 2017 Elsevier Ltd},
author_keywords={3D face recognition;  Local covariance descriptor;  Riemannian kernel sparse coding;  Symmetric positive define matrix},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kim2017477,
author={Kim, J. and Han, D. and Hwang, W. and Kim, J.},
title={3D face recognition via discriminative keypoint selection},
journal={2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2017},
year={2017},
pages={477-480},
doi={10.1109/URAI.2017.7992781},
art_number={7992781},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034232492&doi=10.1109%2fURAI.2017.7992781&partnerID=40&md5=5fe4994d9645b41dca322b1421c30da3},
affiliation={School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Dept. of Software and Computer Engineering, Ajou University, Suwon, South Korea},
abstract={In this paper, we propose a discriminative keypoint selection-based 3D face recognition method that is superior to prevalent techniques in terms of both computational complexity and performance. We use the average face model (AFM) for face registration to efficiently locate the axis of symmetry in the rotated face mesh and recover a full frontal face from a 3D face model commonly corrupted due to pose variances. Instead of using the keypoint detection method, we use the feature selection algorithm to find the most discriminant keypoints for face identification and reduce computational time for not only feature extraction but also keypoint matching. The results of the experiments conducted on the Bosphorus database and the UMB-DB show that our algorithm can improve rank-1 identification accuracy, thus confirming its robustness against pose variances, expressions, and occlusions. © 2017 IEEE.},
author_keywords={Face recognition;  feature selection;  sparse representation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yi2017,
author={Yi, Z. and Yuan, Z.},
title={Research on 3D face recognition based on pose and illumination invariant},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F130523},
doi={10.1145/3110224.3110230},
art_number={a6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030531368&doi=10.1145%2f3110224.3110230&partnerID=40&md5=aa474ad08228f7cca6c22bbea758dde7},
affiliation={College of Software Engineering, Lanzhou Institute of Technology, Lanzhou, 730050, China; School of Chemical and Biological Engineering, Lanzhou Jiaotong University, Lanzhou, 730070, China},
abstract={In order to solve the problem of error rate caused by pose and illumination variation, the sparse statistical deformable model is used to reconstruct the 3D face shape. By using the method of spherical harmonic quotient image, estimation of the original input image light properties, the generated model standardized posture and illumination reconstruction, the original input image due to pose and illumination recognition error caused by the different solution. Experimental results show that the proposed method can effectively improve the recognition rate of 3D face. © 2017 Association for Computing Machinery.},
author_keywords={3D face recognition;  Illumination;  Pose;  Ratio image;  Spherical harmonic},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Torkhani2017969,
author={Torkhani, G. and Ladgham, A. and Sakly, A. and Mansouri, M.N.},
title={A 3D–2D face recognition method based on extended Gabor wavelet combining curvature and edge detection},
journal={Signal, Image and Video Processing},
year={2017},
volume={11},
number={5},
pages={969-976},
doi={10.1007/s11760-016-1046-7},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008237723&doi=10.1007%2fs11760-016-1046-7&partnerID=40&md5=bc47ad9c58f9b47b4c97513603061854},
affiliation={Laboratory EμE, Faculty of Sciences of Monastir, Monastir, Tunisia; Department of Electrical Engineering, National Engineering School of Monastir (ENIM), Monastir, Tunisia; Reseach Unit, Industrial Systems Study and Renewable Energy (ESIER), ENIM, Monastir, Tunisia},
abstract={The main limitation in 3D face recognition (FR) systems is their susceptibility to scanning difficulties and uncontrolled environments such as pose, illumination and expression variety. This paper proposes a new FR framework based on 3D to 2D mesh deforming and combined Gabor curvature and edge maps. The advantage of this method comes from the powerful saliency distribution achieved from applying extended Gabor wavelets to 2D projected face meshes. The extracted feature vectors are classified using the outstanding robustness of the support vector machine. Experiments carried out on common databases proved that valid accuracy rates can be accomplished by the proposed approach comparing to other existing methods. © 2017, Springer-Verlag London.},
author_keywords={Feature extraction;  Gabor curvature and edge maps;  Gabor wavelets;  Recognition rate},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tang2017589,
author={Tang, Y. and Chen, L.},
title={3D Facial Geometric Attributes Based Anti-Spoofing Approach against Mask Attacks},
journal={Proceedings - 12th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2017 - 1st International Workshop on Adaptive Shot Learning for Gesture Understanding and Production, ASL4GUP 2017, Biometrics in the Wild, Bwild 2017, Heterogeneous Face Recognition, HFR 2017, Joint Challenge on Dominant and Complementary Emotion Recognition Using Micro Emotion Features and Head-Pose Estimation, DCER and HPE 2017 and 3rd Facial Expression Recognition and Analysis Challenge, FERA 2017},
year={2017},
pages={589-595},
doi={10.1109/FG.2017.74},
art_number={7961795},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026323809&doi=10.1109%2fFG.2017.74&partnerID=40&md5=ed89e52bd051c85dbee8198cd1d7344e},
affiliation={Universite de Lyon, CNRS, Ecole Centrale de Lyon, LIRIS, Lyon, 69134, France},
abstract={3D scanning and 3D printing techniques, as the technical impetus of 3D face recognition, also boost unconsciously the security threat against it from the spoofing attacks via manufactured mask. In order to improve the robustness of 3D face recognition system, several countermeasures against mask attacks based on photometric features have been reported in recent years. However, the anti-spoofing approach involving 3D meshed face scan and the related 3D facial features have not been studied yet. For filling this gap, in this paper, we propose to exploit the anti-spoofing performance of geometric attributes based 3D facial description. It synthesises the advantages of the selected geometric attributes, named principal curvature measures, and the meshSIFT-based feature descriptor. Specifically, the estimation of geometric attributes is coherent to the property of discrete surface, and the feature related to them can accurately describe the shape of facial surface. These characteristics are beneficial to discovering the geometry-based dissimilarity between genuine face and fraud mask. In the experiment part, the baselines of verification and anti-spoofing performance are evaluated on the Morpho database. Furthermore, for simulating a real-world scenario and testing the corresponding anti-spoofing performance, the size of genuine face set is massively extended by uniting the Morpho database and the FRGC v2.0 database to increase the ratio of genuine faces to fraud masks. The evaluation results prove that the proposed 3D face verification system can guarantee competitive verification accuracy for genuine faces and promising anti-spoofing performance against mask attacks. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yahia2017328,
author={Yahia, S. and Ben Salem, Y. and Abdelkrim, M.N.},
title={3D face recognition using local binary pattern and grey level co-occurrence matrix},
journal={2016 17th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering, STA 2016 - Proceedings},
year={2017},
pages={328-338},
doi={10.1109/STA.2016.7952047},
art_number={7952047},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024382159&doi=10.1109%2fSTA.2016.7952047&partnerID=40&md5=6f4d58a55714353c995acbaca835313b},
affiliation={Electric Department, ENIG, MACS Laboratory, Gabès, Tunisia},
abstract={In this paper, we aim to study the problem of 3D face recognition. This problem becomes complex when we consider the human face expressions and different face occlusions. In this context is situated our work, we use the 3D UMB database to evaluate two powerful methods: The 3D Local Binary Pattern (3D-LBP) and the 3D Grey Level Co-occurrence Matrix (3D-GLCM). We tested also the combination of these two approaches. A training phase is necessary, to pass to the test phase which is followed by classification. We use a multiclass Support Vector Machines (SVM) for classification. The experimental results prove that in this classification problem 3D-LBP is the more suitable. © 2016 IEEE.},
author_keywords={3D face recognition;  3D-GLCM;  3D-LBP;  classification;  SVM},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Saleh2017116,
author={Saleh, Y. and Edirisinghe, E.},
title={3D face reconstruction and recognition using the overfeat network},
journal={2017 8th International Conference on Information and Communication Systems, ICICS 2017},
year={2017},
pages={116-119},
doi={10.1109/IACS.2017.7921956},
art_number={7921956},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020175736&doi=10.1109%2fIACS.2017.7921956&partnerID=40&md5=909441cac89ba044d64659e5f0349f22},
affiliation={Department Computer Science, Loughborough University, Loughborough, LE11 3TU, United Kingdom},
abstract={Although face recognition is considered a popular area of research and study, it still has few unresolved challenges, and with the appearance of devices such as the Microsoft Kinect, new possibilities for researchers were uncovered. With the goal of enhancing face recognition techniques, this paper presents a novel way to reconstruct face images in different angles, through the use of the data of one front image captured by the Kinect, using faster techniques than ever before, also, this paper utilizes a deep learning network called Overfeat, where it functioned as a feature extractor that was used on normal images and on the new 3D created images, which introduced a new application for the network. To check the capabilities of the new created images, they were used as a testing set in three main experiments. Finally, results of the experiments are presented to prove the ability of the created images to function as new data sets for face recognition; also, proving the capability of the Overfeat network, working with computer generated face images. © 2017 IEEE.},
author_keywords={3D Face recognition;  Deep Learning;  Kinect;  Overfeat},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Emambakhsh2017995,
author={Emambakhsh, M. and Evans, A.},
title={Nasal Patches and Curves for Expression-Robust 3D Face Recognition},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
year={2017},
volume={39},
number={5},
pages={995-1007},
doi={10.1109/TPAMI.2016.2565473},
art_number={7467565},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018498024&doi=10.1109%2fTPAMI.2016.2565473&partnerID=40&md5=e1afb77517c631cf7da8f8d394318b02},
affiliation={Institute of Sensors, Signals and Systems, Heriot-Watt University, Edinburgh, United Kingdom; Department of Electronic and Electrical Engineering, University of Bath, Bath, United Kingdom},
abstract={The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm. © 2016 IEEE.},
author_keywords={Face recognition;  facial landmarking;  feature selection;  Gabor wavelets;  nose region;  surface normals},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yu2017296,
author={Yu, X. and Gao, Y. and Zhou, J.},
title={Sparse 3D directional vertices vs continuous 3D curves: Efficient 3D surface matching and its application for single model face recognition},
journal={Pattern Recognition},
year={2017},
volume={65},
pages={296-306},
doi={10.1016/j.patcog.2016.12.009},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010678622&doi=10.1016%2fj.patcog.2016.12.009&partnerID=40&md5=a32f68ce5d21826e871243d030db3868},
affiliation={School of Engineering, Griffith UniversityQLD  4111, Australia; School of Information and Communication Technology, Griffith UniversityQLD  4111, Australia},
abstract={Traditionally, point clouds and meshes are used to represent and match 3D shapes, which often cannot meet the computational speed and storage space requirements in many 3D data matching and retrieval applications. In this paper, we present a novel 3D directional vertices (3D2V) approach to efficiently represent and match 3D surfaces by much fewer sparsely distributed structured vertices that carry structural information transferred from their deleted neighbouring points. A 3D2V conversion and similarity measurement method is developed to compute the distance between two different 3D2Vs. The performance of the proposed method is evaluated on 3D face recognition using Face Recognition Grand Challenge v2.0 (FRGC v2.0) and GavabDB databases and compared with the curve-based benchmark method. The experimental results demonstrate that the proposed 3D2V method can significantly reduce the data storage requirement and computation time with a moderate increase of accuracy at the same time. It provides a new tool for developing fast 3D surface matching algorithms for large scale 3D data classification and retrieval. © 2016},
author_keywords={3D curve;  3D directional vertex;  3D face recognition;  3D surface matching;  Fast 3D matching;  Hausdorff distance;  Iterative closest points;  Storage space},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wu2017398,
author={Wu, Z. and Hou, Z. and Zhang, J.},
title={Research on the 3D face recognition based on multi-class classifier with depth and point cloud data},
journal={Proceedings of 2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference, IMCEC 2016},
year={2017},
pages={398-402},
doi={10.1109/IMCEC.2016.7867242},
art_number={7867242},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016763964&doi=10.1109%2fIMCEC.2016.7867242&partnerID=40&md5=9f0eedd2b08b943e738a503f0aa393bc},
affiliation={Changzhou University, Jiangsu Province, China},
abstract={Human face recognition technology usually takes advantages of two-dimensional or three-dimensional data. Rising from 1980s, three-dimensional face recognition technology soon become one of the headed topic because of its admirable resistance to interference and more information compared with two-dimensional face recognition technology. The new 3D face model standardization algorithm presented in this article provides a solution to transfer the obtained face model to standardized CANDIDE-3 face model. The article also provides a new Bayesian classification model based on multi-class classifier, which could overcome the difficulty that ono-verse-one classifier has a low recognition rate when facing more than two people. The article conduct the comparison experiment based on the provided algorithm. According to the experiment, it could raise the face recognition rate efficiently when applying the standardization algorithm and training model. © 2016 IEEE.},
author_keywords={3D face recognition;  CANDIDE-3;  Depth data;  Face model standardization;  Multi-class classifier;  Point cloud data},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bobulski2017121,
author={Bobulski, J.},
title={Multimodal face recognition method with two-dimensional hidden Markov model},
journal={Bulletin of the Polish Academy of Sciences: Technical Sciences},
year={2017},
volume={65},
number={1},
pages={121-128},
doi={10.1515/bpasts-2017-0015},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013807265&doi=10.1515%2fbpasts-2017-0015&partnerID=40&md5=0560b8de533c2b1b9017479cf483d622},
affiliation={Institute of Computer and Information Science, Czestochowa University of Technology, 73 Dabrowskiego St., Czestochowa, 42-201, Poland},
abstract={The paper presents a new solution for the face recognition based on two-dimensional hidden Markov models. The traditional HMM uses one-dimensional data vectors, which is a drawback in the case of 2D and 3D image processing, because part of the information is lost during the conversion to one-dimensional features vector. The paper presents a concept of the full ergodic 2DHMM, which can be used in 2D and 3D face recognition. The experimental results demonstrate that the system based on two dimensional hidden Markov models is able to achieve a good recognition rate for 2D, 3D and multimodal (2D+3D) face images recognition, and is faster than ICP method.},
author_keywords={3D face recognition;  Biometrics;  Hidden Markov model;  Pattern recognition},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Naveen2017112,
author={Naveen, S. and Rugmini, K.P. and Moni, R.S.},
title={3D face reconstruction by pose correction, patch cloning and texture wrapping},
journal={2016 International Conference on Communication Systems and Networks, ComNet 2016},
year={2017},
pages={112-116},
doi={10.1109/CSN.2016.7823997},
art_number={7823997},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014911379&doi=10.1109%2fCSN.2016.7823997&partnerID=40&md5=d83e42a8548567d921eea89900252c10},
affiliation={Dept. of ECE, LBSITW, Thiruvananthapuram Kerala, India; Dept. of ECE Marian Engineering College, Thiruvananthapuram Kerala, India},
abstract={Face is being considered as one of the most commonly used biometric modality. The inaccuracy in two dimensional face recognition systems is mainly due to pose variations, occlusions, illumination etc. Among this, changes in illumination condition do not affect 3D face recognition systems. But pose variation drastically changes the appearance of face images. To solve the problems with depth map and texture images corrupted by head pose variations and the occlusions generated due to these pose variations, a reconstruction method is proposed which consist of three stages. In the first stage, the pose correction is done by Iterative Closest Point (ICP) algorithm and in the second stage the occluded region of the face is reconstructed by a resurfacing method called patch cloning. It is followed by the wrapping of reconstructed depth map by its texture to generate a 3D model. The statistical error between the original face and the reconstructed face is also evaluated. In this work, facial symmetry is used as a prior knowledge. Experiments are done with the FRAV3D database. © 2016 IEEE.},
author_keywords={Face recognition;  Face Resurfacing;  ICP algorithm;  Patch Cloning;  Pose Correction},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ramalingam2017,
author={Ramalingam, S. and Maheswari, U.},
title={A fuzzy interval valued fusion technique for multi-modal 3D face recognition},
journal={Proceedings - International Carnahan Conference on Security Technology},
year={2017},
doi={10.1109/CCST.2016.7815709},
art_number={7815709},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011685180&doi=10.1109%2fCCST.2016.7815709&partnerID=40&md5=028f8cd51bd05382872e10cdaf8fcc8a},
affiliation={School of Engineering and Technology, University of Hertfordshire, Hatfield, AL10 9AB, United Kingdom; Department of Mathematics, Kamaraj College of Engineering and Technology, Virudhunagar, India},
abstract={This paper proposes a fuzzy interval valued multicriteria decision making (MCDM) technique that aggregates information from multi-modal feature sets during decision making in a 3D face recognition system. In this paper, an interval valued fuzzy TOPSIS technique is applied to a 3D face recognition system that is benchmarked against a set of databases. Such a system is shown to be useful in decision making when the choice of alternatives of the feature sets is combinatorial and complex. © 2016 IEEE.},
author_keywords={3D Face Recognition;  Disparity Maps;  fuzzy interval MCDM;  Range Data;  TOPSIS},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bobulski201753,
author={Bobulski, J.},
title={Face recognition with 3D face asymmetry},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={525},
pages={53-60},
doi={10.1007/978-3-319-47274-4_6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994876936&doi=10.1007%2f978-3-319-47274-4_6&partnerID=40&md5=c7adf1f39551d024cb6732e2715c3479},
affiliation={Institute of Computer and Information Sciences, Czestochowa University of Technology, Dabrowskiego 73, Czestochowa, 42-200, Poland},
abstract={Using of 3D images for the identification was in a field of the interest of many researchers which developed a few methods offering good results. However, there are few techniques exploiting the 3D asymmetry amongst these methods. We propose fast algorithm for rough extraction face asymmetry that is used to 3D face recognition with hidden Markov models. This paper presents conception of fast method for determine 3D face asymmetry. The research results indicate that face recognition with 3D face asymmetry may be used in biometrics systems. © Springer International Publishing AG 2017.},
author_keywords={Face asymmetry;  Face recognition;  Hidden Markov models;  Identity verification},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hariri2017187,
author={Hariri, W. and Tabia, H. and Farah, N. and Declercq, D. and Benouareth, A.},
title={Geometrical and visual feature quantization for 3D face recognition},
journal={VISIGRAPP 2017 - Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
year={2017},
volume={5},
pages={187-193},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013991858&partnerID=40&md5=fd026eef10dcc4922fe7269db34feb6c},
affiliation={ETIS, ENSEA, University of Cergy-Pontoise, CNRS, UMR 8051, Cergy-Pontoise, France; Labged Laboratory, Computer Science Department, Badji Mokhtar Annaba University, Annaba, Algeria},
abstract={In this paper, we present an efficient method for 3D face recognition based on vector quantization of both geometrical and visual proprieties of the face. The method starts by describing each 3D face using a set of orderless features, and use then the Bag-of-Features paradigm to construct the face signature. We analyze the performance of three well-known classifiers: the Naïve Bayes, the Multilayer perceptron and the Random forests. The results reported on the FRGCv2 dataset show the effectiveness of our approach and prove that the method is robust to facial expression. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Bag-of-Features;  Codebook;  Depth image;  HoS;  LBP;  Term vector},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2017633,
author={Zhang, T. and Mu, Z. and Li, Y. and Liu, Q. and Zhang, Y.},
title={3D face and ear recognition based on partial mars map},
journal={ICPRAM 2017 - Proceedings of the 6th International Conference on Pattern Recognition Applications and Methods},
year={2017},
volume={2017-January},
pages={633-637},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049438191&partnerID=40&md5=142925806e53f82e08f8cdf1fe8539c6},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China},
abstract={This paper proposes a 3D face recognition approach based on facial pose estimation, which is robust to large pose variations in the unconstrained scene. Deep learning method is used to facial pose estimation, and the generation of partial MARS (Multimodal fAce and eaR Spherical) map reduces the probability of feature points appearing in the deformed region. Then we extract the features from the depth and texture maps. Finally, the matching scores from two types of maps should be calculated by Bayes decision to generate the final result. In the large pose variations, the recognition rate of the method in this paper is 94.6%. The experimental results show that our approach has superior performance than the existing methods used on the MARS map, and has potential to deal with 3D face recognition in unconstrained scene. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={3d face recognition;  Deep learning;  Head pose estimation;  Partial mars map},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Deng201713,
author={Deng, X. and Da, F. and Shao, H.},
title={Expression-robust 3D face recognition based on feature-level fusion and feature-region fusion},
journal={Multimedia Tools and Applications},
year={2017},
volume={76},
number={1},
pages={13-31},
doi={10.1007/s11042-015-3012-8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945315051&doi=10.1007%2fs11042-015-3012-8&partnerID=40&md5=5f6b0d57d4d091b3769e974b26751540},
affiliation={Department of Automation, Southeast University, Nanjing, Jiangsu  210096, China; Key Laboratory of Measurement and Control for Complex System of Ministry of Education, Southeast University, Nanjing, Jiangsu  210096, China},
abstract={3D face shape is essentially a non-rigid free-form surface, which will produce non-rigid deformation under expression variations. In terms of that problem, a promising solution named Coherent Point Drift (CPD) non-rigid registration for the non-rigid region is applied to eliminate the influence from the facial expression while guarantees 3D surface topology. In order to take full advantage of the extracted discriminative feature of the whole face under facial expression variations, the novel expression-robust 3D face recognition method using feature-level fusion and feature-region fusion is proposed. Furthermore, the Principal Component Analysis and Linear Discriminant Analysis in combination with Rotated Sparse Regression (PL-RSR) dimensionality reduction method is presented to promote the computational efficiency and provide a solution to the curse of dimensionality problem, which benefit the performance optimization. The experimental evaluation indicates that the proposed strategy has achieved the rank-1 recognition rate of 97.91 % and 96.71 % based on Face Recognition Grand Challenge (FRGC) v2.0 and Bosphorus respectively, which means the proposed approach outperforms state-of-the-art approach. © 2015, Springer Science+Business Media New York.},
author_keywords={3D face recognition;  Dimensionality reduction;  Feature-level fusion;  Feature-region fusion;  Non-rigid point set registration},
document_type={Article},
source={Scopus},
}

@ARTICLE{Keshwani2017333,
author={Keshwani, L. and Pete, D.},
title={Comparative analysis of frontal face recognition using radial curves and back propagation neural network},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={469},
pages={333-344},
doi={10.1007/978-981-10-1678-3_32},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984944723&doi=10.1007%2f978-981-10-1678-3_32&partnerID=40&md5=8786b9edc61be7625d9311c127d87030},
affiliation={Datta Meghe College of Engineering, Airoli, Navi Mumbai, India; Electronics and Telecommunication Department, Datta Meghe College of Engineering, Airoli, Navi Mumbai, India},
abstract={Person identification using face as a cue is one of the most prominent and robust technique. This paper presents 3D face recognition system using Radial curves and Back Propagation Neural Networks (BPNN). The face images used for experimentation are under various challenges like illumination, pose variation, expression and occlusions. The features of images are extracted using Eigen vectors. These features are compared using radial curves on the face starting from center of the face to the end of the face. Each corresponding curve is matched using Euclidean Distance classifier. The BPNN is used to train the features for face matching. The proposed algorithms are tested on ORL and DMCE database. The performance analysis is based on recognition rate accuracy of the system. The proposed radial curve system yields recognition rate accuracy of 100 % for images from the ORL database and 98 % for the images from DMCE database. © Springer Science+Business Media Singapore 2017.},
author_keywords={Back propagation neural networks;  Face recognition;  ORL database;  Radial curves},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tortorici201756,
author={Tortorici, C. and Werghi, N.},
title={Early features fusion over 3D face for face recognition},
journal={Communications in Computer and Information Science},
year={2017},
volume={684},
pages={56-64},
doi={10.1007/978-3-319-60654-5_5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025144868&doi=10.1007%2f978-3-319-60654-5_5&partnerID=40&md5=3b06dd7bdc4134f54389a82b8b2fcda0},
affiliation={Khalifa University, Abu Dhabi, United Arab Emirates},
abstract={In this paper, a novel approach for fusing shape and texture Local Binary Patterns (LBP) for 3D Face Recognition is presented. Using the recently proposed mesh-LBP [23], it is now possible to compute LBP directly on a mesh manifold, allowing Early Feature Fusion to enhance face description power. Compared to its depth image counterparts, the proposed method (a) inherits the intrinsic advantages of mesh surfaces, (such as preservation of full geometry), (b) does not require face registration, (c) can accommodate partial or rotation matching, and (d) natively allows early-level fusion of texture and shape descriptors. The advantages of early-fusion is presented together with an experimentation of two merging schemes tested on the Bosphorus database. © Springer International Publishing AG 2017.},
author_keywords={3D face recognition;  Early feature-fusion;  LBP;  Local Binary Pattern},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{SilvaMata20173,
author={Silva Mata, F.J. and Castellanos, E.G. and Muñoz-Briseño, A. and Talavera-Bustamante, I. and Berretti, S.},
title={3D Face Recognition in Continuous Spaces},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10485 LNCS},
pages={3-13},
doi={10.1007/978-3-319-68548-9_1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032464388&doi=10.1007%2f978-3-319-68548-9_1&partnerID=40&md5=4288e99914c770d9d22c7b028ccbc05a},
affiliation={CENATAV, Havana, Cuba; University of Florence, Florence, Italy},
abstract={This work introduces a new approach for face recognition based on 3D scans. The main idea of the proposed method is that of converting the 3D face scans into a functional representation, performing all the subsequent processing in the continuous space. To this end, a model alignment problem is first solved by combining graph matching and clustering. Fiducial points of the face are initially detected by analysis of continuous functions computed on the surface. Then, the alignment is performed by transforming the geometric graphs whose nodes are the critical points of the representative function of the surface in previously determined subspaces. A clustering step is finally applied to correct small displacement in the models. The 3D face representation is then obtained on the aligned models by functions carefully selected according to mathematical and computational criteria. In particular, the face is divided into regions, which are treated as independent domains where a set of functions is determined by fitting the surface data using the least squares method. Experimental results demonstrate the feasibility of the method. © 2017, Springer International Publishing AG.},
author_keywords={3D face recognition;  Functional representation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tang201741,
author={Tang, Y. and Chen, L.},
title={Shape analysis based anti-spoofing 3D face recognition with mask attacks},
journal={Communications in Computer and Information Science},
year={2017},
volume={684},
pages={41-55},
doi={10.1007/978-3-319-60654-5_4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025122871&doi=10.1007%2f978-3-319-60654-5_4&partnerID=40&md5=ee21d18278533c54c55ae227daf6a772},
affiliation={Université de Lyon, Ecole Centrale de Lyon, LIRIS laboratory, UMR CNRS 5205, Lyon, 69134, France},
abstract={With the growth of face recognition, the spoofing mask attacks attract more attention in biometrics research area. In recent years, the countermeasures based on the texture and depth image against spoofing mask attacks have been reported, but the research based on 3D meshed sample has not been studied yet. In this paper, we propose to apply 3D shape analysis based on principal curvature measures to describe the meshed facial surface. Meanwhile, a verification protocol based on this feature descriptor is designed to verify person identity and to evaluate the anti-spoofing performance on Morpho database. Furthermore, for simulating a real-life testing scenario, FRGCv2 database is enrolled as an extension of face scans to augment the ratio of genuine face samples to fraud mask samples. The experimental results show that our system can guarantee a high verification rate for genuine faces and the satisfactory anti-spoofing performance against spoofing mask attacks in parallel. © Springer International Publishing AG 2017.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wei201766,
author={Wei, X. and Li, H. and Gu, X.D.},
title={Three Dimensional Face Recognition via Surface Harmonic Mapping and Deep Learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10568 LNCS},
pages={66-76},
doi={10.1007/978-3-319-69923-3_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032656852&doi=10.1007%2f978-3-319-69923-3_8&partnerID=40&md5=598d2aabb96d1b2d7f9963542a2fcddf},
affiliation={School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science and Department of Mathematics, State University of New York at Stony Brook, New York, United States},
abstract={In this paper, we propose a general 3D face recognition framework by combining the idea of surface harmonic mapping and deep learning. In particular, given a 3D face scan, we first run the pre-processing pipeline and detect three main facial landmarks (i.e., nose tip and two inner eye corners). Then, harmonic mapping is employed to map the 3D coordinates and differential geometry quantities (e.g., normal vectors, curvatures) of each 3D face scan to a 2D unit disc domain, generating a group of 2D harmonic shape images (HSI). The 2D rotation of the harmonic shape images are removed by using the three detected landmarks. All these pose normalized harmonic shape images are fed into a pre-trained deep convolutional neural network (DCNN) to generate their deep representations. Finally, sparse representation classifier with score-level fusion is used for face similarity measurement and the final decision. The advantage of our method is twofold: (i) it is a general framework and can be easily extended to other surface mapping and deep learning algorithms. (ii) it is registration-free and only needs three landmarks. The effectiveness of the proposed framework was demonstrated on the BU-3DFE database, and reporting a rank-one recognition rate of 89.38% on the whole database. © 2017, Springer International Publishing AG.},
author_keywords={3D face recognition;  Deep learning;  Surface harmonic mapping},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2017105,
author={Lee, D. and Krim, H.},
title={3D face recognition in the Fourier domain using deformed circular curves},
journal={Multidimensional Systems and Signal Processing},
year={2017},
volume={28},
number={1},
pages={105-127},
doi={10.1007/s11045-015-0334-7},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931003254&doi=10.1007%2fs11045-015-0334-7&partnerID=40&md5=e10f2e06f41d7b10795343f6f7dad231},
affiliation={Division of Mobile Communications, Samsung Electronics Co. Ltd, Suwon, Gyeonggi, South Korea; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC  27695, United States},
abstract={One of the most significant problems in image and vision applications is the efficient representation of a target image containing a large amount of data with high complexity. The ability to analyze high dimensional signals in a lower dimension without losing their information, has been crucial in the field of image processing. This paper proposes an approach to 3D face recognition using dimensionality reduction based on deformed circular curves, on the shortest geodesic distances, and on the properties of the Fourier Transform. Measured geodesic distances information generates a matrix whose entities are geodesic distances between the reference point and an arbitrary point on a 3D object, and an one-dimensional vector is generated by reshaping the matrix without losing the original properties of the target object. Following the property of the Fourier Transform, symmetry of the magnitude response, the original signal can be analyzed in the lower dimensional space without loss of inherent characteristics. This paper mainly deal with the efficient representation and recognition algorithm using deformed circular curves and the simulation shows promising result for recognition of geometric face information. © 2015, Springer Science+Business Media New York.},
author_keywords={Classification;  Deformed circular curves;  Dimensionality reduction;  Face recognition;  Fourier Transform;  Geodesic distance},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pitteri2017925,
author={Pitteri, G. and Munaro, M. and Menegatti, E.},
title={Depth-based frontal view generation for pose invariant face recognition with consumer RGB-D sensors},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={531},
pages={925-937},
doi={10.1007/978-3-319-48036-7_67},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013040754&doi=10.1007%2f978-3-319-48036-7_67&partnerID=40&md5=9cd77bba58f0cd9c12593505c307634b},
affiliation={Department of Information Engineering, University of Padova, Via Gradenigo 6/A, Padova, 35131, Italy},
abstract={In this work, we propose to exploit depth information to build a pose-invariant face recognition algorithm from RGB-D data. Our approach first estimates the head pose and then generates a frontal view for those faces that are rotated with respect to the frame of the camera. Then, some interest points of the face are detected by means of a Random Forest applied to the RGB image and they are used as keypoints where to compute feature descriptors. Around these points and their 3D counterpart, we extract both 2D and 3D local descriptors, which are then concatenated and classified by means of a Support Vector Machine trained in “one-versus-all” fashion. In order to validate the accuracy of the system with data from consumer RGB-D sensors, we created the IAS-Lab RGB-D Face Dataset, a new public dataset in which RGB-D data are acquired with a second generation Microsoft Kinect. The reported experiments show that the depth-aided approach we propose allows to improve the recognition rate up to 50 %. © Springer International Publishing AG 2017.},
author_keywords={3D face recognition;  Frontalization;  Pose-invariance;  RGB-D},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yu2016,
author={Yu, X. and Gao, Y. and Zhou, J.},
title={Boosting Radial Strings for 3D Face Recognition with Expressions and Occlusions},
journal={2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016},
year={2016},
doi={10.1109/DICTA.2016.7797014},
art_number={7797014},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011088593&doi=10.1109%2fDICTA.2016.7797014&partnerID=40&md5=b22aac1e03b48565af8c230b46a10822},
affiliation={School of Engineering, Griffith University, Nathan, QLD, Australia; School of Information and Communication Technology, Griffith University, Nathan, QLD, Australia},
abstract={In this paper, we present a new radial string representation and matching approach for 3D face recognition under expression variations and partial occlusions. The radial strings are an indexed collection of strings emanating from the nose tip of a face scan. The matching between two radial strings is conducted through a dynamic programming process, in which a partial matching mechanism is established to effectively find those un-occluded substrings. Moreover, the most discriminative and stable radial strings are selected optimally by the well-known AdaBoost algorithm to achieve a composite classifier for 3D face recognition under facial expression changes. Experimental results on the GavabDB and the Bosphorus databases show that the proposed approach achieves promising results for human face recognition with expressions and occlusions. © 2016 IEEE.},
author_keywords={face recognition;  facial curves;  feature selection;  machine learning;  string matching},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gilani2016,
author={Gilani, S.Z. and Mian, A.},
title={Towards Large-Scale 3D Face Recognition},
journal={2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016},
year={2016},
doi={10.1109/DICTA.2016.7797090},
art_number={7797090},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011072173&doi=10.1109%2fDICTA.2016.7797090&partnerID=40&md5=8e7de072eb2e5794e1830d7699cecbb6},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, Australia},
abstract={3D face recognition holds great promise in achieving robustness to pose, expressions and occlusions. However, 3D face recognition algorithms are still far behind their 2D counterparts due to the lack of large-scale datasets. We present a model based algorithm for 3D face recognition and test its performance by combining two large public datasets of 3D faces. We propose a Fully Convolutional Deep Network (FCDN) to initialize our algorithm. Reliable seed points are then extracted from each 3D face by evolving level set curves with a single curvature dependent adaptive speed function. We then establish dense correspondence between the faces in the training set by matching the surface around the seed points on a template face to the ones on the target faces. A morphable model is then fitted to probe faces and face recognition is performed by matching the parameters of the probe and gallery faces. Our algorithm achieves state of the art landmark localization results. Face recognition results on the combined FRGCv2 and Bosphorus datasets show that our method is effective in recognizing query faces with real world variations in pose and expression, and with occlusion and missing data despite a huge gallery. Comparing results of individual and combined datasets show that the recognition accuracy drops when the size of the gallery increases. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Manjani2016,
author={Manjani, I. and Sumerkan, H. and Flynn, P.J. and Bowyer, K.W.},
title={Template aging in 3D and 2D face recognition},
journal={2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems, BTAS 2016},
year={2016},
doi={10.1109/BTAS.2016.7791202},
art_number={7791202},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011292291&doi=10.1109%2fBTAS.2016.7791202&partnerID=40&md5=489de6a99b54a846a691ee770e40a082},
affiliation={Department of Computer Science and Engineering, IIIT-Delhi, Delhi, 110020, India; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN  46556, United States},
abstract={This is the first work to explore template aging in 3D face recognition. We use a dataset of images representing 16 subjects with 3D and 2D face images, and compare short-term and long-term time-lapse matching accuracy. We find that an ensemble-of-regions approach to 3D face matching has much greater accuracy than whole-face 3D matching, or than a commercial 2D matcher. We observe a drop in accuracies with increased time lapse, most with whole-face 3D matching followed by 2D matching and the 3D ensemble of regions approach. Finally, we determine whether the difference in match quality arising with an increased time lapse is statistically significant. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Das2016243,
author={Das, N. and Mandal, D. and Biswas, S.},
title={Simultaneous Semi-Coupled Dictionary Learning for Matching RGBD Data},
journal={IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
year={2016},
pages={243-251},
doi={10.1109/CVPRW.2016.37},
art_number={7789527},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010203549&doi=10.1109%2fCVPRW.2016.37&partnerID=40&md5=aa825a3ef4e099d932800d5621327839},
affiliation={Indian Institute of Science, Bangalore, India},
abstract={Matching with hidden information which is available only during training and not during testing has recently become an important research problem. Matching data from two different modalities, known as cross-modal matching is another challenging problem due to the large variations in the data coming from different modalities. Often, these are treated as two independent problems. But for applications like matching RGBD data, when only one modality is available during testing, it can reduce to either of the two problems. In this work, we propose a framework which can handle both these scenarios seamlessly with applications to matching RGBD data of Lambertian objects. The proposed approach jointly uses the RGB and depth data to learn an illumination invariant canonical version of the objects. Dictionaries are learnt for the RGB, depth and the canonical data, such that the transformed sparse coefficients of the RGB and the depth data is equal to that of the canonical data. Given RGB or depth data, their sparse coefficients corresponding to their canonical version is computed which can be directly used for matching using a Mahalanobis metric. Extensive experiments on three datasets, EURECOM, VAP RGB-D-T and Texas 3D Face Recognition database show the effectiveness of the proposed framework. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shah2016,
author={Shah, S.A.A. and Bennamoun, M. and Boussaid, F.},
title={Automatic 3D face landmark localization based on 3D vector field analysis},
journal={International Conference Image and Vision Computing New Zealand},
year={2016},
volume={2016-November},
doi={10.1109/IVCNZ.2015.7761526},
art_number={7761526},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006942604&doi=10.1109%2fIVCNZ.2015.7761526&partnerID=40&md5=5da7d80624be2691571e8fafab5b9dbf},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Perth, Australia; School of Electrical, Electronic and Computer Engineering, University of Western Australia, 35 Stirling Highway, Perth, WA, Australia},
abstract={In applications such as 3D face synthesis and animation, a prominent face landmark is required to enable 3D face normalization, pose correction, 3D face recognition and reconstruction. Due to variations in facial expressions, automatic 3D face landmark localization remains a challenge. Nose tip is one of the salient landmarks in a human face. In this paper, a novel nose tip localization technique is proposed. In the proposed approach, the rotation of the 3D vector field is analyzed for robust and efficient nose tip localization. The proposed technique has the following three characteristics: (1) it does not require any training; (2) it does not rely on any particular model; (3) it is very efficient, requiring an average time of only 1.9s for nose tip detection. We tested the proposed technique on BU3DFE and Shrec'10 datasets. Experimental results show that the proposed technique is robust to variations in facial expressions, achieving a 100% detection rate on these publicly available 3D face datasets. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li201693,
author={Li, B.Y.L. and Xue, M. and Mian, A. and Liu, W. and Krishna, A.},
title={Robust RGB-D face recognition using Kinect sensor},
journal={Neurocomputing},
year={2016},
volume={214},
pages={93-108},
doi={10.1016/j.neucom.2016.06.012},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977478475&doi=10.1016%2fj.neucom.2016.06.012&partnerID=40&md5=df18014ab4a68d40273fdbb72a7a85ae},
affiliation={Department of Computing, Curtin University, Kent Street, Perth, WA  6102, Australia; Dalian Key Lab of Digital Technology for National Culture, Dalian Minzu University, Liaoning, Dalian  116600, China; Computer Science and Software Engineering, The University of Western Australia, 35 Stirling Highway, Crawley, WA  6009, Australia},
abstract={In this paper we propose a robust face recognition algorithm for low resolution RGB-D Kinect data. Many techniques are proposed for image preprocessing due to the noisy depth data. First, facial symmetry is exploited based on the 3D point cloud to obtain a canonical frontal view image irrespective of the initial pose and then depth data is converted to XYZ normal maps. Secondly, multi-channel Discriminant Transforms are then used to project RGB to DCS (Discriminant Color Space) and normal maps to DNM (Discriminant Normal Maps). Finally, a Multi-channel Robust Sparse Coding method is proposed that codes the multiple channels (DCS or DNM) of a test image as a sparse combination of training samples with different pixel weighting. Weights are calculated dynamically in an iterative process to achieve robustness against variations in pose, illumination, facial expressions and disguise. In contrast to existing techniques, our multi-channel approach is more robust to variations. Reconstruction errors of the test image (DCS and DNM) are normalized and fused to decide its identity. The proposed algorithm is evaluated on four public databases. It achieves 98.4% identification rate on CurtinFaces, a Kinect database with 4784 RGB-D images of 52 subjects. Using a first versus all protocol on the Bosphorus, CASIA and FRGC v2 databases, the proposed algorithm achieves 97.6%, 95.6% and 95.2% identification rates respectively. To the best of our knowledge, these are the highest identification rates reported so far for the first three databases. © 2016 Elsevier B.V.},
author_keywords={3D face recognition;  Kinect;  Multi-channel discriminant transform;  Sparse coding},
document_type={Article},
source={Scopus},
}

@ARTICLE{Guo2016403,
author={Guo, Y. and Lei, Y. and Liu, L. and Wang, Y. and Bennamoun, M. and Sohel, F.},
title={EI3D: Expression-invariant 3D face recognition based on feature and shape matching},
journal={Pattern Recognition Letters},
year={2016},
volume={83},
pages={403-412},
doi={10.1016/j.patrec.2016.04.003},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966659227&doi=10.1016%2fj.patrec.2016.04.003&partnerID=40&md5=b09b19b7a5436b53278c02d001e93910},
affiliation={College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan  410073, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan  610065, China; College of Information System and Management, National University of Defense Technology, Changsha, Hunan  410073, China; College of Computer Science, Sichuan University, Chengdu, Sichuan, China; School of Computer Science and Software Engineering, The University of Western Australia, Perth, WA  6009, Australia; School of Engineering and Information Technology, Murdoch University, Perth, WA  6150, Australia},
abstract={This paper presents a local feature based shape matching algorithm for expression-invariant 3D face recognition. Each 3D face is first automatically detected from a raw 3D data and normalized to achieve pose invariance. The 3D face is then represented by a set of keypoints and their associated local feature descriptors to achieve robustness to expression variations. During face recognition, a probe face is compared against each gallery face using both local feature matching and 3D point cloud registration. The number of feature matches, the average distance of matched features, and the number of closest point pairs after registration are used to measure the similarity between two 3D faces. These similarity metrics are then fused to obtain the final results. The proposed algorithm has been tested on the FRGC v2 benchmark and a high recognition performance has been achieved. It obtained the state-of-the-art results by achieving an overall rank-1 identification rate of 97.0% and an average verification rate of 99.01% at 0.001 false acceptance rate for all faces with neutral and non-neutral expressions. Further, the robustness of our algorithm under different occlusions has been demonstrated on the Bosphorus dataset. © 2016 Elsevier B.V.},
author_keywords={3D face recognition;  Face identification;  Facial expression;  Keypoint detection;  Local feature;  Shape matching},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lei2016994,
author={Lei, Y. and Feng, S. and Zhou, X. and Guo, Y.},
title={An efficient 3D partial face recognition approach with single sample},
journal={Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016},
year={2016},
pages={994-999},
doi={10.1109/ICIEA.2016.7603727},
art_number={7603727},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997335714&doi=10.1109%2fICIEA.2016.7603727&partnerID=40&md5=05e7f7f4b11d4caaaace67a1698a150c},
affiliation={College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan, 610065, China; College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, 410073, China},
abstract={3D partial face recognition under missing parts, occlusions and data corruptions is a major challenge for the practical application of the techniques of 3D face recognition. Moreover, one individual can only provide one sample for training in most practical scenarios, and thus the face recognition with single sample problem is another highly challenging task. We propose an efficient framework for 3D partial face recognition with single sample addressing both of the two problems. First, we represent a facial scan with a set of keypoint based local geometrical descriptors, which gains sufficient robustness to partial facial data along with expression/pose variations. Then, a two-step modified collaborative representation classification scheme is proposed to address the single sample recognition problem. A class-based probability estimation is given during the first classification step, and the obtained result is then incorporated into the modified collaborative representation classification as a locality constraint to improve its classification performance. Extensive experiments on the Bosphorus and FRGC v2.0 datasets demonstrate the efficiency of the proposed approach when addressing the problem of 3D partial face recognition with single sample. © 2016 IEEE.},
author_keywords={3D facial representation;  3D partial face recognition;  collaborative representation;  locality constraint;  single sample problem},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2016663,
author={Zhang, J. and Hou, Z. and Wu, Z. and Chen, Y. and Li, W.},
title={Research of 3D face recognition algorithm based on deep learning stacked denoising autoencoder theory},
journal={Proceedings of 2016 8th IEEE International Conference on Communication Software and Networks, ICCSN 2016},
year={2016},
pages={663-667},
doi={10.1109/ICCSN.2016.7586606},
art_number={7586606},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994495941&doi=10.1109%2fICCSN.2016.7586606&partnerID=40&md5=9eed5623ef21575da3fdcb6dfd818fc2},
affiliation={College of Information, Mathematics and Physics, Changzhou University, Changzhou, China},
abstract={This electronic Due to the fact that the 3D face depth data have more information, the 3D face recognition is attracting more and more attention in the machine learning area. Firstly, this paper selects 30 feature points from the 113 feature points of Candide-3 face model to characterize face, which improves the efficiency of recognition algorithm obviously without affecting the recognition accuracy. With the significant advantage of the characterization of essential features by learning a deep nonlinear network, this paper presents a stacked denoising autoencoder algorithm model based on deep learning which improves neural networks model. This algorithm conducts the unsupervised preliminary training of face depth data and the supervised training to fine-tuning the network which is better than neural network's random initialization. The experiment indicates that compared with real face data, the reconstruction face model has a small matching error by using SDAE algorithm and it achieves an excellent face recognition effect. © 2016 IEEE.},
author_keywords={3D face depth data;  deep learning;  neural networks;  stacked denoising autoencoder;  unsupervised preliminary training},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Ganguly2016933,
author={Ganguly, S. and Bhattacharjee, D. and Nasipuri, M.},
title={3D image acquisition and analysis of range face images for registration and recognition},
journal={Biometrics: Concepts, Methodologies, Tools, and Applications},
year={2016},
pages={933-968},
doi={10.4018/978-1-5225-0983-7.ch037},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015971759&doi=10.4018%2f978-1-5225-0983-7.ch037&partnerID=40&md5=8615e03e322fd512c4ff348631cff16a},
affiliation={Jadavpur University, India},
abstract={Although, automatic face recognition has been studied for more than four decades; there are still some challenging issues due to different variations in face images. There are mainly two categories of face recognition based on acquisition procedure. One technology that deals with video based face recognition and another approach where different sensors are used for acquisition purpose of different stationary face images, for instance: optical image, infra-red image and 3D image. In this context, researchers have focused only on 3D face images. 3D face images convey a series of advantages over 2D i.e. video frame, optical as well as infra-red face images. In this chapter, a detailed study of acquisition, visualization, detail about 3D images, analyzing it with some fundamental image processing techniques and application in the field of biometric through face registration and recognition are discussed. This chapter also gives a brief idea of the state of the art about the research methodologies of 3D face recognition and its applications. © 2017, IGI Global. All rights reserved.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Zhang2016,
author={Zhang, J. and Huang, D. and Wang, Y. and Sun, J.},
title={Lock3DFace: A large-scale database of low-cost Kinect 3D faces},
journal={2016 International Conference on Biometrics, ICB 2016},
year={2016},
doi={10.1109/ICB.2016.7550062},
art_number={7550062},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988432113&doi=10.1109%2fICB.2016.7550062&partnerID=40&md5=b25394bb9ffda22d92409c2cd0a74cfa},
affiliation={IRIP Lab, School of Computer Science and Engineering, Beihang University, Beijing, 100191, China},
abstract={In this paper, we present a large-scale database consisting of low cost Kinect 3D face videos, namely Lock3DFace, for 3D face analysis, particularly for 3D Face Recognition (FR). To the best of our knowledge, Lock3DFace is currently the largest low cost 3D face database for public academic use. The 3D samples are highly noisy and contain a diversity of variations in expression, pose, occlusion, time lapse, and their corresponding texture and near infrared channels have changes in lighting condition and radiation intensity, allowing for evaluating FR methods in complex situations. Furthermore, based on Lock3DFace, we design the standard experimental protocol for low-cost 3D FR, and give the baseline performance of individual subsets belonging to different scenarios for fair comparison in the future. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kim20163011,
author={Kim, D. and Choi, J. and Leksut, J.T. and Medioni, G.},
title={Accurate 3D face modeling and recognition from RGB-D stream in the presence of large pose changes},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2016},
volume={2016-August},
pages={3011-3015},
doi={10.1109/ICIP.2016.7532912},
art_number={7532912},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006789474&doi=10.1109%2fICIP.2016.7532912&partnerID=40&md5=132fb651cb89c0d50239c14c3a7104ae},
affiliation={Institute for Robotics and Intelligent Systems, University of Southern California, 3737 Watt way PHE 101, Los Angeles, CA  90089, United States},
abstract={We propose a 3D face modeling and recognition system using an RGB-D stream in the presence of large pose changes. In the previous work, all facial data points are registered with a reference to improve the accuracy of 3D face model from a low-resolution depth sequence. This registration often fails when applied to non-frontal faces. It causes inaccurate 3D face models and poor performance of matching. We address this problem by pre-aligning each input face ('frontalization') before the registration, which avoids registration failures. For each frame, our method estimates the 3D face pose, assesses the quality of data, segments the facial region, frontalizes it, and performs an accurate registration with the previous 3D model. The 3D-3D recognition system using accurate 3D models from our method outperforms other face recognition systems and shows 100% rank 1 recognition accuracy on a dataset with 30 subjects. © 2016 IEEE.},
author_keywords={3D Face Modeling;  3D Face Recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yu20163016,
author={Yu, X. and Gao, Y. and Zhou, J.},
title={3D face recognition under partial occlusions using radial strings},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2016},
volume={2016-August},
pages={3016-3020},
doi={10.1109/ICIP.2016.7532913},
art_number={7532913},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006713653&doi=10.1109%2fICIP.2016.7532913&partnerID=40&md5=dd468caaf8cc8593dad5e05e0c040b9c},
affiliation={School of Engineering, Griffith University, Nathan, QLD, Australia; School of Information and Communication Technology, Griffith University, Nathan, QLD, Australia},
abstract={3D face recognition with partial occlusions is a highly challenging problem. In this paper, we propose a novel radial string representation and matching approach to recognize 3D facial scans in the presence of partial occlusions. Here we encode 3D facial surfaces into an indexed collection of radial strings emanating from the nosetips and Dynamic Programming (DP) is then used to measure the similarity between two radial strings. In order to address the recognition problems with partial occlusions, a partial matching mechanism is established in our approach that effectively eliminates those occluded parts and finds the most discriminative parts during the matching process. Experimental results on the Bosphorus database demonstrate that the proposed approach yields superior performance on partially occluded data. © 2016 IEEE.},
author_keywords={3D face recognition;  Partial occlusions;  Radial string matching;  Structural recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Torkhani2016447,
author={Torkhani, G. and Ladgham, A. and Mansouri, M.N. and Sakly, A.},
title={Gabor-SVM applied to 3D-2D deformed mesh model},
journal={2nd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2016},
year={2016},
pages={447-452},
doi={10.1109/ATSIP.2016.7523133},
art_number={7523133},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984607903&doi=10.1109%2fATSIP.2016.7523133&partnerID=40&md5=a94aa03e640ea81c789823dfdf4c35ed},
affiliation={CSR Research Unit, E e Laboratory, National School of Engineering, Ibn Eljazzar, Monastir, 5019, Tunisia; Electrical Departement, National School of Engineering, Ibn Eljazzar, Monastir, 5019, Tunisia},
abstract={We propose a robust method for 3D face recognition using 3D to 2D modeling and facial curvatures detection. The 3D-2D algorithm permits to transform 3D images into 3D triangular mesh, then the mesh model is deformed and fitted to the 2D space in order to obtain a 2D smoother mesh. Then, we apply Gabor wavelets to the deformed model in order to exploit surface curves in the detection of salient face features. The classification of the final Gabor facial model is performed using the support vector machines (SVM). To demonstrate the quality of our technique, we give some experiments using the 3D AJMAL faces database. The experimental results prove that the proposed method is able to give a good recognition quality and a high accuracy rate. © 2016 IEEE.},
author_keywords={3D face recognition;  deformed mesh model;  facial curvatures;  Gabor wavelet;  salient points;  SVM},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hariri20161,
author={Hariri, W. and Tabia, H. and Farah, N. and Benouareth, A. and Declercq, D.},
title={3D face recognition using covariance based descriptors},
journal={Pattern Recognition Letters},
year={2016},
volume={78},
pages={1-7},
doi={10.1016/j.patrec.2016.03.028},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964930100&doi=10.1016%2fj.patrec.2016.03.028&partnerID=40&md5=bca65280157410a38ef712a15de825bc},
affiliation={ETIS, ENSEA, Univ Cergy-Pontoise, CNRS, UMR-8051, Cergy-Pontoise Cedex, 95014, France; Labged Laboratory, Computer Science Department, Badji Mokhtar Annaba University, B.P.12, Annaba, 23000, Algeria},
abstract={In this paper, we propose a new 3D face recognition method based on covariance descriptors. Unlike feature-based vectors, covariance-based descriptors enable the fusion and the encoding of different types of features and modalities into a compact representation. The covariance descriptors are symmetric positive definite matrices which can be viewed as an inner product on the tangent space of (Symd+) the manifold of Symmetric Positive Definite (SPD) matrices. In this article, we study geodesic distances on the Symd+ manifold and use them as metrics for 3D face matching and recognition. We evaluate the performance of the proposed method on the FRGCv2 and the GAVAB databases and demonstrate its superiority compared to other state of the art methods. © 2016 Elsevier B.V. All rights reserved.},
author_keywords={Covariance matrix;  Face matching;  Geodesic distances},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ratyal2016294,
author={Ratyal, N.I. and Taj, I.A. and Bajwa, U.I. and Sajid, M. and Baig, M.J.A. and Butt, F.M.},
title={3D face recognition based on region ensemble and hybrid features},
journal={2016 International Conference on Computing, Electronic and Electrical Engineering, ICE Cube 2016 - Proceedings},
year={2016},
pages={294-300},
doi={10.1109/ICECUBE.2016.7495241},
art_number={7495241},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979619459&doi=10.1109%2fICECUBE.2016.7495241&partnerID=40&md5=92ad69daeb0afd442983127ab6cf1e01},
affiliation={Electrical Engineering Department, Vision and Pattern Recognition Systems Research Group, Capital University of Science and Technology, Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan; Electrical (Power) Engineering Department, Mirpur University of Science and Technology (AJK), Pakistan; Electrical Engineering Department, University of Azad Jammu and Kashmir, Muzaffarabad (AJK), Pakistan},
abstract={In this paper, we present a novel pose and expression invariant 3D face recognition approach based on intrinsic coordinate system (ICS) alignment. Motivated by the fact that a single classifier cannot be generally efficient against all face regions, a two tier region ensemble based classification approach is presented which employs three parallel face recognition algorithms using Mahalanobis Cosine (MahCos) matching score. The parallel face recognition algorithms employ Principal Component Analysis (PCA) based holistic features, Local Binary Patterns (LBP) based local features and modified Borda Count (MBC) based fusion technique respectively to classify the face images. The results obtained from the parallel algorithms are combined using an exponential rank reordering approach. The performance of the proposed methodology is corroborated by extensive experiments performed on FRGC v2.0 3D database. The results confirm that fusion strategies can be effectively used to construct a single classifier for improved performance. © 2016 IEEE.},
author_keywords={3D face recognition;  FRGC v2.0;  fusion;  region ensemble},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Galbally201683,
author={Galbally, J. and Satta, R.},
title={Three-dimensional and two-and-a-halfdimensional face recognition spoofing using three-dimensional printed models},
journal={IET Biometrics},
year={2016},
volume={5},
number={2},
pages={83-91},
doi={10.1049/iet-bmt.2014.0075},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971441283&doi=10.1049%2fiet-bmt.2014.0075&partnerID=40&md5=428d278db100f600f4c059cb0568c416},
affiliation={European Commission, Joint Research Centre (JRC), Institute for Protection and Security of Citizen (IPSC), via Enrico Fermi 2749, Ispra, VA  21027, Italy},
abstract={The vulnerability of biometric systems to external attacks using a physical artefact in order to impersonate the legitimate user has become a major concern over the last decade. Such a threat, commonly known as 'spoofing', poses a serious risk to the integrity of biometric systems. The usual low-complexity and low-cost characteristics of these attacks make them accessible to the general public, rendering each user a potential intruder. The present study addresses the spoofing issue analysing the feasibility to perform low-cost attacks with self-manufactured three-dimensional (3D) printed models to 2.5D and 3D face recognition systems. A new database with 2D, 2.5D and 3D real and fake data from 26 subjects was acquired for the experiments. Results showed the high vulnerability of the three tested systems, including a commercial solution, to the attacks. © The Institution of Engineering and Technology 2016.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Werghi2016964,
author={Werghi, N. and Tortorici, C. and Berretti, S. and Del Bimbo, A.},
title={Boosting 3D LBP-Based Face Recognition by Fusing Shape and Texture Descriptors on the Mesh},
journal={IEEE Transactions on Information Forensics and Security},
year={2016},
volume={11},
number={5},
pages={964-979},
doi={10.1109/TIFS.2016.2515505},
art_number={7373633},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963974403&doi=10.1109%2fTIFS.2016.2515505&partnerID=40&md5=376f43714248cb873d28dcb663ac1bb5},
affiliation={Electrical and Computer Engineering Department, Khalifa University, Abu Dhabi, 127788, United Arab Emirates; Department of Information Engineering, University of Florence, Florence, 50139, Italy},
abstract={In this paper, we present a novel approach for fusing shape and texture local binary patterns (LBPs) on a mesh for 3D face recognition. Using a recently proposed framework, we compute LBP directly on the face mesh surface, then we construct a grid of the regions on the facial surface that can accommodate global and partial descriptions. Compared with its depth-image counterpart, our approach is distinguished by the following features: 1) inherits the intrinsic advantages of mesh surface (e.g., preservation of the full geometry); 2) does not require normalization; and 3) can accommodate partial matching. In addition, it allows early level fusion of texture and shape modalities. Through experiments conducted on the BU-3DFE and Bosphorus databases, we assess different variants of our approach with regard to facial expressions and missing data, also in comparison to the state-of-the-art solutions. © 2016 IEEE.},
author_keywords={3D face recognition;  feature and score fusion;  mesh-LBP},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Sun2016,
author={Sun, Y.},
title={Expression invariant 3D face recognition based on GMDS},
journal={2015 10th International Conference on Information, Communications and Signal Processing, ICICS 2015},
year={2016},
doi={10.1109/ICICS.2015.7459832},
art_number={7459832},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973640839&doi=10.1109%2fICICS.2015.7459832&partnerID=40&md5=e564c632dda19325c177c7574b194f1b},
affiliation={School of Information Engineering, Guangdong University of Technology, Guangzhou, China},
abstract={In this paper, we propose an efficient expression-invariant 3D face recognition algorithm to compute the minimum-distortion mapping between two 3D face by the Generalized MultiDimensional Scaling (GMDS). Both full and partial parts matching are computed for finding the least distortion embedding of one 3D face into another during GMDS. The problem of expression-invariant three-dimensional face recognition turns to be isometry-invariant matching of surfaces by the means of GMDS. The FRGC v2.0 dataset is conducted for covering face recognition under expression changes. The experimental results demonstrate that the proposed method provides a very encouraging new solution for 3D face recognition. © 2015 IEEE.},
author_keywords={3D face recognition;  Generalized MultiDimensional Scaling(GMDS)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ganguly2016275,
author={Ganguly, S. and Bhattachaijee, D. and Nasipuri, M.},
title={3D face recognition from complement component range face images},
journal={2015 IEEE International Conference on Computer Graphics, Vision and Information Security, CGVIS 2015},
year={2016},
pages={275-278},
doi={10.1109/CGVIS.2015.7449936},
art_number={7449936},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966632732&doi=10.1109%2fCGVIS.2015.7449936&partnerID=40&md5=ac5698f1d98fa8b29941ffc837f84a7b},
affiliation={Department of Computer Science and Engineering, Jadavpur University, Kolkata-32, India},
abstract={Face and facial attributes represent meaningful definition about a variety of information to discriminate an individual from others and for developing a computational model for automatic face recognition purpose. However, in this work, selection of relevant features from newly created face space is the pivotal contribution of the authors. Here, authors have demonstrated a new face space 'Complement Component' that have been used to extract the four basic components along X, and Y axes in four directions. Later, authors have experimented the discriminative attributes from these face spaces for recognition purpose. Here, comparison of the proposed method has been reported by examining its success on two well accepted 3D face databases, namely: Frav3D and Texas3D. In case of 2D face images, it does not contain depth like information i.e. Z-values in X-Y plane through intensity values. Therefore, it has not been undertaken during this investigation. © 2015 IEEE.},
author_keywords={3D face image;  Complement Component;  Face recognition;  range face image},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lei2016218,
author={Lei, Y. and Guo, Y. and Hayat, M. and Bennamoun, M. and Zhou, X.},
title={A Two-Phase Weighted Collaborative Representation for 3D partial face recognition with single sample},
journal={Pattern Recognition},
year={2016},
volume={52},
pages={218-237},
doi={10.1016/j.patcog.2015.09.035},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947306090&doi=10.1016%2fj.patcog.2015.09.035&partnerID=40&md5=50ca73115b78f6746739042c1f293a0e},
affiliation={College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan, China; College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China; School of Computer Science and Software Engineering, University of Western Australia, Crawley, WA, Australia; IBM Research Australia, Carlton, VIC, Australia},
abstract={3D face recognition with the availability of only partial data (missing parts, occlusions and data corruptions) and single training sample is a highly challenging task. This paper presents an efficient 3D face recognition approach to address this challenge. We represent a facial scan with a set of local Keypoint-based Multiple Triangle Statistics (KMTS), which is robust to partial facial data, large facial expressions and pose variations. To address the single sample problem, we then propose a Two-Phase Weighted Collaborative Representation Classification (TPWCRC) framework. A class-based probability estimation is first calculated based on the extracted local descriptors as a prior knowledge. The resulting class-based probability estimation is then incorporated into the proposed classification framework as a locality constraint to further enhance its discriminating power. Experimental results on six challenging 3D facial datasets show that the proposed KMTS-TPWCRC framework achieves promising results for human face recognition with missing parts, occlusions, data corruptions, expressions and pose variations. © 2015 Elsevier Ltd. All rights reserved.},
author_keywords={3D face recognition;  3D representation;  Partial facial data;  Single sample problem;  Sparse representation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Echeagaray-Patron2016843,
author={Echeagaray-Patron, B.A. and Miramontes-Jaramillo, D. and Kober, V.},
title={Conformal parameterization and curvature analysis for 3D facial recognition},
journal={Proceedings - 2015 International Conference on Computational Science and Computational Intelligence, CSCI 2015},
year={2016},
pages={843-844},
doi={10.1109/CSCI.2015.133},
art_number={7424213},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964412211&doi=10.1109%2fCSCI.2015.133&partnerID=40&md5=6a3fc9e7dac95a6f25aacc425aa40af5},
affiliation={Department of Computer Science, CICESE, Ensenada, B.C., 22860, Mexico; Department of Mathematics, Chelyabinsk State University, Russian Federation},
abstract={This work proposes a new algorithm for 3D face recognition. The algorithm uses 3D shape data without color or texture information and exploits local curvature information which is a measure with high discriminant capability and robust to deformations such as rotation and scaling. In order to reduce high dimensionality of typical face surfaces our approach uses a conformal parameterization, preserving angles of original faces and simplifies the correspondence problem. Experimental results are presented and discussed using CASIA and Gavab databases. © 2015 IEEE.},
author_keywords={3D face recognition;  Conformal parameterization;  Curvature analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhou2016109,
author={Zhou, W. and Chen, J.-X. and Wang, L.},
title={A RGB-D face recognition approach without confronting the camera},
journal={Proceedings of 2015 IEEE International Conference on Computer and Communications, ICCC 2015},
year={2016},
pages={109-114},
doi={10.1109/CompComm.2015.7387550},
art_number={7387550},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963938690&doi=10.1109%2fCompComm.2015.7387550&partnerID=40&md5=d5bfca843f857fa39877a526fa1c2108},
affiliation={Key Lab of Broadband Wireless Communication and Sensor Network Technology, Ministry of Education, Nanjing, 210003, China},
abstract={Face recognition research mainly focuses on traditional 2D color images, which is extremely susceptible to be affected by external factors such as various viewpoints and has limited recognition accuracy. In order to achieve improved recognition performance, as well as the 3D face holds more abundant information than 2D, we present a 3D human face recognition algorithm using the Microsoft's Kinect. The proposed approach integrates the depth data with the RGB data to generate 3D face raw data and then extracts feature points, identifies the target via a two-level cascade classifier. Also, we build a 3D-face database including 16 individuals captured exclusively using Kinect. The experimental results indicate that the introduced algorithm can not only achieve better recognition accuracy in comparison to existing 2D and 3D face recognition algorithms when the probe face is exactly in front of Kinect sensor, but also can increase 9.3% of recognition accuracy compared to the PCA-3D algorithm when it is not confronting the camera. © 2015 IEEE.},
author_keywords={3D face recognition;  classifier;  Kinect;  RGB-D images;  XML file},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bagchi2016,
author={Bagchi, P. and Bhattacharjee, D. and Nasipuri, M.},
title={3D Face Recognition using surface normals},
journal={IEEE Region 10 Annual International Conference, Proceedings/TENCON},
year={2016},
volume={2016-January},
doi={10.1109/TENCON.2015.7372819},
art_number={7372819},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962199727&doi=10.1109%2fTENCON.2015.7372819&partnerID=40&md5=8d29f7cc34b9d49495eea2e33fa5af0b},
affiliation={Dept of CSE, RCC Institute of Information Technology, Beliaghata, Kolkata, India; Dept of CSE, Jadavpur University, Kolkata, India},
abstract={In this proposed work, a fully automatic 3D Face Recognition system across pose is presented, which works successfully on three modern databases namely the Frav3D, GavabDB and the Bosphorus databases. Poses handled in the system are yaw, pitch and roll varying from 0° to ±30° as well as expressions. The feature extraction is by depth face images with variation in depth values of the surface normals and also by KPCA. The system gives high recognition rate of 96.92% in case of GavabDB database, 96.25% in case of Bosphorus face database and 92.25% in case of Frav3D database by surface normals extraction. © 2015 IEEE.},
author_keywords={Gaussian kernel;  ICP;  Kernel-PCA;  Range Images},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{AdrianaEcheagaray-Patrón2016,
author={Adriana Echeagaray-Patrón, B. and Kober, V.},
title={Face recognition based on matching of local features on 3D dynamic range sequences},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2016},
volume={9971},
doi={10.1117/12.2236355},
art_number={997131},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006856443&doi=10.1117%2f12.2236355&partnerID=40&md5=12be001842b19c746ae9a723c01aed88},
affiliation={Department of Computer Science, CICESE, Ensenada, B.C., 22860, Mexico; Department of Mathematics, Chelyabinsk State University, Russian Federation},
abstract={3D face recognition has attracted attention in the last decade due to improvement of technology of 3D image acquisition and its wide range of applications such as access control, surveillance, human-computer interaction and biometric identification systems. Most research on 3D face recognition has focused on analysis of 3D still data. In this work, a new method for face recognition using dynamic 3D range sequences is proposed. Experimental results are presented and discussed using 3D sequences in the presence of pose variation. The performance of the proposed method is compared with that of conventional face recognition algorithms based on descriptors. © 2016 SPIE.},
author_keywords={3D face recognition;  Dynamic 3D range sequences;  HOG;  LBP;  SURF},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Starczewski2016210,
author={Starczewski, J.T. and Pabiasz, S. and Vladymyrska, N. and Marvuglia, A. and Napoli, C. and Wózniak, M.},
title={Self organizing maps for 3D face understanding},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9693},
pages={210-217},
doi={10.1007/978-3-319-39384-1_19},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977471207&doi=10.1007%2f978-3-319-39384-1_19&partnerID=40&md5=7f993d82b7b04337f5466c3ed735ff72},
affiliation={Institute of Computational Intelligence, Czestochowa University of Technology, Czestochowa, Poland; Radom Academy of Economics, Radom, Poland; Environmental Research and Innovation Department, Luxembourg Institute of Science and Technology, Esch-sur-Alzette, Luxembourg; Department of Mathematics and Informatics, University of Catania, Catania, Italy; Institute of Mathematics, Silesian University of Technology, Gliwice, Poland},
abstract={Landmarks are unique points that can be located on every face. Facial landmarks typically recognized by people are correlated with anthropomorphic points. Our purpose is to employ in 3D face recognition such landmarks that are easy to interpret. Face understanding is construed as identification of face characteristic points with automatic labeling of them. In this paper, we apply methods based on Self Organizing Maps to understand 3D faces. © Springer International Publishing Switzerland 2016.},
author_keywords={3D face recognition;  Self organizing maps;  Understanding of images},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Galbally2016199,
author={Galbally, J. and Satta, R.},
title={Biometric sensor interoperability: A case study in 3D face recognition},
journal={ICPRAM 2016 - Proceedings of the 5th International Conference on Pattern Recognition Applications and Methods},
year={2016},
pages={199-204},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969988967&partnerID=40&md5=80af1e7c3fa3ef4e303e144e6927af47},
affiliation={European Commission - Joint Research Centre, IPSC, Via Enrico Fermi 2749, Ispra, 21027, Italy},
abstract={Biometric systems typically suffer a significant loss of performance when the acquisition sensor is changed between enrolment and authentication. Such a problem, commonly known as sensor interoperability, poses a serious challenge to the accuracy of matching algorithms. The present work addresses for the first time the sensor interoperability issue in 3D face recognition systems, analysing the performance of two popular and well known techniques for 3D facial authentication. For this purpose, a new gender-balanced database comprising 3D data of 26 subjects has been acquired using two devices belonging to the new generation of low-cost 3D sensors. The results show the high sensor-dependency of the tested systems and the need to develop matching algorithms robust to the variation in the sensor resolution. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={3D face database;  3D face recognition;  Interoperability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Song2016,
author={Song, D. and Luo, J. and Zi, C. and Tian, H.},
title={3D Face Recognition Using Anthropometric and Curvelet Features Fusion},
journal={Journal of Sensors},
year={2016},
volume={2016},
doi={10.1155/2016/6859364},
art_number={6859364},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954447014&doi=10.1155%2f2016%2f6859364&partnerID=40&md5=145d972d12039ce0cfdea217aaa57214},
affiliation={College of Electrical Engineering and Automation, Tianjin Polytechnic University, Tianjin, 300387, China; Key Laboratory of Advanced Electrical Engineering and Energy Technology, Tianjin, 300387, China; School of Electrical, Computer and Telecommunications Engineering, University of Wollongong, Sydney, NSW  2522, Australia},
abstract={Curvelet transform can describe the signal by multiple scales, and multiple directions. In order to improve the performance of 3D face recognition algorithm, we proposed an Anthropometric and Curvelet features fusion-based algorithm for 3D face recognition (Anthropometric Curvelet Fusion Face Recognition, ACFFR). First, the eyes, nose, and mouth feature regions are extracted by the Anthropometric characteristics and curvature features of the human face. Second, Curvelet energy features of the facial feature regions at different scales and different directions are extracted by Curvelet transform. At last, Euclidean distance is used as the similarity between template and objectives. To verify the performance, the proposed algorithm is compared with Anthroface3D and Curveletface3D on the Texas 3D FR database. The experimental results have shown that the proposed algorithm performs well, with equal error rate of 1.75% and accuracy of 97.0%. The algorithm we proposed in this paper has better robustness to expression and light changes than Anthroface3D and Curveletface3D. © 2016 Dan Song et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bellil2016365,
author={Bellil, W. and Brahim, H. and Ben Amar, C.},
title={Gappy wavelet neural network for 3D occluded faces: detection and recognition},
journal={Multimedia Tools and Applications},
year={2016},
volume={75},
number={1},
pages={365-380},
doi={10.1007/s11042-014-2294-6},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953638822&doi=10.1007%2fs11042-014-2294-6&partnerID=40&md5=e5d7d42e44edd21d1de8b6e4cc7bdd48},
affiliation={REGIM: REsearch Groups on Intelligent Machines, University of Sfax, National Engineering School of Sfax (ENIS), Sfax, Tunisia},
abstract={The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 % which represents a competitive result compared to the state of the art. © 2014, Springer Science+Business Media New York.},
author_keywords={3D face recognition; Wavelets;  Gappy data;  Occlusion detection;  Wavelet neural network},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gaonkar201615,
author={Gaonkar, A.A. and Gad, M.D. and Vetrekar, N.T. and Tilve, V.S. and Gad, R.S.},
title={Experimental evaluation of 3D kinect face database},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10481 LNCS},
pages={15-26},
doi={10.1007/978-3-319-68124-5_2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057824711&doi=10.1007%2f978-3-319-68124-5_2&partnerID=40&md5=3a104665aebdb39c053c8b83ce35c8fb},
affiliation={Department of Electronics, Goa University, Taleigao Plateau, Goa, India; Goa Engineering College, Farmagudi, Goa, India; School of Earth and Space Exploration, Arizona State University, Tempe, United States},
abstract={3D face recognition has gain a paramount importance over 2D due to its potential to address the limitations of 2D face recognition against the variation in facial poses, angles, occlusions etc. Research in 3D face recognition has accelerated in recent years due to the development of low cost 3D Kinect camera sensor. This has leads to the development of few RGB-D database across the world. Here in this paper we introduce the base results of our 3D facial database (GU-RGBD database) comprising variation in pose (0°, 45°, 90°, −45°, −90°), expression (smile, eyes closed), occlusion (half face covered with paper) and illumination variation using Kinect. We present a proposed noise removal non-linear interpolation filter for the patches present in the depth images. The results were obtained on three face recognition algorithms and fusion at matching score level for recognition and verification rate. The obtained results indicated that the performance with our proposed filter shows improvement over pose with score level fusion using sum rule. © Springer International Publishing AG 2017.},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Tistarelli2016305,
author={Tistarelli, M. and Cadoni, M. and Lagorio, A. and Grosso, E.},
title={Blending 2D and 3D face recognition},
journal={Face Recognition Across the Imaging Spectrum},
year={2016},
pages={305-331},
doi={10.1007/978-3-319-28501-6_13},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014098769&doi=10.1007%2f978-3-319-28501-6_13&partnerID=40&md5=44e32cb05fff607d64356a67b85a0d29},
affiliation={University of Sassari, Sassari, Italy},
abstract={Over the last decade, performance of face recognition algorithms systematically improved. This is particularly impressive when considering very large or challenging datasets such as the FRGC v2 or Labelled Faces in the Wild. A better analysis of the structure of the facial texture and shape is one of the main reasons of improvement in recognition performance. Hybrid face recognition methods, combining holistic and feature-based approaches, also allowed to increase efficiency and robustness. Both photometric information and shape information allow to extract facial features which can be exploited for recognition. However, both sources, grey levels of image pixels and 3D data, are affected by several noise sources which may impair the recognition performance. One of the main difficulties in matching 3D faces is the detection and localization of distinctive and stable points in 3D scans. Moreover, the large amount of data (tens of thousands of points) to be processed make the direct one-to-one matching a very time-consuming process. On the other hand, matching algorithms based on the analysis of 2D data alone are very sensitive to variations in illumination, expression and pose. Algorithms, based on the face shape information alone, are instead relatively insensitive to these sources of noise. These mutually exclusive features of 2D- and 3D-based face recognition algorithm call for a cooperative scheme which may take advantage of the strengths of both, while coping for their weaknesses. We envisage many real and practical applications where 2D data can be used to improve 3D matching and vice versa. Towards this end, this chapter highlights both the advantages and disadvantages of 2D- and 3D-based face recognition algorithms. It also explores the advantages of blending 2D- and 3D data-based techniques, also proposing a novel approach for a fast and robust matching. Several experimental results, obtained from publicly available datasets, currently at the state of the art, demonstrate the effectiveness of the proposed approach. © Springer International Publishing Switzerland 2016.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Boukamcha2015,
author={Boukamcha, H. and Elhallek, M. and Atri, M. and Smach, F.},
title={3D face landmark auto detection},
journal={2015 World Symposium on Computer Networks and Information Security, WSCNIS 2015},
year={2015},
doi={10.1109/WSCNIS.2015.7368276},
art_number={7368276},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962430025&doi=10.1109%2fWSCNIS.2015.7368276&partnerID=40&md5=13ae6691c8afd0ea13bb469882ec0aea},
affiliation={University of Sciences of Monastir, Monastir, Tunisia; Université of Bourgogne, France},
abstract={This paper presents our methodology for Landmark Point detection to improve 3D face recognition in a presence of variant facial expression. The objective was to develop an automatic process for distinguishing and segmenting to be embedded in a 3D face recognition system using only 3D Point Distribution Model (PDM) as input. The approach used hydride method to extract this features from the surface curvature information. Landmark Localization is done on the segmented face via finding the change that decreases the deviation of the model from the mean profile. Face registering is achieved using previous anthropometric information and the localized landmarks. The results confirm that the method used is accurate and robust for the proposed application. © 2015 IEEE.},
author_keywords={3D Face;  Graph Matching;  Labelling;  Registration},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lv20153635,
author={Lv, S. and Da, F. and Deng, X.},
title={A 3D face recognition method using region-based extended local binary pattern},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2015},
volume={2015-December},
pages={3635-3639},
doi={10.1109/ICIP.2015.7351482},
art_number={7351482},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956668987&doi=10.1109%2fICIP.2015.7351482&partnerID=40&md5=2c0948e184ab3751c8c447b235e50e0a},
affiliation={School of Automation, Southeast University, Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, 210096, China},
abstract={A 3D face recognition method using region-based extended local binary pattern (eLBP) is proposed. First, the depth image converted from the preprocessed 3D pointclouds is normalized. Then, different regions according to their distortions under facial expressions are extracted by binary masks and represented by the uniform pattern of extended LBP. Finally, sparse representation classifier (SRC) is adopted for classification on the single region. Feature-level and score-level fusion with weight-sparse representation classifier (W-SRC) are also tested and compared, and the latter has better performance. The experiments on FRGC v2.0 database demonstrate that the proposed method is robust and efficient. © 2015 IEEE.},
author_keywords={3D face recognition;  binary mask;  depth image;  extended local binary pattern;  weight-sparse representation classifier},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tortorici20152670,
author={Tortorici, C. and Werghi, N. and Berretti, S.},
title={Boosting 3D LBP-based face recognition by fusing shape and texture descriptors on the mesh},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2015},
volume={2015-December},
pages={2670-2674},
doi={10.1109/ICIP.2015.7351287},
art_number={7351287},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956639911&doi=10.1109%2fICIP.2015.7351287&partnerID=40&md5=6ea1b56b061b463d4fc6e850dc9c85e6},
affiliation={Khalifa University, Abu Dhabi, United Arab Emirates; University of Florence, Florence, Italy},
abstract={In this paper, we present a novel approach for fusing shape and texture local binary patterns (LBP) for 3D face recognition. Using the framework proposed in [1], we compute LBP directly on the face mesh surface, then we construct a grid of the regions on the facial surface that can accommodate global and partial descriptions. Compared to its depth-image counterpart, our approach is distinguished by the following features: a) inherits the intrinsic advantages of mesh surface; b) does not require normalization; c) can accommodate partial matching. In addition, it allows early-level fusion of texture and shape modalities. Through experiments conducted on the BU-3DFE and Bosphorus databases, we assess different variants of our approach with regard to facial expressions and missing data. © 2015 IEEE.},
author_keywords={3D face recognition;  fusion;  mesh-LBP},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Patil2015393,
author={Patil, H. and Kothari, A. and Bhurchandi, K.},
title={3-D face recognition: features, databases, algorithms and challenges},
journal={Artificial Intelligence Review},
year={2015},
volume={44},
number={3},
pages={393-441},
doi={10.1007/s10462-015-9431-0},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941419993&doi=10.1007%2fs10462-015-9431-0&partnerID=40&md5=c90b8821f623bcb40665d0010a316ef6},
affiliation={Visvesvaraya National Institute of Technology, Nagpur, India},
abstract={Face recognition is being widely accepted as a biometric technique because of its non-intrusive nature. Despite extensive research on 2-D face recognition, it suffers from poor recognition rate due to pose, illumination, expression, ageing, makeup variations and occlusions. In recent years, the research focus has shifted toward face recognition using 3-D facial surface and shape which represent more discriminating features by the virtue of increased dimensionality. This paper presents an extensive survey of recent 3-D face recognition techniques in terms of feature detection, classifiers as well as published algorithms that address expression and occlusion variation challenges followed by our critical comments on the published work. It also summarizes remarkable 3-D face databases and their features used for performance evaluation. Finally we suggest vital steps of a robust 3-D face recognition system based on the surveyed work and identify a few possible directions for research in this area. © 2015, Springer Science+Business Media Dordrecht.},
author_keywords={3-D Face databases;  3-D faces;  Biometrics;  Classifiers;  Face matching;  Face recognition;  Feature extraction},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Werghi20152521,
author={Werghi, N. and Tortorici, C. and Berretti, S. and Del Bimbo, A.},
title={Representing 3D texture on mesh manifolds for retrieval and recognition applications},
journal={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
year={2015},
volume={07-12-June-2015},
pages={2521-2530},
doi={10.1109/CVPR.2015.7298867},
art_number={7298867},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959190332&doi=10.1109%2fCVPR.2015.7298867&partnerID=40&md5=f250cc4afb5eff7b0a9ce39449bd5844},
affiliation={Khalifa University of Science, Technology and Research, Sharjah, United Arab Emirates; University of Florence, Florence, Italy},
abstract={In this paper, we present and experiment a novel approach for representing texture of 3D mesh manifolds using local binary patterns (LBP). Using a recently proposed framework [37], we compute LBP directly on the mesh surface, either using geometric or photometric appearance. Compared to its depth-image counterpart, our approach is distinguished by the following features: a) inherits the intrinsic advantages of mesh surface (e.g., preservation of the full geometry); b) does not require normalization; c) can accommodate partial matching. In addition, it allows early-level fusion of the geometry and photometric texture modalities. Through experiments conducted on two application scenarios, namely, 3D texture retrieval and 3D face recognition, we assess the effectiveness of the proposed solution with respect to state of the art approaches. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liang2015,
author={Liang, Y. and Zhang, Y.},
title={Expression-invariant face recognition using three-dimensional weighted walkthrough and centroid distance},
journal={Journal of Electronic Imaging},
year={2015},
volume={24},
number={5},
doi={10.1117/1.JEI.24.5.053007},
art_number={053007},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941344580&doi=10.1117%2f1.JEI.24.5.053007&partnerID=40&md5=cf2a7dde7737084919b6a8b4c738d263},
affiliation={Guangdong University of Technology, School of Automation, Guangzhou Higher Education Mega Centre, No. 100, Waihuan Xi Road, Guangzhou, 510006, China; South China Normal University, School of Software, Nanhai Information Technology Park, Foshan, 528225, China},
abstract={Three-dimensional (3-D) face recognition provides a potential to handle challenges caused by illumination and pose variations. However, extreme expression variations still complicate the task of recognition. An accurate and robust method for expression-invariant 3-D face recognition is proposed. A 3-D face is partitioned into a set of isogeodesic stripes and the spatial relationships of the stripes are described by 3-D weighted walkthrough and the centroid distance. Moreover, the method of the similarity measure is given. Experiments are performed on the CASIA dataset and the FRGC v2.0 dataset. The results show that our method has advantages for recognition performance despite large expression variations. © 2015 SPIE and IS&T.},
author_keywords={3-D face recognition;  3-D weighted walkthrough;  centroid distance;  isogeodesic stripes},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng20155509,
author={Deng, X. and Da, F. and Shao, H.},
title={Expression-robust 3D face recognition using region-based multiscale wavelet feature fusion},
journal={Journal of Computational Information Systems},
year={2015},
volume={11},
number={15},
pages={5509-5517},
doi={10.12733/jcis14953},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950271521&doi=10.12733%2fjcis14953&partnerID=40&md5=da8d93edfc030808fb309b097e409e94},
affiliation={Department of Automation, Southeast University, Nanjing, 210096, China; Key Laboratory of Measurement and Control for Complex System of Ministry of Education, Southeast University, Nanjing, 210096, China},
abstract={In order to eliminate the impact of facial expressions and improve the efficiency of calculation, this paper proposes a novel expression-robust 3D face recognition algorithm using region-based feature fusion technique based on multiscale wavelet transformations. The discrete wavelet transformation is applied to extract frequency component features of geometric image based on the semi-rigid face region as well as the non-rigid face region in order to reduce the influence from the facial expression using the Coherent Point Drift non-rigid point set registration. The dimensionality reduction methods are utilized to promote the computational efficiency, and the experimental results show that our algorithm outperforms state-of-the-art methods based on FRGC v2.0. Copyright © 2015 Binary Information Press.},
author_keywords={3D face recognition;  Dimensionality reduction;  Multiscale wavelet transform;  Non-rigid point set registration},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mracek2015,
author={Mracek, S. and Dvorak, R. and Vana, J. and Novotny, T. and Drahansky, M.},
title={3D face recognition utilizing a low-cost depth sensor},
journal={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015},
year={2015},
doi={10.1109/FG.2015.7163169},
art_number={7163169},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944930257&doi=10.1109%2fFG.2015.7163169&partnerID=40&md5=195536ecc9cf6a2730e8b680cec47b46},
affiliation={Faculty of Information Technology, Brno University of Technology, Bozetechova 1/2, Brno, 612 66, Czech Republic},
abstract={This demo shows a working prototype of the 3D face recognition biometric device utilizing a low-cost depth sensor, namely SoftKinetic DS325. It is based on the Intel Celeron board for embedded PCs, the sensor, and a touch screen. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gao2015,
author={Gao, J. and Evans, A.N.},
title={Expression robust 3D face recognition by matching multi-component local shape descriptors on the nasal and adjoining cheek regions},
journal={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015},
year={2015},
doi={10.1109/FG.2015.7163144},
art_number={7163144},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944930906&doi=10.1109%2fFG.2015.7163144&partnerID=40&md5=f40854840a153023accb0e1bb1ac740d},
affiliation={Department of Electronic and Electrical Engineering, University of Bath, Bath, United Kingdom},
abstract={This paper proposes a novel local depth and surface normals descriptor to explore the discriminative features on the nasal surface and the adjoining cheek regions for expression robust 3D face recognition. After preprocessing the 3D face data, landmarks located on the perimeter of a triangular region covering the nose and adjoining parts of the cheeks are accurately detected. Inspired by Local Binary Patterns, local shape differences for 3D points on a set of horizontal curves joining selected landmarks provide a novel representation of the local shape information. A further analysis of the discriminatory power of each patch shows that the adjoining regions have the potential to produce good recognition performance. Using the FRGC and Bosphorus databases, the performance of the proposed descriptor is evaluated on diverse patches, scales and for four components, one from the depth and three from the surface normals. Results show that the new local shape descriptor performs well at representing the shape information on a relatively large scale. On the basis of this descriptor, a relatively small set of features extracted from the nasal and adjoining cheek regions produce a R1RR of 97.76% and an EER of 1.32%. The adjoining cheek regions demonstrate a high discriminatory power and provide a useful new addition to 3D face biometrics. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Xuechun2015587,
author={Xuechun, W. and Zhaoping, W.},
title={Design of a three-dimensional face recognition system},
journal={Open Automation and Control Systems Journal},
year={2015},
volume={7},
number={1},
pages={587-590},
doi={10.2174/1874444301507010587},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958249364&doi=10.2174%2f1874444301507010587&partnerID=40&md5=2acfca5b28422aff2b32e0652b175519},
affiliation={School of Information Engineering, Huanghe Science and Technology College, Zhengzhou, Henan  450006, China},
abstract={With the development of computer vision and computer graphics, face recognition technology has gradually developed from 2D to 3D. Using in-depth information of faces, 3D face recognition solves and overcomes the environ- ment and changes in the expression that 2D face recognition encounters. In this paper, the principles of laser triangulation measurement applied in 3D detection and modeling of faces are studied. A 3D face recognition system is designed on this basis. It not only has universal configuration and simple algorithm as well as other characteristics, but also has certain practicality. © Xuechun and Zhaoping.},
author_keywords={3D modeling;  Computer vision;  Face recognition;  Principles of triangulation measurement},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2015128,
author={Li, H. and Huang, D. and Morvan, J.-M. and Wang, Y. and Chen, L.},
title={Towards 3D Face Recognition in the Real: A Registration-Free Approach Using Fine-Grained Matching of 3D Keypoint Descriptors},
journal={International Journal of Computer Vision},
year={2015},
volume={113},
number={2},
pages={128-142},
doi={10.1007/s11263-014-0785-6},
note={cited By 51},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939949330&doi=10.1007%2fs11263-014-0785-6&partnerID=40&md5=e89019b8bd090159f9b7875702ccf3e6},
affiliation={School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, Shaanxi, 710049, China; Beijing Center for Mathematics and Information Interdisciplinary Sciences (BCMIIS), Beijing, China; Laboratory of Intelligent Recognition and Image Processing, School of Computer Science and Engineering, Beihang University, Beijing, 10091, China; Département de Mathématiques, Université Claude Bernard Lyon 1, Lyon, 69622, France; Geometric Modeling and Scientific Visualization Center, King Abdullah University of Science and Technology, Makkah, Saudi Arabia; Département de Mathématiques et Informatique, UMR CNRS 5205, Ecole Centrale Lyon, Lyon, 69134, France},
abstract={Registration algorithms performed on point clouds or range images of face scans have been successfully used for automatic 3D face recognition under expression variations, but have rarely been investigated to solve pose changes and occlusions mainly since that the basic landmarks to initialize coarse alignment are not always available. Recently, local feature-based SIFT-like matching proves competent to handle all such variations without registration. In this paper, towards 3D face recognition for real-life biometric applications, we significantly extend the SIFT-like matching framework to mesh data and propose a novel approach using fine-grained matching of 3D keypoint descriptors. First, two principal curvature-based 3D keypoint detectors are provided, which can repeatedly identify complementary locations on a face scan where local curvatures are high. Then, a robust 3D local coordinate system is built at each keypoint, which allows extraction of pose-invariant features. Three keypoint descriptors, corresponding to three surface differential quantities, are designed, and their feature-level fusion is employed to comprehensively describe local shapes of detected keypoints. Finally, we propose a multi-task sparse representation based fine-grained matching algorithm, which accounts for the average reconstruction error of probe face descriptors sparsely represented by a large dictionary of gallery descriptors in identification. Our approach is evaluated on the Bosphorus database and achieves rank-one recognition rates of 96.56, 98.82, 91.14, and 99.21 % on the entire database, and the expression, pose, and occlusion subsets, respectively. To the best of our knowledge, these are the best results reported so far on this database. Additionally, good generalization ability is also exhibited by the experiments on the FRGC v2.0 database. © 2014, Springer Science+Business Media New York.},
author_keywords={3D keypoint descriptors;  Expression, pose and occlusion;  Fine-grained matching;  Registration-free 3D face recognition},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang20151817,
author={Zhang, C. and Gu, Y.-Z. and Hu, K.-L. and Wang, Y.-G.},
title={Face recognition using SIFT features under 3D meshes},
journal={Journal of Central South University},
year={2015},
volume={22},
number={5},
pages={1817-1825},
doi={10.1007/s11771-015-2700-x},
art_number={2700},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930008100&doi=10.1007%2fs11771-015-2700-x&partnerID=40&md5=569ac008f1ef201b7fcbffd9e0faa163},
affiliation={Key Laboratory of Wireless Sensor Network & Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, 201800, China; Department of Computer Science and Engineering, Shaoxing University, Shaoxing, 312000, China},
abstract={Expression, occlusion, and pose variations are three main challenges for 3D face recognition. A novel method is presented to address 3D face recognition using scale-invariant feature transform (SIFT) features on 3D meshes. After preprocessing, shape index extrema on the 3D facial surface are selected as keypoints in the difference scale space and the unstable keypoints are removed after two screening steps. Then, a local coordinate system for each keypoint is established by principal component analysis (PCA). Next, two local geometric features are extracted around each keypoint through the local coordinate system. Additionally, the features are augmented by the symmetrization according to the approximate left-right symmetry in human face. The proposed method is evaluated on the Bosphorus, BU-3DFE, and Gavab databases, respectively. Good results are achieved on these three datasets. As a result, the proposed method proves robust to facial expression variations, partial external occlusions and large pose changes. © 2015, Central South University Press and Springer-Verlag Berlin Heidelberg.},
author_keywords={3D face recognition;  3D meshes;  expression;  large pose changes;  occlusion;  scale-invariant feature transform (SIFT)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chen20159,
author={Chen, H.-Z. and Hung, P.-S.},
title={3D Point Clouds Face Recognition by BP Neural Networks},
journal={Chung Cheng Ling Hsueh Pao/Journal of Chung Cheng Institute of Technology},
year={2015},
volume={44},
number={1},
pages={9-24},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959360389&partnerID=40&md5=a7ab39b6b4cfc96adbb4c77ed8a96d41},
affiliation={Institute of Civil and Hydraulic Engineering, Feng Chia University, Taiwan; Land Management, Feng Chia University, Taiwan},
abstract={In this paper, coordinates of 3D point clouds data are used directly for face recognition. 3D face point clouds database were built from neutral expressions and variant poses (left, frontal, and right). We are currently concentrating on a procedure of the coarse and fine transformation adjustment for face recognition. The transformation adjustment is based on the spatial fitted line to the point clouds data, centered at the nose tip, along longitudinal and cross-section profiles. Our 3D face point clouds data are combinations of 69 same-person pairs and 19,531 different-person pairs. We present an artificial neural networks with nose tip/root alignment geometry concept as network inputs for face recognition. The experiment presents that the success rates of same-person pairs is 100%. An appropriate amount for different-person pairs are 820 and their success rates can reach 99.3%. Compared to other related works, the framework has following highlights: (1) a coordinate transformation has to be done before face recognition alignment stage; (2) face recognition is directly completed by using point clouds without building 3D modality; (3) artificial intelligence neural networks for face recognition only with the feature points of nose tip/ root have illustrated that the proposed system is feasible.},
author_keywords={3D face point clouds database;  3D face recognition;  Artificial Intelligence neural networks},
document_type={Article},
source={Scopus},
}

@CONFERENCE{CardiaNeto201566,
author={Cardia Neto, J.B. and Marana, A.N.},
title={3DLBP and HAOG fusion for face recognition utilizing kinect as a 3D scanner},
journal={Proceedings of the ACM Symposium on Applied Computing},
year={2015},
volume={13-17-April-2015},
pages={66-73},
doi={10.1145/2695664.2695807},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955478290&doi=10.1145%2f2695664.2695807&partnerID=40&md5=2159132826aeae8225527d924694aade},
affiliation={Graduate Program in Computer Science, UNESP - São Paulo State University, Bauru, São Paulo, 17018-820, Brazil; Department of Computing, Faculty of Sciences, UNESP - São Paulo State University, Bauru, São Paulo, 17018-820, Brazil},
abstract={Pose and illumination variability are two major problems with 2D face recognition. Since 3D data is less sensible to illumination changes and can be used to adjust pose variations, it has been adopted to improve performance on face recognition systems. The main problem with utilizing 3D data is the high cost of the traditional 3D scanners. The Kinect is a low cost device that can be used to obtain the 3D data from an environment in a fast manner, but with lower accuracy than the traditional scanners. Recently, a 3D Local Binary Pattern (3DLBP) method was proposed for 3D face recognition by using high resolution scanners. The main goal of this work is to assess the performance of 3DLBP method, fused with Histogram of Averaged Oriented Gradients (HAOG) face descriptor method, for face recognition when Kinect is used as the 3D face scanner. Another goal is to compare the 3DLBP method, fused with HAOG descriptor, with other methods proposed in the literature for face recognition by using Kinect. Experimental results on EURECOM face dataset showed that the data generated by Kinect are discriminative enough to allow face recognition and that 3DLBP performs better than the other methods. Copyright is held by the owner/author(s).},
author_keywords={3D face recognition;  3DLBP;  HAOG;  Kinect},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Beumier20152291,
author={Beumier, C.},
title={Design of coded structured light pattern for 3D facial surface capture},
journal={European Signal Processing Conference},
year={2015},
volume={06-10-September-2004},
pages={2291-2294},
art_number={7079884},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979948896&partnerID=40&md5=b09f05fe749fab292462602ba77b999e},
affiliation={Signal and Image Centre, Royal Military Academy, Avenue de la Renaissance, 30, Brussels, B-1000, Belgium},
abstract={In the context of 3D face recognition, facial surfaces are advantageously captured by a structured light acquisition system, which is typically quick, low cost and uses off-the-shelve components. The light pattern projected, a key aspect of the structured light approach, makes the major difference between developed systems. In most of them, elements of the light pattern must be identified by a property such as element thickness or colour. We present in this paper the design of projected patterns that led to the realisation of three 3D acquisition prototypes. © 2004 EUSIPCO.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Elaiwat20151235,
author={Elaiwat, S. and Bennamoun, M. and Boussaid, F. and El-Sallam, A.},
title={A Curvelet-based approach for textured 3D face recognition},
journal={Pattern Recognition},
year={2015},
volume={48},
number={4},
pages={1235-1246},
doi={10.1016/j.patcog.2014.10.013},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920743471&doi=10.1016%2fj.patcog.2014.10.013&partnerID=40&md5=dde3d88e6412c83672a1a30bbf49b936},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Electrical, Electronic and Computer Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Sport Science, Exercise and Health, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia},
abstract={In this paper, we present a fully automated multimodal Curvelet-based approach for textured 3D face recognition. The proposed approach relies on a novel multimodal keypoint detector capable of repeatably identifying keypoints on textured 3D face surfaces. Unique local surface descriptors are then constructed around each detected keypoint by integrating Curvelet elements of different orientations, resulting in highly descriptive rotation invariant features. Unlike previously reported Curvelet-based face recognition algorithms which extract global features from textured faces only, our algorithm extracts both texture and 3D local features. In addition, this is achieved across a number of frequency bands to achieve robust and accurate recognition under varying illumination conditions and facial expressions. The proposed algorithm was evaluated using three well-known and challenging datasets, namely FRGC v2, BU-3DFE and Bosphorus datasets. Reported results show superior performance compared to prior art, with 99.2%, 95.1% and 91% verification rates at 0.001 FAR for FRGC v2, BU-3DFE and Bosphorus datasets, respectively. © 2014 Elsevier Ltd. All rights reserved.},
author_keywords={Digital Curvelet transform;  Face recognition;  Keypoint detection;  Local features},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li201575,
author={Li, Y. and Wang, Y. and Wang, B. and Sui, L.},
title={Nose tip detection on three-dimensional faces using pose-invariant differential surface features},
journal={IET Computer Vision},
year={2015},
volume={9},
number={1},
pages={75-84},
doi={10.1049/iet-cvi.2014.0070},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988269675&doi=10.1049%2fiet-cvi.2014.0070&partnerID=40&md5=9b44b1684d50589e30f8aa93abe2e4b3},
affiliation={School of Computer Science and Engineering, Xi'an University of Technology, 5 South Jinhua Road, Xi'an, 710048, China},
abstract={Three-dimensional (3D) facial data offer the potential to overcome the difficulties caused by the variation of head pose and illumination in 2D face recognition. In 3D face recognition, localisation of nose tip is essential to face normalisation, face registration and pose correction etc. Most of the existing methods of nose tip detection on 3D face deal mainly with frontal or near-frontal poses or are rotation sensitive. Many of them are training-based or model-based. In this study, a novel method of nose tip detection is proposed. Using pose-invariant differential surface features - high-order and low-order curvatures, it can detect nose tip on 3D faces under various poses automatically and accurately. Moreover, it does not require training and does not depend on any particular model. Experimental results on GavabDB verify the robustness and accuracy of the proposed method. © The Institution of Engineering and Technology 2015.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Betta2015,
author={Betta, G. and Capriglione, D. and Corvino, M. and Gasparetto, M. and Liguori, C. and Paolillo, A. and Zappa, E.},
title={Metrological performance comparison of biometric system architectures for 3D face recognition},
journal={XXI IMEKO World Congress "Measurement in Research and Industry"},
year={2015},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951072890&partnerID=40&md5=f575fdc74c6576579e3881b3aeb3a78c},
affiliation={DIEI, University of Cassino and of Southern Lazio Cassino (FR), Italy; DME, Politecnico di Milano, Via La Masa, 1, Milano, Italy; DIIn, University of Salerno, Via Giovanni Paolo II, 132, Fisciano (SA), Italy},
abstract={Different biometric system architectures based on 3D images can be realized for face recognition. In such systems the triangulation of images provided by a couple of 2D cameras is employed to achieve the 3D features of a face. To setting up the system, different positioning of cameras as well as both kind and resolution of camera could be considered. These parameters can affect the correct decision rate of the system in classifying the input face, especially in presence of image uncertainty. In previous papers, the authors proposed an original approach for the estimation of the confidence level of results provided by classification systems for face recognition. Such approach is here adopted in order to compare several 3D architectures differing in camera specifications and geometrical positioning.},
author_keywords={3D image features;  Classifier;  Decision support systems;  Face recognition;  Measurement uncertainty},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liang2015406,
author={Liang, R. and Shen, W. and Li, X.-X. and Wang, H.},
title={Bayesian multi-distribution-based discriminative feature extraction for 3D face recognition},
journal={Information Sciences},
year={2015},
volume={320},
pages={406-417},
doi={10.1016/j.ins.2015.03.063},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937521792&doi=10.1016%2fj.ins.2015.03.063&partnerID=40&md5=ea6a6994deb813d32a7a1d39602f0d94},
affiliation={College of Information Engineering, Zhejiang University of TechnologyHangzhou, China},
abstract={Due to the difficulties associated with the collection of 3D samples, 3D face recognition technologies often have to work with smaller than desirable sample sizes. With the aim of enlarging the training number for each subject, we divide each training image into several patches. However, this immediately introduces two further problems for 3D models: high computational cost and dispersive features caused by the divided 3D image patches. We therefore first map 3D face images into 2D depth images, which greatly reduces the dimension of the samples. Though the depth images retain most of the robust features of 3D images, such as pose and illumination invariance, they lose many discriminative features of the original 3D samples. In this study, we propose a Bayesian learning framework to extract the discriminative features from the depth images. Specifically, we concentrate the features of the intra-class patches to a mean feature by maximizing the multivariate Gaussian likelihood function, and, simultaneously, enlarge the distances between the inter-class mean features by maximizing the exponential priori distribution of the mean features. For classification, we use the nearest neighbor classifier combined with the Mahalanobis distance to calculate the distance between the features of the test image and items in the training set. Experiments on two widely-used 3D face databases demonstrate the efficiency and accuracy of our proposed method compared to relevant state-of-the-art methods. © 2015 Elsevier Inc. All rights reserved.},
author_keywords={3D face recognition;  Bayesian learning;  Depth image;  Single training sample per person},
document_type={Article},
source={Scopus},
}

@ARTICLE{Quan2015199,
author={Quan, W. and Matuszewski, B.J. and Shark, L.-K.},
title={3-d face recognition using geodesic-map representation and statistical shape modelling},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9493},
pages={199-212},
doi={10.1007/978-3-319-27677-9_13},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955314982&doi=10.1007%2f978-3-319-27677-9_13&partnerID=40&md5=e85737d15347f5ea197969c838869be9},
affiliation={Applied Digital Signal and Image Processing (ADSIP) Research Centre, University of Central Lancashire, Preston, PR1 2HE, United Kingdom},
abstract={3-D face recognition research has received significant attention in the past two decades because of the rapid development in imaging technology and ever increasing security demand of modern society. One of its challenges is to cope with non-rigid deformation among faces, which is often caused by the changes of appearance and facial expression. Popular solutions to deal with this problem are to detect the deformable parts of the face and exclude them, or to represent a face in terms of sparse signature points, curves or patterns that are invariant to deformation. Such approaches, however, may lead to loss of information which is important for classification. In this paper, we propose a new geodesic-map representation with statistical shape modelling for handling the non-rigid deformation challenge in face recognition. The proposed representation captures all geometrical information from the entire 3-D face and provides a compact and expression-free map that preserves intrinsic geometrical information. As a result, the search for dense points correspondence in the face recognition task can be speeded up by using a simple image-based method instead of time-consuming, recursive closest distance search in 3-D space. An experimental investigation was conducted on 3-D face scans using publicly available databases and compared with the benchmark approaches. The experimental results demonstrate that the proposed scheme provides a highly competitive new solution for 3-D face recognition. © Springer International Publishing Switzerland 2015.},
author_keywords={3-D face recognition;  Geodesic-map representation;  Non-rigid deformation;  Shape modeling},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang201527,
author={Wang, H. and Mu, Z. and Zeng, H. and Huang, M.},
title={3D face recognition using local features matching on sphere depth representation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9428},
pages={27-34},
doi={10.1007/978-3-319-25417-3_4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950245926&doi=10.1007%2f978-3-319-25417-3_4&partnerID=40&md5=a7ea7b117fa5089c7a6e2e77750229fd},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China},
abstract={This paper proposes a 3D face recognition approach using sphere depth image, which is robust to pose variations in unconstrained environments. The input 3D face point clouds is first transformed into sphere depth images, and then represented as a 3DLBP image to enhance the distinctiveness of smooth and similar facial depth images. An improved SIFT algorithm is applied in the following matching process. The improved SIFT algorithm employs the learning to rank approach to select the keypoints with higher stability and repeatability instead of manually rule-based method used by the original SIFT algorithm. The proposed face recognition method is evaluated on CASIA 3D face database. And the experimental results show our approach has superior performance than many existing methods for 3D face recognition and handles pose variations quite well. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  Learning to rank;  Local binary patterns;  Sphere depth image},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ming2015352,
author={Ming, Y. and Jin, Y.},
title={Robust 3D local SIFT features for 3D face recognition},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9246},
pages={352-359},
doi={10.1007/978-3-319-22873-0_31},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985029352&doi=10.1007%2f978-3-319-22873-0_31&partnerID=40&md5=4448fcb45dc3bae2a2c99810502b1ce7},
affiliation={School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, 100044, China},
abstract={In this paper, a robust 3D local SIFT feature is proposed for 3D face recognition. For preprocessing the original 3D face data, facial regional segmentation is first employed by fusing curvature characteristics and shape band mechanism. Then, we design a new local descriptor for the extracted regions, called 3D local Scale-Invariant Feature Transform (3D LSIFT). The key point detection based on 3D LSIFT can effectively reflect the geometric characteristic of 3D facial surface by encoding the gray and depth information captured by 3D face data. Then, 3D LSIFT descriptor extends to describe the discrimination on 3D faces. Experimental results based on the common international 3D face databases demonstrate the higher-qualified performance of our proposed algorithm with effectiveness, robustness, and universality. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  3D local Scale-Invariant feature transform;  Depth information;  Facial region segmentation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ming201514,
author={Ming, Y.},
title={Robust regional bounding spherical descriptor for 3D face recognition and emotion analysis},
journal={Image and Vision Computing},
year={2015},
volume={35},
pages={14-22},
doi={10.1016/j.imavis.2014.12.003},
note={cited By 26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921669860&doi=10.1016%2fj.imavis.2014.12.003&partnerID=40&md5=fe785e43fe879b32d41aadd4abc61953},
affiliation={School of Electronic Engineering, Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, 100876, China},
abstract={3D face recognition and emotion analysis play important roles in many fields of communication and edutainment. An effective facial descriptor, with higher discriminating capability for face recognition and higher descriptiveness for facial emotion analysis, is a challenging issue. However, in the practical applications, the descriptiveness and discrimination are independent and contradictory to each other. 3D facial data provide a promising way to balance these two aspects. In this paper, a robust regional bounding spherical descriptor (RBSR) is proposed to facilitate 3D face recognition and emotion analysis. In our framework, we first segment a group of regions on each 3D facial point cloud by shape index and spherical bands on the human face. Then the corresponding facial areas are projected to regional bounding spheres to obtain our regional descriptor. Finally, a regional and global regression mapping (RGRM) technique is employed to the weighted regional descriptor for boosting the classification accuracy. Three largest available databases, FRGC v2, CASIA and BU-3DFE, are contributed to the performance comparison and the experimental results show a consistently better performance for 3D face recognition and emotion analysis. © 2015 Elsevier B.V. All rights reserved.},
author_keywords={3D face recognition;  Emotion analysis;  Kullback-Leiber divergence (KLD);  Regional and global regression;  Regional bounding spherical descriptor},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Echeagaray-Patrón2015,
author={Echeagaray-Patrón, B.A. and Kober, V.},
title={3D face recognition based on matching of facial surfaces},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9598},
doi={10.1117/12.2186695},
art_number={95980V},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951325808&doi=10.1117%2f12.2186695&partnerID=40&md5=cb5a757e08c6a66683fc0706f09faf95},
affiliation={Department of Computer Science, CICESE, Ensenada, B.C.22860, Mexico; Department of Mathematics, Chelyabinsk State University, Russian Federation},
abstract={Face recognition is an important task in pattern recognition and computer vision. In this work a method for 3D face recognition in the presence of facial expression and poses variations is proposed. The method uses 3D shape data without color or texture information. A new matching algorithm based on conformal mapping of original facial surfaces onto a Riemannian manifold followed by comparison of conformal and isometric invariants computed in the manifold is suggested. Experimental results are presented using common 3D face databases that contain significant amount of expression and pose variations. © 2015 SPIE.},
author_keywords={3D face recognition;  3D facial shape analysis;  Conformal mapping},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Guo2015,
author={Guo, Z. and Liu, S. and Wang, Y. and Lei, T.},
title={Learning deformation model for expression-robust 3D face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9817},
doi={10.1117/12.2228002},
art_number={98170O},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028295582&doi=10.1117%2f12.2228002&partnerID=40&md5=42fcb3ae1a1a8506c08003ac3fd73bc1},
affiliation={School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China; School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lanzhou, 730070, China},
abstract={Expression change is the major cause of local plastic deformation of the facial surface. The intra-class differences with large expression change somehow are larger than the inter-class differences as it's difficult to distinguish the same individual with facial expression change. In this paper, an expression-robust 3D face recognition method is proposed by learning expression deformation model. The expression of the individuals on the training set is modeled by principal component analysis, the main components are retained to construct the facial deformation model. For the test 3D face, the shape difference between the test and the neutral face in training set is used for reconstructing the expression change by the constructed deformation model. The reconstruction residual error is used for face recognition. The average recognition rate on GavabDB and self-built database reaches 85.1% and 83%, respectively, which shows strong robustness for expression changes. © 2015 SPIE.},
author_keywords={3D face recognition;  Facial deformation model;  Principal component analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Luo2015,
author={Luo, J. and Geng, S.Z. and Xiao, Z.X. and Xiu, C.B.},
title={A review of recent advances in 3d face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9443},
doi={10.1117/12.2178750},
art_number={944303},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925431201&doi=10.1117%2f12.2178750&partnerID=40&md5=f8e793b50759be140f6e5bf45667a121},
affiliation={Key Laboratory of Advanced of Electrical Engineering and Energy Technology, Tianjin Polytechnic University, Tianjin, 300387, China; College of Electrical Engineering and Automation, Tianjin Polytechnic University, Tianjin, 300387, China},
abstract={Face recognition based on machine vision has achieved great advances and been widely used in the various fields. However, there are some challenges on the face recognition, such as facial pose, variations in illumination, and facial expression. So, this paper gives the recent advances in 3D face recognition. 3D face recognition approaches are categorized into four groups: minutiae approach, space transform approach, geometric features approach, model approach. Several typical approaches are compared in detail, including feature extraction, recognition algorithm, and the performance of the algorithm. Finally, this paper summarized the challenge existing in 3D face recognition and the future trend. This paper aims to help the researches majoring on face recognition. © 2015 SPIE.},
author_keywords={3D face recognition;  geometric features;  minutiae approach.;  space transform},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Belghini2015317,
author={Belghini, N. and Ezghari, S. and Zahi, A.},
title={3D face recognition using facial curves, sparse random projection and fuzzy similarity measure},
journal={Colloquium in Information Science and Technology, CIST},
year={2015},
volume={2015-January},
number={January},
pages={317-322},
doi={10.1109/CIST.2014.7016639},
art_number={7016639},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938075627&doi=10.1109%2fCIST.2014.7016639&partnerID=40&md5=bca04cb8b40640821dbbc277a0cf6e71},
affiliation={System Intelligent and Application Laboratory (SIA) FST, Fez, Morocco},
abstract={In this paper, we propose a fuzzy similarity based classification approach for 3D face recognition. In the feature extraction method, we exploit curve concept to represent the 3D facial data, two types of curves was considered: depth-level and depth-radial curves. As the dimension of the obtained features is high, the problem 'curse of dimensionality' appears. To solve this problem, the Random Projection (RP) method was used. The proposed classifier performs Fuzzification operation using triangular membership functions for input data and ordered weighted averaging operators to measure similarity. Experiment was conducted using vrml files from 3D Database considering only one training sample per person. The obtained results are very promising for depth-level and depth-radial curves, besides the recognition rates are higher than 98%. © 2014 IEEE.},
author_keywords={3D face recognition;  facial curves;  fuzzy logic;  OWA operator;  similarity measure;  sparse random projection},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ratyal2015241,
author={Ratyal, N.I. and Taj, I.A. and Bajwa, U.I. and Sajid, M.},
title={3D face recognition based on pose and expression invariant alignment},
journal={Computers and Electrical Engineering},
year={2015},
volume={46},
pages={241-255},
doi={10.1016/j.compeleceng.2015.06.007},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931030581&doi=10.1016%2fj.compeleceng.2015.06.007&partnerID=40&md5=a95f41db3d492d423152cf1d2907956a},
affiliation={Vision and Pattern Recognition Systems Research Group, Mohammad Ali Jinnah University, Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan},
abstract={In this paper we present a novel pose and expression invariant approach for 3D face registration based on intrinsic coordinate system characterized by nose tip, horizontal nose plane and vertical symmetry plane of the face. It is observed that distance of nose tip from 3D scanner is reduced after pose correction which is presented as a quantifying heuristic for proposed registration scheme. In addition, motivated by the fact that a single classifier cannot be generally efficient against all face regions, a two tier ensemble classifier based 3D face recognition approach is presented which employs Principal Component Analysis (PCA) for feature extraction and Mahalanobis Cosine (MahCos) matching score for classification of facial regions with weighted Borda Count (WBC) based combination and a re-ranking stage. The performance of proposed approach is corroborated by extensive experiments performed on two databases: GavabDB and FRGC v2.0, confirming effectiveness of fusion strategies to improve performance. © 2015 Elsevier Ltd. All rights reserved.},
author_keywords={3D face recognition;  3D registration;  Ensemble classifier;  Fusion;  Intrinsic coordinate system},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wang2015192,
author={Wang, X. and Ruan, Q. and Jin, Y. and An, G.},
title={3D face recognition using closest point coordinates and spherical vector norms},
journal={IET Conference Publications},
year={2015},
volume={2015},
number={CP681},
pages={192-196},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983122121&partnerID=40&md5=4a26023e54f7fb05eaa6d68668c88d60},
affiliation={Institution of Information Science, Beijing Jiaotong University, Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, 100044, China},
abstract={In this paper, we introduce a new feature named spherical vector norms for 3D face recognition. The proposed feature is efficient, insensitive to facial expression and contains discriminatory information of 3D face. The feature extraction method is firstly finding a set of the points with the closest distance to the standard face, denoted as closest point coordinates, and then extracting the spherical vector norms of these points. This paper combines point coordinates and spherical vector norms for improving recognition. Finally this approach is finished by Linear Discriminant Analysis (LDA) and Nearest Neighbor classifier. We have performed different experiments on the Face Recognition Grand Challenge database. It achieves the verification rate of 97.11% on All vs. All experiment at 0.1% FAR and 96.64% verification rate on Neutral vs. Expression experiment.},
author_keywords={3D face recognition;  Linear discriminant analysis;  Spherical vector norms},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tang2015466,
author={Tang, Y. and Sun, X. and Huang, D. and Morvan, J.-M. and Wang, Y. and Chen, L.},
title={3D face recognition with asymptotic cones based principal curvatures},
journal={Proceedings of 2015 International Conference on Biometrics, ICB 2015},
year={2015},
pages={466-472},
doi={10.1109/ICB.2015.7139111},
art_number={7139111},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943279293&doi=10.1109%2fICB.2015.7139111&partnerID=40&md5=bd52f57fa0f04d14b00dab8a5d4e64e2},
affiliation={Université de Lyon, CNRS, Ecole Centrale de Lyon, LIRIS, Lyon, 69134, France; King Abdullah University of Science and Technology, V.C.C. Research Center, Thuwal, 23955-6900, Saudi Arabia; IRIP, School of Computer Science and Engineering, Beihang Universtiy, Beijing, 100191, China; Université de Lyon, CNRS, Université Claude Bernard Lyon 1, ICJ UMR 5208, Villeurbanne, F-69622, France},
abstract={The classical curvatures of smooth surfaces (Gaussian, mean and principal curvatures) have been widely used in 3D face recognition (FR). However, facial surfaces resulting from 3D sensors are discrete meshes. In this paper, we present a general framework and define three principal curvatures on discrete surfaces for the purpose of 3D FR. These principal curvatures are derived from the construction of asymptotic cones associated to any Borel subset of the discrete surface. They describe the local geometry of the underlying mesh. First two of them correspond to the classical principal curvatures in the smooth case. We isolate the third principal curvature that carries out meaningful geometric shape information. The three principal curvatures in different Borel subsets scales give multi-scale local facial surface descriptors. We combine the proposed principal curvatures with the LNP-based facial descriptor and SRC for recognition. The identification and verification experiments demonstrate the practicability and accuracy of the third principal curvature and the fusion of multi-scale Borel subset descriptors on 3D face from FRGC v2.0. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hafez2015373,
author={Hafez, S.F. and Selim, M.M. and Zayed, H.H.},
title={3D face recognition based on normal map features using selected Gabor filters and linear discriminant analysis},
journal={International Journal of Biometrics},
year={2015},
volume={7},
number={4},
pages={373-390},
doi={10.1504/IJBM.2015.076138},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969234799&doi=10.1504%2fIJBM.2015.076138&partnerID=40&md5=4c091fd618afea54f7840fe4998e06bf},
affiliation={Faculty of Engineering, Benha University, Benha, Egypt; Department of Computer Science, Faculty of Computers and Informatics, Benha University, Benha, Egypt},
abstract={In this paper, we present a new approach to enhance and improve the performance of automatic 3D face recognition system. The proposed method has been implemented through a preprocessing technique to align and normalise all images in the database based on eyes centres localisation using 2D normalised cross-correlation (2DNCC). Preprocessing 3D face data has been implemented using depth map representation of the 3D data. The detected eyes centres and eyes distance (ED) have been used to segment and align 3D face images to produce a cropped face region of interest (ROI). The proposed approach extracted 3D face features using a set of selected orthogonal Gabor filters applied to normal map representation of the 3D face model. This approach minimises the feature vector extracted compared to systems that use complete Gabor filters bank. A further compression to the extracted features has been accomplished using linear discriminant analysis (LDA) before the classification stage. Experimental results show that the proposed system is effective for both dimensionality reduction and good recognition performance when compared to current systems. The system has been tested using CASIA and Gavab 3D face images databases and achieved 98.35% and 85% recognition rates, respectively. © 2015 Inderscience Enterprises Ltd.},
author_keywords={Depth maps;  Face recognition;  LDA;  Linear discriminant analysis;  Normal maps;  Preprocessing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zou2015898,
author={Zou, H. and Da, F. and Wang, Z.},
title={A novel 3D face feature based on geometry image vertical shape information},
journal={Optik},
year={2015},
volume={126},
number={9-10},
pages={898-902},
doi={10.1016/j.ijleo.2015.02.083},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928986749&doi=10.1016%2fj.ijleo.2015.02.083&partnerID=40&md5=2eba158b312d6844869e98302c0480fa},
affiliation={School of Automation, Southeast University, Nanjing, Jiangsu, 210096, China; School of Mechanical and Electronic Engineering, Nanjing Forestry University, Nanjing, 210037, China},
abstract={A novel and efficient face feature is proposed in this paper. 3D faces from the database are preprocessed and mapped to 2D geometry images. Then the geometry images are decomposed into wavelet responses by multi-scale Gabor transforms. According to analyses and experiments, responses that represent vertical shape information are figured out to be face feature for recognition. Moreover, the feature extracted by multi-scale Haar transforms also obtains satisfying experiment results, which prove that the feature is free from the extraction methods. Extensive experiments conducted on FRGC(Face Recognition Grand Challenge) v2.0 show a satisfactory performance compared with existing popular methods. It is also approved that the vertical shape information is promising for dealing with face expressions in 3D face recognition. © 2015 Elsevier GmbH. All rights reserved.},
author_keywords={3D face feature;  Geometry image;  Vertical shape information},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang20153357,
author={Zhang, C. and Gu, Y. and Wang, Y. and Li, F. and Zhan, Y. and Pi, J. and Qu, L.},
title={Adaptive multiple regions matching for 3D face recognition under expression and pose variations},
journal={Journal of Computational Information Systems},
year={2015},
volume={11},
number={9},
pages={3357-3369},
doi={10.12733/jcis14297},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938320850&doi=10.12733%2fjcis14297&partnerID=40&md5=af76d7b96bb6eca2db8bc3e1babc780a},
affiliation={Key Laboratory of Wireless Sensor Network & Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, 200050, China; University of Chinese Academy of Sciences, Beijing, 100049, China; Shanghai Internet of Things Co., Ltd., Shanghai, 201800, China},
abstract={Expression and pose variations are two major challenges for 3D face recognition. This paper presents a method to cope with these two challenges by fusing the matching results of adaptive multiple regions on the 3D face. First, one approach is proposed for pose correction of 3D face based on three landmark points: nose tip, nasion, and subnasale. Then multiple regions are adaptively chosen from the facial surface, which include nose, left and right eye-forehead regions, left and right cheeks, and mouth-chin region. Next, a least trimmed square Hausdorff distance method is applied for region matching. Moreover, to obtain a better overall performance, several score-level and rank-level fusion schemes are used to fuse the contribution of each region. The proposed approach is evaluated on the Bosphorus and the BU-3DFE databases, and yields good results. The study shows that the proposed algorithm is robust to expression and pose changes. ©, 2015, Binary Information Press. All right reserved.},
author_keywords={3D face recognition;  Expression;  Pose correction;  Pose rotation;  Region matching},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Xue2015,
author={Xue, J. and Su, X. and Zhang, Q.},
title={High-speed 3D face measurement based on color speckle projection},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9302},
doi={10.1117/12.2076458},
art_number={93022Y},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924939644&doi=10.1117%2f12.2076458&partnerID=40&md5=6eb59f4ca5a72e8c2457421e42cda527},
affiliation={School of Aeronautics and Astronautics, Sichuan University, Chengdu, 610065, China; Department of Opto-Electronics Science and Technology, Sichuan University, Chengdu, 610065, China},
abstract={Nowadays, 3D face recognition has become a subject of considerable interest in the security field due to its unique advantages in domestic and international. However, acquiring color-textured 3D faces data in a fast and accurate manner is still highly challenging. In this paper, a new approach based on color speckle projection for 3D face data dynamic acquisition is proposed. Firstly, the projector-camera color crosstalk matrix that indicates how much each projector channel influences each camera channel is measured. Secondly, the reference-speckle-sets images are acquired with CCD, and then three gray sets are separated from the color sets using the crosstalk matrix and are saved. Finally, the color speckle image which is modulated by face is captured, and it is split three gray channels. We measure the 3D face using multi-sets of speckle correlation methods with color speckle image in high-speed similar as one-shot, which greatly improves the measurement accuracy and stability. The suggested approach has been implemented and the results are supported by experiments. © 2015 SPIE.},
author_keywords={3D face measurement;  Color crosstalk;  Color speckle projection;  High-speed measurement},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chouchane2015,
author={Chouchane, A. and Belahcene, M. and Ouamane, A. and Bourennane, S.},
title={3D face recognition based on histograms of local descriptors},
journal={2014 4th International Conference on Image Processing Theory, Tools and Applications, IPTA 2014},
year={2015},
doi={10.1109/IPTA.2014.7001925},
art_number={7001925},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921721830&doi=10.1109%2fIPTA.2014.7001925&partnerID=40&md5=4bbf52130cd2484d05cce4611c376687},
affiliation={LMSE, University of Biskra, Biskra, R.P.07000, Algeria; Centre de Développement des Technologies Avancées, ASM Alger, Algeria; Institut Fresnel, UMR CNRS 7249, Ecole Centrale Marseille, France},
abstract={Face recognition in an uncontrolled condition such as illumination and expression variations is a challenging task. Local descriptor is one of the most efficient methods used to deal with these problems. In this paper, we present an automatic 3D face recognition approach based on three local descriptors, local phase quantization (LPQ), Three-Patch Local Binary Patterns (TPLBP) and Four-Patch Local Binary Patterns (TPLBP). Facial images are passing through one of the three descriptors and divided into sub-regions or rectangular blocks. The histogram of each sub-region is extracted and concatenated into a single feature vector. PCA (Principal Component Analysis) and EFM (Enhanced Fisher linear discriminant Model) are used to reduce the dimensionality of the resulting feature vectors. Finally, these vectors are sent to the classification step, when we use two methods; SVM (Support Victor Machine) and similarity measures. CASIA 3D face database is introduced to experimental evaluation. The experimental results illustrate a high recognition performance of the proposed approach. © 2014 IEEE.},
author_keywords={3D face recognition;  FPLBP;  Local phase quantization;  Locale descriptors;  Support vector machines;  TPLBP},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chouchane201550,
author={Chouchane, A. and Belahcene, M. and Bourennane, S.},
title={3D and 2D face recognition using integral projection curves based depth and intensity images},
journal={International Journal of Intelligent Systems Technologies and Applications},
year={2015},
volume={14},
number={1},
pages={50-69},
doi={10.1504/IJISTA.2015.072219},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964744543&doi=10.1504%2fIJISTA.2015.072219&partnerID=40&md5=e5008a255876319ef73de7c015360bc8},
affiliation={Faculty of Science and Technology, Department of Electrical Engineering, University of Mohamed Khider, Biskra, BP 145 RP, Biskra, 07000, Algeria; Institut Fresnel, UMR CNRS 7249, Ecole Centrale Marseille, France},
abstract={This paper presents an automatic face recognition system in the presence of illumination, expressions and pose variations based on depth and intensity information. At first, the registration of 3D faces is achieved using iterative closest point (ICP). Nose tip point must be located using Maximum Intensity Method. This point usually has the largest depth value; however there is a problem with some unnecessary data such as: shoulders, hair, neck and parts of clothes; to cope with this issue, we propose the integral projection curves (IPC)-based facial area segmentation to extract the facial area. After that, the combined method principal component analysis (PCA) with enhanced fisher model (EFM) is used to obtain the feature matrix vectors. Finally, the classification is performed using distance measurement and support vector machine (SVM). The experiments are implemented on two face databases CASIA3D and GavabDB; our results show that the proposed method achieves a high recognition performance. Copyright © 2015 Inderscience Enterprises Ltd.},
author_keywords={2D and 3D face recognition;  EFM;  Enhanced fisher model;  IPC-based facial area segmentation;  Nose tip;  PCA;  Principal component analysis;  Support vector machine;  SVM},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lagorio2015,
author={Lagorio, A. and Cadoni, M. and Grosso, E. and Tistarelli, M.},
title={A 3D algorithm for unsupervised face identification},
journal={3rd International Workshop on Biometrics and Forensics, IWBF 2015},
year={2015},
doi={10.1109/IWBF.2015.7110239},
art_number={7110239},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936101701&doi=10.1109%2fIWBF.2015.7110239&partnerID=40&md5=65b942c6e6bd6ec99d853a5a632cd56f},
affiliation={VisionLab - Computer Vision Laboratory, United Kingdom},
abstract={With the increasing availability of low-cost 3D data acquisition devices, the use of 3D face data for the recognition of individuals is becoming more appealing and computationally feasible. This paper proposes a completely automatic algorithm for face registration and matching. The algorithm is based on the extraction of stable 3D facial features characterizing the face and the subsequent construction of a signature manifold. The facial features are extracted by performing a continuous-to-discrete scale-space analysis. Registration is driven from the matching of triplets of feature points and the registration error is computed as shape matching score. Conversely to most techniques in the literature, a major advantage of the proposed method is that no data pre-processing is required. Therefore all presented results have been obtained exclusively from the raw data available from the 3D acquisition device. The method has been tested on the Bosphorus 3D face database and the performances compared to the ICP baseline algorithm. Even in presence of noise in the data, the algorithm proved to be very robust and reported identification performances which are aligned to the current state of the art, but without requiring any pre-processing of the raw data. © 2015 IEEE.},
author_keywords={3D Face recognition;  Face recognition},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu20152759,
author={Liu, X. and Yang, G. and Sun, X.},
title={A new strategy for 3D face recognition},
journal={Journal of Information and Computational Science},
year={2015},
volume={12},
number={7},
pages={2759-2768},
doi={10.12733/jics20105863},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929754542&doi=10.12733%2fjics20105863&partnerID=40&md5=2f790a80a714665fcf2c18c84c9d3346},
affiliation={Department of Computer, Shandong Institute of Business and Technology, Yantai, 264005, China; Engineering Training Center, Yantai University, Yantai, 264005, China},
abstract={This paper discusses the improved method for 3D face recognition. The novel method is introduced in detail. By the Thin Plate Spline (TPS) transformation, the negative effects caused by expressions and postures are weakened. In order to reduce the time for registration, the template face is used for the process of registration. After a series of registration process, the point set distance is calculated. The face that with the smallest point set distance to the query face is selected as the final recognition result. The method for the temp template face acquiring and the method for registration are improved. To reserve the original face feature to a large extent, the temp template face is selected from the original face set, and some registration is directly processed between the template face and original face set. Experiment results show that the new method of this paper has better identification rate and higher operating efficiency. Copyright © 2015 Binary Information Press.},
author_keywords={Face recognition;  Improved;  Recognition;  Registration;  Template face},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wu2015,
author={Wu, Y. and Cheng, Y. and Yang, N.},
title={3D face recognition algorithm of alignment and fitting},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9631},
doi={10.1117/12.2197158},
art_number={96311A},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946042352&doi=10.1117%2f12.2197158&partnerID=40&md5=a23ce1e3c95831e97dd1ba3873a690aa},
affiliation={Department of Command and Automation, Dalian Air Force Communication NCO Academy, Dalian Liaoning, 116100, China},
abstract={For 3D face recognition area, Design a algorithm follows a morphable model approach. To align the scan with a model, ICP and spin-images are used also referred to as registration. Deformation is done by a nonrigid ICP algorithm to fit the model with the scan. From the fitted model a geometry image and a normal image is generated. The developed algorithm is tested by several measurements. From the results of these measurements, it could be concluded that the algorithm is robust and reliable. © 2015 SPIE.},
author_keywords={Eigenfaces;  Face recognition;  Spin-image;  Transformation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Said2015,
author={Said, S. and Jemai, O. and Zaied, M. and Ben Amar, C.},
title={3D fast wavelet network model-assisted 3D face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9875},
doi={10.1117/12.2228368},
art_number={98750E},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958206236&doi=10.1117%2f12.2228368&partnerID=40&md5=e95e90acc2067f0a5a38e384b37d87d2},
affiliation={REsearch Groups in Intelligent Machines (REGIM-Lab), University of Sfax, National Engineering School of Sfax, BP 1173, Sfax, 3038, Tunisia},
abstract={In last years, the emergence of 3D shape in face recognition is due to its robustness to pose and illumination changes. These attractive benefits are not all the challenges to achieve satisfactory recognition rate. Other challenges such as facial expressions and computing time of matching algorithms remain to be explored. In this context, we propose our 3D face recognition approach using 3D wavelet networks. Our approach contains two stages: learning stage and recognition stage. For the training we propose a novel algorithm based on 3D fast wavelet transform. From 3D coordinates of the face (x,y,z), we proceed to voxelization to get a 3D volume which will be decomposed by 3D fast wavelet transform and modeled after that with a wavelet network, then their associated weights are considered as vector features to represent each training face. For the recognition stage, an unknown identity face is projected on all the training WN to obtain a new vector features after every projection. A similarity score is computed between the old and the obtained vector features. To show the efficiency of our approach, experimental results were performed on all the FRGC v.2 benchmark. © 2015 SPIE.},
author_keywords={3D face recognition;  Fast wavelet transform;  Wavelet network},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Soltanpour2015,
author={Soltanpour, S. and Wu, Q.M.J. and Anvaripour, M.},
title={Multimodal 2D-3D face recognition using structural context and pyramidal shape index},
journal={IET Seminar Digest},
year={2015},
volume={2015},
number={5},
doi={10.1049/ic.2015.0100},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946097401&doi=10.1049%2fic.2015.0100&partnerID=40&md5=a74cf5dc0ae25ab330b63f02f8787fde},
affiliation={Department of Electrical and Computer Engineering, University of Windsor, Canada},
abstract={Combination of 2D and 3D face recognition approaches intensifies recognition accuracy. In this paper, we propose a new algorithm for face recognition by applying hybrid approach, structural context and pyramidal shape index. Proposed pyramidal local shape index descriptors are extracted in each level or scale of the Gaussian pyramid of range image. In this way, we can extract high contrast and reliable 3D face features. We extract Scale Invariant Feature Transform on pyramidal shape index image and histogram of structural context is used to find matched key points. A local descriptor structural context represents the structure of the image using SIFT. Structural context histogram is applied in both texture and range images to find SIFT matched points as 2D and 3D matching score respectively. Score level fusion using sum rule is applied to get final matching score. Experimental results on Face Recognition Grand Challenge (FRGC v2.0) database illustrate detection rate 98.8% and 98.5% at 0.1% false acceptance rate for All vs. All and ROC III experiments respectively. Comparing to the state of the art, these are the best results.},
author_keywords={3D face recognition;  Gaussian pyramid;  Shape index;  SIFT;  Structural context},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Quy2015117,
author={Quy, N.H. and Quoc, N.H. and Anh, N.T.L. and Yang, H.-J. and Bao, P.T.},
title={3D human face recognition using sift descriptors of face’s feature regions},
journal={Studies in Computational Intelligence},
year={2015},
volume={572},
pages={117-126},
doi={10.1007/978-3-319-10774-5_11},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921639289&doi=10.1007%2f978-3-319-10774-5_11&partnerID=40&md5=d996f0febf2256df0de13d2ef642f8a2},
affiliation={University of Science, Ho Chi Minh City, Viet Nam; Department of Computer Engineering, Chonnam National University, South Korea},
abstract={Many researches in 3D face recognition problem have been studied because of adverse effects of human’s age, emotions, and environmental conditions on 2D models. In this paper, we propose a novel method for recognizing 3D faces. First, a 3D human face is normalized and determined regions of interest (ROI). Second, SIFT algorithm is applied to these ROIs for detecting invariant feature points. Finally, this descriptor, extracted from a training image, will be stored and later used to identify the face in a test image. For performing reliable recognition, we also adjust parameters of SIFT algorithm to fit own characteristics of the template database. In our experiments, the proposed method produces promising performance up to 84.6% of accuracy when using 3D Notre Dame biometric data-TEC. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  Range images;  SIFT descriptors},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu2015151,
author={Liu, S. and Mu, Z. and Huang, H.},
title={3D face recognition fusing spherical depth map and spherical texture map},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9428},
pages={151-159},
doi={10.1007/978-3-319-25417-3_19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950277767&doi=10.1007%2f978-3-319-25417-3_19&partnerID=40&md5=828cf646ebe1b2dd0a70ea3a6fdb0939},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Computing Center, Beijing Information Science and Technology University, Beijing, 100192, China},
abstract={Face recognition in unconstrained environments is often influenced by pose variations. And the problem is basically the identification that uses partial data. In this paper, a method fusing structure and texture information is proposed to solve the problem. In the register phase, the approximate 180 degree information of face is acquired, and the data used to identify individual is obtained from a random single view. Pure face is extracted from 3D data first, then convert the original data to the form of spherical depth map (SDM) and spherical texture map (STM), which are invariant to out-plane rotation, subsequently facilitating the successive alignment-free identification that is robust to pose variations. We make identification through sparse representation for its well performance with the two maps. Experiments show that our proposed method gets a high recognition rate with pose and expression variations. © Springer International Publishing Switzerland 2015.},
author_keywords={Face recognition;  Sparse representation;  Spherical Depth Map;  Spherical Texture Map},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Schimbinschi2015180,
author={Schimbinschi, F. and Schomaker, L. and Wiering, M.},
title={Ensemble methods for robust 3D face recognition using commodity depth sensors},
journal={Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015},
year={2015},
pages={180-187},
doi={10.1109/SSCI.2015.36},
art_number={7376609},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964959816&doi=10.1109%2fSSCI.2015.36&partnerID=40&md5=fd84168d29ae9b46a6cbb844ab04e5cf},
affiliation={Department of Computing and Information Systems, University of Melbourne, Melbourne, VIC, Australia; Institute of Artificial Intelligence and Cognitive Engineering, University of Groningen, Groningen, Netherlands},
abstract={In this paper we introduce a new dataset and pose invariant sampling method and describe the ensemble methods used for recognizing faces in 3D scenes, captured using commodity depth sensors. We use the 3D SIFT key point detector to take advantage of the similarities between faces, which leads to a set of points of interest based on the curvature of the face. For all key points, features are extracted using a 3D feature descriptor. Then, a variable-sized amount of features are generated per each 3D face image. The first ensemble method we constructed uses a K-nearest neighbors classifier to classify each key point-sampled feature vector as belonging to one of the subjects recorded in our dataset. All votes over all key points are combined. In the second ensemble technique, the key points are clustered with K-means, using the feature vectors and approximated sampling positions relative to the face. This leads to a set of experts that specialize for a specific region. Then a K-nearest neighbors classifier is trained on the examples falling in each expert's specialized region. Finally, for a new 3D face image, votes from all experts are combined in a sum ensemble technique to categorize the 3D face. We also introduce 6 new "real world" datasets with different variances: 3 types of 3D rotations, distance to sensor, expressions, and an all-in-one dataset. The results show very high cross validation accuracies for the same type of variance. In addition, 36 variance specific pair-Tests in which the system is trained on one dataset and tested on a completely different dataset also show encouraging results. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Svoboda2015452,
author={Svoboda, J. and Bronstein, M.M. and Drahansky, M.},
title={Contactless biometric hand geometry recognition using a low-cost 3D camera},
journal={Proceedings of 2015 International Conference on Biometrics, ICB 2015},
year={2015},
pages={452-457},
doi={10.1109/ICB.2015.7139109},
art_number={7139109},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943329089&doi=10.1109%2fICB.2015.7139109&partnerID=40&md5=088b980bbb44eef1cfc61d3c229e1b06},
affiliation={Faculty of Informatics, Universita della Svizzera Italiana, Lugano, Switzerland; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic},
abstract={In the past decade, the interest in using 3D data for biometric person authentication has increased significantly, propelled by the availability of affordable 3D sensors. The adoption of 3D features has been especially successful in face recognition applications, leading to several commercial 3D face recognition products. In other biometric modalities such as hand recognition, several studies have shown the potential advantage of using 3D geometric information, however, no commercial-grade systems are currently available. In this paper, we present a contactless 3D hand recognition system based on the novel Intel RealSense camera, the first mass-produced embeddable 3D sensor. The small form factor and low cost make this sensor especially appealing for commercial biometric applications, however, they come at the price of lower resolution compared to more expensive 3D scanners used in previous research. We analyze the robustness of several existing 2D and 3D features that can be extracted from the images captured by the RealSense camera and study the use of metric learning for their fusion. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Vijayalakshmi20151,
author={Vijayalakshmi, G.V. and Joseph Raj, A.N. and Ashok Varma, S.V.S.K.},
title={Optimum selection of features for 2D (color) and 3D (depth) face recognition using modified PCA (2D)},
journal={2014 IEEE International Conference on "Smart Structures and Systems", ICSSS 2014},
year={2015},
pages={1-7},
doi={10.1109/ICSSS.2014.7006175},
art_number={7006175},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922421135&doi=10.1109%2fICSSS.2014.7006175&partnerID=40&md5=1ebe3cb224d86125718e03677dc69b96},
affiliation={SENSE, VIT University, Vellore, India},
abstract={The paper proposes a Modified Principal Component Analysis coined as 2DPCA to compare 2D and 3D face recognition. In 2DPCA a covariance matrix of image is obtained directly from the original image and is used to find the eigenvectors for image feature extraction. Here the Texas 3D +AFs-1+AF0- face recognition database was considered, which has 1149 pairs of high resolution, preprocessed and pose normalized color and range images. These images are pixel-to-pixel registered and of resolution of 751×501 pixels. The experiment performed using the images reconstructed from feature vectors demonstrated that depth information was beneficial in representing and recognizing the face with least number of principal components. © 2014 IEEE.},
author_keywords={2D(RGB) image;  2DPCA;  3D (Depth) image;  eigen faces;  eigen vectors;  face recognition;  feature extraction;  Principal Component Analysis (PCA)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tian2015499,
author={Tian, L. and Fan, C. and Ming, Y. and Shi, J.},
title={SRDANet: An efficient deep learning algorithm for face analysis},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9244},
pages={499-510},
doi={10.1007/978-3-319-22879-2_46},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985006693&doi=10.1007%2f978-3-319-22879-2_46&partnerID=40&md5=677312dc329735134faf0a8467c2ea50},
affiliation={Beijing Key Laboratory of Work Safety Intelligent Monitoring, School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China},
abstract={In this work, we take advantage of the superiority of Spectral Graph Theory in classification application and propose a novel deep learning framework for face analysis which is called Spectral Regression Discriminant Analysis Network (SRDANet). Our SRDANet model shares the same basic architecture of Convolutional Neural Network (CNN),which comprises three basic components: convolutional filter layer, nonlinear processing layer and feature pooling layer. While it is different from traditional deep learning network that in our convolutional layer, we extract the leading eigenvectors from patches in facial image which are used as filter kernels instead of randomly initializing kernels and update them by stochastic gradient descent (SGD). And the output of all cascaded convolutional filter layers is used as the input of nonlinear processing layer. In the following nonlinear processing layer, we use hashing method for nonlinear processing. In feature pooling layer, the block-based histograms are employed to pooling output features instead of max-pooling technique. At last, the output of feature pooling layer is considered as one final feature output of our model. Different from the previous single-task research for face analysis, our proposed approach demonstrates an excellent performance in face recognition and expression recognition with 2D/3D facial images simultaneously. Extensive experiments conducted on many different face analysis databases demonstrate the efficiency of our proposed SRDANet model. Databases such as Extended Yale B, PIE, ORL are used for 2D face recognition, FRGC v2 is used for 3D face recognition and BU-3DFE is used for 3D expression recognition. © Springer International Publishing Switzerland 2015.},
author_keywords={Deep learning;  Expression recognition;  Face recognition;  Spectral regression discriminant analysis;  SRDA network},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{MatíasdiMartino2015176,
author={Matías di Martino, J. and Fernández, A. and Ferrari, J.},
title={One-shot 3D-gradient method applied to face recognition},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9423},
pages={176-183},
doi={10.1007/978-3-319-25751-8_22},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983485990&doi=10.1007%2f978-3-319-25751-8_22&partnerID=40&md5=d1ca3b0d2eb47528de1f16f2734dc918},
affiliation={Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay},
abstract={In this work we describe a novel one-shot face recognition setup. Instead of using a 3D scanner to reconstruct the face, we acquire a single photo of the face of a person while a rectangular pattern is been projected over it. Using this unique image, it is possible to extract 3D low-level geometrical features without the explicit 3D reconstruction. To handle expression variations and occlusions that may occur (e.g. wearing a scarf or a bonnet), we extract information just from the eyes-forehead and nose regions which tend to be less influenced by facial expressions. Once features are extracted, SVM hyper-planes are obtained from each subject on the database (one vs all approach), then new instances can be classified according to its distance to each of those hyper-planes. The advantage of our method with respect to other ones published in the literature, is that we do not need and explicit 3D reconstruction. Experiments with the Texas 3D Database and with new acquired data are presented, which shows the potential of the presented framework to handle different illumination conditions, pose and facial expressions. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  Differential 3D reconstruction},
document_type={Conference Paper},
source={Scopus},
}
