
@ARTICLE{Shi2019455,
author={Shi, B. and Zang, H. and Zheng, R. and Zhan, S.},
title={An efficient 3D face recognition approach using Frenet feature of iso-geodesic curves},
journal={Journal of Visual Communication and Image Representation},
year={2019},
volume={59},
pages={455-460},
doi={10.1016/j.jvcir.2019.02.002},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061129042&doi=10.1016%2fj.jvcir.2019.02.002&partnerID=40&md5=8f0fe3cd51ff2049c71bfe756a9bf6d6},
affiliation={School of Computer and Information, Hefei University of Technology, Hefei, 230009, China},
abstract={Extracting efficient features from the large volume of 3D facial data directly is extremely difficult in 3D face recognition (3D-FR) with the latest methods, which mostly require heavy computations and manual processing steps. This paper presents a computationally efficient 3D-FR system based on a novel Frenet frame-based feature that is derived from the 3D facial iso-geodesic curves. In terms of the evaluation of the proposed method, we conducted a number of experiments on the CASIA 3D face database, and a superior recognition performance has been achieved. The performance evaluation suggests that the pose invariance attribute of the features relieves the need of an expensive 3D face registration in the face preprocessing procedure, where we take less time to process conversely. Our experiments further demonstrate that the proposed method not only achieves competitive recognition performance when compared with some existing techniques for 3D-FR, but also is computationally efficient. © 2019 Elsevier Inc.},
author_keywords={3D face recognition;  Facial curves;  Frenet framework;  Iso-geodesic;  Pose invariant},
document_type={Article},
source={Scopus},
}

@ARTICLE{Neto2019594,
author={Neto, J.B.C. and Marana, A.N.},
title={3D face recognition with reconstructed faces from a collection of 2D images},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11401 LNCS},
pages={594-601},
doi={10.1007/978-3-030-13469-3_69},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063066921&doi=10.1007%2f978-3-030-13469-3_69&partnerID=40&md5=ae38ed3a54a47df05e22f1ec3db64720},
affiliation={São Carlos Federal University - UFSCAR, São Carlos, SP  13565-905, Brazil; UNESP - São Paulo State University, Bauru, SP  17033-360, Brazil},
abstract={Nowadays, there is an increasing need for systems that can accurately and quickly identify a person. Traditional identification methods utilize something a person knows or something a person has. This kind of methods has several drawbacks, being the main one the fact that it is impossible to detect an imposter who uses genuine credentials to pass as a genuine person. One way to solve these kinds of problems is to utilize biometric identification. The face is one of the biometric features that best suits the covert identification. However, in general, biometric systems based on 2D face recognition perform very poorly in unconstrained environments, common in covert identification scenarios, since the input images present variations in pose, illumination, and facial expressions. One way to mitigate this problem is to use 3D face data, but the current 3D scanners are expensive and require a lot of cooperation from people being identified. Therefore, in this work, we propose an approach based on local descriptors for 3D Face Recognition based on 3D face models reconstructed from collections of 2D images. Initial results show 95% in a subset of the LFW Face dataset. © Springer Nature Switzerland AG 2019.},
author_keywords={3D face recognition;  3DLBP;  Biometrics;  Face reconstruction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hajati2019936,
author={Hajati, F. and Cheraghian, A. and Ameri Sianaki, O. and Zeinali, B. and Gheisari, S.},
title={Polar Topographic Derivatives for 3D Face Recognition: Application to Internet of Things Security},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={927},
pages={936-945},
doi={10.1007/978-3-030-15035-8_92},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064875340&doi=10.1007%2f978-3-030-15035-8_92&partnerID=40&md5=a1997efd234042ace42c04b05607ab05},
affiliation={College of Engineering and Science, Victoria University Sydney, Sydney, Australia; College of Engineering and Computer Science, The Australian National University, Canberra, Australia; Electrical Engineering Department, Iran University of Science and Technology, Tehran, Iran; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia},
abstract={We propose Polar Topographic Derivatives (PTD) to fuse the shape and texture information of a facial surface for 3D face recognition. Polar Average Absolute Deviations (PAADs) of the Gabor topography maps are extracted as features. High-order polar derivative patterns are obtained by encoding texture variations in a polar neighborhood. By using the and Bosphorus 3D face database, our method shows that it is robust to expression and pose variations comparing to existing state-of-the-art benchmark approaches. © 2019, Springer Nature Switzerland AG.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Peter201977,
author={Peter, M. and Minoi, J.-L. and Hipiny, I.H.M.},
title={3D face recognition using kernel-based PCA approach},
journal={Lecture Notes in Electrical Engineering},
year={2019},
volume={481},
pages={77-86},
doi={10.1007/978-981-13-2622-6_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053242189&doi=10.1007%2f978-981-13-2622-6_8&partnerID=40&md5=c4b90626b4453034107d227cbd63ef3d},
affiliation={Faculty of Computer Science and Information Technology, Universiti Malaysia SarawakSarawak, Malaysia},
abstract={Face recognition is commonly used for biometric security purposes in video surveillance and user authentications. The nature of face exhibits non-linear shapes due to appearance deformations, and face variations presented by facial expressions. Recognizing faces reliably across changes in facial expression has proved to be a more difficult problem leading to low recognition rates in many face recognition experiments. This is mainly due to the tens degree-of-freedom in a non-linear space. Recently, non-linear PCA has been revived as it posed a significant advantage for data representation in high dimensionality space. In this paper, we experimented the use of non-linear kernel approach in 3D face recognition and the results of the recognition rates have shown that the kernel method outperformed the standard PCA. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={3D face;  Facial recognition;  Kernel PCA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dutta2019175,
author={Dutta, K. and Bhattacharjee, D. and Nasipuri, M. and Poddar, A.},
title={3D face recognition based on volumetric representation of range image},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={883},
pages={175-189},
doi={10.1007/978-981-13-3702-4_11},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061157145&doi=10.1007%2f978-981-13-3702-4_11&partnerID=40&md5=2543d63ceec9074d39578ea3320cdfbd},
affiliation={Department of Computer Science and Engineering, Jadavpur University, Kolkata, West Bengal, India; Computer Science Engineering, Birla Institute of Technology, Mesra, Ranchi, India},
abstract={In this paper, a 3D face recognition system has been developed based on the volumetric representation of 3D range image. The main approach to build this system is to calculate volume on some distinct region of 3D range face data. The system has mainly three steps. In the very first step, seven significant facial landmarks are identified on the face. Secondly, six distinct triangular regions A to F are created on the face using any three individual landmarks where nose tip is common to all regions. Further 3D volumes of all the respective triangular regions have been calculated based on plane fitting on the input range images. Finally, KNN and SVM classifiers are considered for classification. Initially, the classification and recognition are carried out on the different volumetric region, and a further combination of all the regions is considered. The proposed approach is tested on three useful challenging databases, namely Frav3D, Bosphorous, and GavabDB. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={3D range image;  Classification;  Facial landmark;  Plane fitting;  Volumetric representation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{ZulqarnainGilani20181896,
author={Zulqarnain Gilani, S. and Mian, A.},
title={Learning from Millions of 3D Scans for Large-Scale 3D Face Recognition},
journal={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
year={2018},
pages={1896-1905},
doi={10.1109/CVPR.2018.00203},
art_number={8578301},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060207182&doi=10.1109%2fCVPR.2018.00203&partnerID=40&md5=7a2227c884147feae86f1d25240e9a7a},
affiliation={Computer Science and Software Engineering, University of Western Australia, Australia},
abstract={Deep networks trained on millions of facial images are believed to be closely approaching human-level performance in face recognition. However, open world face recognition still remains a challenge. Although, 3D face recognition has an inherent edge over its 2D counterpart, it has not benefited from the recent developments in deep learning due to the unavailability of large training as well as large test datasets. Recognition accuracies have already saturated on existing 3D face datasets due to their small gallery sizes. Unlike 2D photographs, 3D facial scans cannot be sourced from the web causing a bottleneck in the development of deep 3D face recognition networks and datasets. In this backdrop, we propose a method for generating a large corpus of labeled 3D face identities and their multiple instances for training and a protocol for merging the most challenging existing 3D datasets for testing. We also propose the first deep CNN model designed specifically for 3D face recognition and trained on 3.1 Million 3D facial scans of 100K identities. Our test dataset comprises 1,853 identities with a single 3D scan in the gallery and another 31K scans as probes, which is several orders of magnitude larger than existing ones. Without fine tuning on this dataset, our network already outperforms state of the art face recognition by over 10%. We fine tune our network on the gallery set to perform end-to-end large scale 3D face recognition which further improves accuracy. Finally, we show the efficacy of our method for the open world face recognition problem. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Reji2018,
author={Reji, R. and Sojanlal, P.},
title={Region Based 3D Face Recognition},
journal={2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
year={2018},
doi={10.1109/ICCIC.2017.8524581},
art_number={8524581},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057946157&doi=10.1109%2fICCIC.2017.8524581&partnerID=40&md5=92c092fa4e2838ab444fcc0356fcdb75},
affiliation={Mahatma Gandhi University, School of Computer Sciences, Kottayam, Kerala, India; Mar-Baselious Institute of Technology Science, Kothamangalam, Kerala, India},
abstract={This paper focuses on a region based methodology for expression in sensitive 3D face recognition process. Considering facial regions that are comparatively unchanging during expressions, results shows that using fifteen sub regions on the face can attain high 3D face recognition. We use a modified face recognition algorithm along with hierarchical contour based image registration for finding the similarity score. Our method operates in two modes: verification mode and confirmation mode. Crop 100 mm of frontal face region, apply preprocessing and automatically detect nose tip, translate the face image to origin and crop fifteen sub regions. The cropped sub regions are defined by cuboids which occupy more volumetric data, Nose Tip is the most projecting point of the face with the highest value along Z-axis so consider it as origin. The modified face recognition algorithm reduces the effects caused by facial expressions and artifacts. Finally a Hierarchical contour based image registration technique is applied which yields better results. The approach is applied on Bosphorus 3D datasets and achieved a verification rate of 95.3% at 0.1% false acceptance rate. In the identification scenario 99.3% rank one recognition is achieved. © 2017 IEEE.},
author_keywords={3D face recognition;  Biometrics;  Contour based image registration;  MFRA;  Rank based Score},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Siqueira20183513,
author={Siqueira, R.S. and Alexandre, G.R. and Soares, J.M. and The, G.A.P.},
title={Triaxial slicing for 3-D face recognition from adapted rotational invariants spatial moments and minimal keypoints dependence},
journal={IEEE Robotics and Automation Letters},
year={2018},
volume={3},
number={4},
pages={3513-3520},
doi={10.1109/LRA.2018.2854295},
art_number={8408720},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063307357&doi=10.1109%2fLRA.2018.2854295&partnerID=40&md5=5205595c202573ef77808eaf4aee1626},
affiliation={Faculty of Electrical Engineering, Instituto Federal de Educação, Ciência e Tecnologia Do Ceará, Fortaleza, CE 60410-42, Brazil; Department of Teleinformatics Engineering, Universidade Federal Do Ceará, Fortaleza, CE 60020-181, Brazil},
abstract={This letter presents a multiple slicing model for three-dimensional (3-D) images of human face, using the frontal, sagittal, and transverse orthogonal planes. The definition of the segments depends on just one key point, the nose tip, which makes it simple and independent of the detection of several key points. For facial recognition, attributes based on adapted 2-D spatial moments of Hu and 3-D spatial invariant rotation moments are extracted from each segment. Tests with the proposed model using the Bosphorus Database for neutral vs nonneutral ROC I experiment, applying linear discriminant analysis as classifier and more than one sample for training, achieved 98.7% of verification rate at 0.1% of false acceptance rate. By using the support vector machine as classifier the rank1 experiment recognition rates of 99% and 95.4% have been achieved for a neutral vs neutral and for a neutral vs non-neutral, respectively. These results approach the state-of-the-art using Bosphorus Database and even surpasses it when anger and disgust expressions are evaluated. In addition, we also evaluate the generalization of our method using the FRGC v2.0 database and achieve competitive results, making the technique promising, especially for its simplicity. © 2016 IEEE.},
author_keywords={Computer vision for automation;  recognition;  surveillance systems},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fei2018139,
author={Fei, H. and Tu, B. and Chen, Q. and He, D. and Zhou, C. and Peng, Y.},
title={An overview of face-related technologies},
journal={Journal of Visual Communication and Image Representation},
year={2018},
volume={56},
pages={139-143},
doi={10.1016/j.jvcir.2018.09.012},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053774931&doi=10.1016%2fj.jvcir.2018.09.012&partnerID=40&md5=ddfc4618812dd5bf104f59915ffc5af0},
affiliation={College of Information and Communication Engineering, School of Information Science and Technology, Hunan Institute of Science and Technology, Yueyang, China; School of Computer and Information, Hefei University of Technology, Hefei, China},
abstract={In recent years, information technology is developing continuously and set off a burst of artificial intelligence boom in the field of science. The development of advanced technologies such as unmanned driving and AI chips, is the extensive application of artificial intelligence. Face-related technologies have a wide range of applications because of intuitive results and good concealment. Since 3D face information can provide more comprehensive facial information than 2D face information, and it can solve many difficulties that cannot be solved in 2D face recognition. Therefore, more and more researchers have studied 3D face recognition in recent years. Under the new circumstances, the research on face are experiencing all kinds of challenges. With the tireless of many scientists, the new technology is also making a constant progress, and in the development of many technologies it still maintained its leading position. In this paper, we simply sort out the present development process of facial correlation technology, and the general evolution of this technology is outlined. Finally, the practical significance of this technology development is briefly discussed. © 2018},
author_keywords={3D face reconstruction;  Deep learning;  Face enhancement;  Face recognition},
document_type={Article},
source={Scopus},
}

@ARTICLE{Abbad2018525,
author={Abbad, A. and Abbad, K. and Tairi, H.},
title={3D face recognition: Multi-scale strategy based on geometric and local descriptors},
journal={Computers and Electrical Engineering},
year={2018},
volume={70},
pages={525-537},
doi={10.1016/j.compeleceng.2017.08.017},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028606046&doi=10.1016%2fj.compeleceng.2017.08.017&partnerID=40&md5=5414b01946f345f018c49654dff50957},
affiliation={LIIAN, Department of Computer Science, Faculty of Sciences Dhar El Mahraz University Sidi Mohamed Ben Abdelah, Fez, Morocco; LISA, Department of Computer Science, Faculty of Science and Technology University Sidi Mohamed Ben Abdelah, Fez, Morocco},
abstract={Most human expression variations cause a non-rigid deformation of face scans, which is a challenge today. In this article, we present a novel framework for 3D face recognition that uses a geometry and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. This algorithm consists of four major components. First, the 3D face model is presented at different scales. Second, isometric-invariant features on each scale are extracted. Third, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Fourth, the feature vectors on each scale are concatenated with their corresponding geometric information. We conducted a number of experiments using two well-known and challenging datasets, namely, the GavabDB and Bosphorus datasets, and superior recognition performance has been achieved. The new system displays an overall rank-1 identification rate of 98.9% for all faces with neutral and non-neutral expressions on the GavabDB database. © 2017 Elsevier Ltd},
author_keywords={3D face recognition;  Expression;  Facial curves;  Geometric features;  Local features},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gao2018120,
author={Gao, J. and Evans, A.N.},
title={Expression robust 3D face landmarking using thresholded surface normals},
journal={Pattern Recognition},
year={2018},
volume={78},
pages={120-132},
doi={10.1016/j.patcog.2018.01.011},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042375361&doi=10.1016%2fj.patcog.2018.01.011&partnerID=40&md5=a93105edc5d4f49296e9c43d397e9898},
affiliation={Department of Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden; Department of Electronic and Electrical Engineering, University of Bath, Bath, United Kingdom},
abstract={3D face recognition is an increasing popular modality for biometric authentication, for example in the iPhoneX. Landmarking plays a significant role in region based face recognition algorithms. The accuracy and consistency of the landmarking will directly determine the effectiveness of feature extraction and hence the overall recognition performance. While surface normals have been shown to provide high performing features for face recognition, their use in landmarking has not been widely explored. To this end, a new 3D facial landmarking algorithm based on thresholded surface normal maps is proposed, which is applicable to widely used 3D face databases. The benefits of employing surface normals are demonstrated for both facial roll and yaw rotation calibration and nasal landmarks localization. Results on the Bosphorus, FRGC and BU-3DFE databases show that the detected landmarks possess high within-class consistency and accuracy under different expressions. For several key landmarks the performance achieved surpasses that of state-of-the-art techniques and is also training free and computationally efficient. The use of surface normals therefore provides a useful representation of the 3D surface and the proposed landmarking algorithm provides an effective approach to localising the key nasal landmarks. © 2018 Elsevier Ltd},
author_keywords={3D face landmarking;  Surface normals},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ahdid201873,
author={Ahdid, R. and Taifi, K. and Said, S. and Fakir, M. and Manaut, B.},
title={Automatic face recognition system using iso-geodesic curves in riemanian manifold},
journal={Proceedings - 2017 14th International Conference on Computer Graphics, Imaging and Visualization, CGiV 2017},
year={2018},
pages={73-78},
doi={10.1109/CGiV.2017.25},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048323921&doi=10.1109%2fCGiV.2017.25&partnerID=40&md5=73b9e65d367cee00cdcb28e7b5ef55cb},
affiliation={Sultan Moulay Slimane University, Beni Mellal, Morocco},
abstract={In this paper, we present an automatic 3D face recognition system. This system is based on the representation of human faces surfaces as collections of Iso-Geodesic Curves (IGC) using 3D Fast Marching algorithm. To compare two facial surfaces, we compute a geodesic distance between a pair of facial curves using a Riemannian geometry. In the classifying step, we use: Neural Networks (NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this method and evaluate its performance, a simulation series of experiments were performed on 3D Shape REtrieval Contest 2008 database (SHREC2008). © 2017 IEEE.},
author_keywords={3D face recognition;  facial surfaces;  geodesic distance;  iso-geodesic curves;  Riemannian geometry},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NourbakhshKaashki201866,
author={Nourbakhsh Kaashki, N. and Safabakhsh, R.},
title={RGB-D face recognition under various conditions via 3D constrained local model},
journal={Journal of Visual Communication and Image Representation},
year={2018},
volume={52},
pages={66-85},
doi={10.1016/j.jvcir.2018.02.003},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042322207&doi=10.1016%2fj.jvcir.2018.02.003&partnerID=40&md5=2b91afeff8a19c987036cf8a30b610dc},
affiliation={Department of Computer Engineering, Amirkabir University of Technology, Tehran, Iran},
abstract={This research proposes a method for 3D face recognition in various conditions using 3D constrained local model (CLM-Z). In this method, a combination of 2D images (RGBs) and depth images (Ds) captured by Kinect has been used. After detecting the face and smoothing the depth image, CLM-Z model has been used to model and detect the important points of the face. These points are described using Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and 3D Local Binary Patterns (3DLBP). Finally, each face is recognized by a Support Vector Machine (SVM). The challenging situations are changes of lighting, facial expression and head pose. The results on CurtinFaces and IIIT-D datasets demonstrate that the proposed method outperformed state-of-the-art methods under illumination, expression and pitch pose conditions and comparable results were obtained in other cases. Additionally, our proposed method is robust even when the training data has not been carefully collected. © 2018 Elsevier Inc.},
author_keywords={3D constrained local model;  3D face recognition;  Depth image;  Face model;  Facial expression;  Feature descriptor;  Head pose;  Kinect;  Lighting},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Abbad20181,
author={Abbad, A. and Abbad, K. and Tairi, H.},
title={3D face recognition in the presence of facial expressions based on empirical mode decomposition},
journal={ACM International Conference Proceeding Series},
year={2018},
volume={2018-March},
pages={1-6},
doi={10.1145/3177148.3180087},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047112949&doi=10.1145%2f3177148.3180087&partnerID=40&md5=93db67c347fc7dadc31256f7eb69e983},
affiliation={Laboratory LIIAN, Faculty of Science, Dhar EL Mahraz, Morocco; Laboratory ISA, Faculty of Science and Technology, Morocco},
abstract={This paper presents an efficient 3D face recognition method to handle facial expression. The proposed method uses the Surfaces Empirical Mode Decomposition (SEMD), facial curves and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. The basic idea is that, the face is presented at different scales by SEMD. Then the isometric-invariant features on each scale are extracted. After that, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Finally, the feature vectors on each scale are associated with their corresponding geometric information. The presented method is validated on GavabDB database resulting a rank 1 recognition rate (RR) of 98.9% for all faces with neutral and non-neutral expressions. This result outperforms other 3D expression-invariant face recognition methods on the same database. © 2018 Association for Computing Machinery.},
author_keywords={3D face recognition;  EMD;  Expression;  Facial curves;  Geometric features;  Local features},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guo2018,
author={Guo, Y. and Wei, R. and Liu, Y.},
title={Weighted gradient feature extraction based on multiscale sub-blocks for 3d facial recognition in bimodal images},
journal={Information (Switzerland)},
year={2018},
volume={9},
number={3},
doi={10.3390/info9030048},
art_number={48},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042711391&doi=10.3390%2finfo9030048&partnerID=40&md5=fe75121af64143005ff6ec84435ed59d},
affiliation={School of Computer Science and Engineering, Hebei University of Technology, Tianjin, 300400, China},
abstract={In this paper, we propose a bimodal 3D facial recognition method aimed at increasing the recognition rate and reducing the effect of illumination, pose, expression, ages, and occlusion on facial recognition. There are two features extracted from the multiscale sub-blocks in both the 3D mode depth map and 2D mode intensity map, which are the local gradient pattern (LGP) feature and the weighted histogram of gradient orientation (WHGO) feature. LGP and WHGO features are cascaded to form the 3D facial feature vector LGP-WHGO, and are further trained and identified by the support vector machine (SVM). Experiments on the CASIA database, FRGC v2.0 database, and Bosphorus database show that, the proposed method can efficiently extract the structure information and texture information of the facial image, and have a robustness to illumination, expression, occlusion and pose. © 2018 by the authors.},
author_keywords={3D face recognition;  Bimodal;  Depth map;  Intensitymap;  LGP-WHGO;  Multiscale sub-blocks},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Soltanpour20182811,
author={Soltanpour, S. and Wu, Q.M.J.},
title={High-order local normal derivative pattern (LNDP) for 3D face recognition},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2018},
volume={2017-September},
pages={2811-2815},
doi={10.1109/ICIP.2017.8296795},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045292850&doi=10.1109%2fICIP.2017.8296795&partnerID=40&md5=12c33512c432220af4c4c49f5116433e},
affiliation={University of Windsor, Department of Electrical and Computer Engineering, Windsor, Canada},
abstract={This paper proposes a novel descriptor based on the local derivative pattern (LDP) for 3D face recognition. Compared to the local binary pattern (LBP), LDP can capture more detailed information by encoding directional pattern features. It is based on the local derivative variations that extract high-order local information. We propose a novel discriminative facial shape descriptor, local normal derivative pattern (LNDP) that extracts LDP from the surface normal. Using surface normal, the orientation of a surface at each point is determined as a first-order surface differential. Three normal component images are extracted by estimating three components of normal vectors in x, y, and z channels. Each normal component is divided into several patches and encoded using LDP. The final descriptor is created by concatenating histograms of the LNDP on each patch. Experimental results on two famous 3D face databases, FRGC v2.0 and Bosphorus illustrate the effectiveness of the proposed descriptor. © 2017 IEEE.},
author_keywords={3D face;  High-order local pattern;  Local derivative pattern;  Surface normal},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li20181295,
author={Li, Y. and Wang, Y. and Liu, J. and Hao, W.},
title={Expression-insensitive 3D face recognition by the fusion of multiple subject-specific curves},
journal={Neurocomputing},
year={2018},
volume={275},
pages={1295-1307},
doi={10.1016/j.neucom.2017.09.070},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040674183&doi=10.1016%2fj.neucom.2017.09.070&partnerID=40&md5=ecfea39a1b4d26ab1e33c34b50b87558},
affiliation={Institute of Computer Science & Engineering, Xi'an University of Technology, No.5 South Jinhua Road, Xi'an, 710048, China},
abstract={This study proposes a 3D face recognition method using multiple subject-specific curves insensitive to intra-subject distortions caused by expression variations. Considering that most sharp variances in facial convex regions are closely related to the bone structure, the convex crest curves are first extracted as the most vital subject-specific facial curves based on the principal curvature extrema in convex local surfaces. Then, the central profile curve and the horizontal contour curve passing through the nose tip are detected by using the precise localization of the nose tip and symmetry plane. Based on their discriminative power and robustness to expression changes, the three types of curves are fused with appropriate weights at the feature-level and used for matching 3D faces with the iterative closest point algorithm. The combination of multiple expression-insensitive curves is complementary and provides sufficient and stable facial surface features for face recognition. In addition, for each convex crest curve, an expression-irrelevant factor is assigned as the adaptive weight to improve the face matching performance. The results of experiments using two public 3D databases, GavabDB and BU-3DFE, demonstrate the effectiveness of the proposed method, and its recognition rates on both databases reflect an encouraging performance. © 2017 Elsevier B.V.},
author_keywords={3D face recognition;  Expression-insensitive;  Feature-level;  Fusion;  Subject-specific curve},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kim2018133,
author={Kim, D. and Hernandez, M. and Choi, J. and Medioni, G.},
title={Deep 3D face identification},
journal={IEEE International Joint Conference on Biometrics, IJCB 2017},
year={2018},
volume={2018-January},
pages={133-142},
doi={10.1109/BTAS.2017.8272691},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046247920&doi=10.1109%2fBTAS.2017.8272691&partnerID=40&md5=9660021125b86249b9768912252c19ff},
affiliation={USC Institute for Robotics and Intelligent Systems (IRIS), University of Southern California, United States},
abstract={We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D face expression augmentation technique. The performance of 2D face recognition algorithms has significantly increased by leveraging the representational power of deep neural networks and the use of large-scale labeled training data. In this paper, we show that transfer learning from a CNN trained on 2D face images can effectively work for 3D face recognition by fine-tuning the CNN with an extremely small number of 3D facial scans. We also propose a 3D face expression augmentation technique which synthesizes a number of different facial expressions from a single 3D face scan. Our proposed method shows excellent recognition results on Bosphorus, BU-3DFE, and 3D-TEC datasets without using hand-crafted features. The 3D face identification using our deep features also scales well for large databases. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2018234,
author={Li, H. and Sun, J. and Chen, L.},
title={Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition},
journal={IEEE International Joint Conference on Biometrics, IJCB 2017},
year={2018},
volume={2018-January},
pages={234-242},
doi={10.1109/BTAS.2017.8272703},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046291057&doi=10.1109%2fBTAS.2017.8272703&partnerID=40&md5=e5c4065442f8bc899597efdc443ed01c},
affiliation={School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, 710049, China; Department of Mathematics and Informatics, Ecole Centrale de Lyon, Lyon, 69134, France},
abstract={This paper presents a straight-forward yet efficient, and expression-robust 3D face recognition approach by exploring location sensitive sparse representation of deep normal patterns (DNP). In particular, given raw 3D facial surfaces, we first run 3D face pre-processing pipeline, including nose tip detection, face region cropping, and pose normalization. The 3D coordinates of each normalized 3D facial surface are then projected into 2D plane to generate geometry images, from which three images of facial surface normal components are estimated. Each normal image is then fed into a pre-trained deep face net to generate deep representations of facial surface normals, i.e., deep normal patterns. Considering the importance of different facial locations, we propose a location sensitive sparse representation classifier (LS-SRC) for similarity measure among deep normal patterns associated with different 3D faces. Finally, simple score-level fusion of different normal components are used for the final decision. The proposed approach achieves significantly high performance, and reporting rank-one scores of 98.01%, 97.60%, and 96.13% on the FRGC v2.0, Bosphorus, and BU-3DFE databases when only one sample per subject is used in the gallery. These experimental results reveals that the performance of 3D face recognition would be constantly improved with the aid of training deep models from massive 2D face images, which opens the door for future directions of 3D face recognition. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhao2018207,
author={Zhao, J.-L. and Wu, Z.-K. and Pan, Z.-K. and Duan, F.-Q. and Li, J.-H. and Lv, Z.-H. and Wang, K. and Chen, Y.-C.},
title={3D Face Similarity Measure by Fréchet Distances of Geodesics},
journal={Journal of Computer Science and Technology},
year={2018},
volume={33},
number={1},
pages={207-222},
doi={10.1007/s11390-018-1814-7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041342736&doi=10.1007%2fs11390-018-1814-7&partnerID=40&md5=8478bdecdc0eeeb6cb4dda3bb1ecda52},
affiliation={School of Data Science and Software Engineering, Qingdao University, Qingdao, 266071, China; College of Automation and Electrical Engineering, Qingdao University, Qingdao, 266071, China; College of Information Science and Technology, Beijing Normal University, Beijing, 100087, China; College of Computer Science and Technology, Qingdao University, Qingdao, 266071, China; School of Management, Capital Normal University, Beijing, 100048, China},
abstract={3D face similarity is a critical issue in computer vision, computer graphics and face recognition and so on. Since Fréchet distance is an effective metric for measuring curve similarity, a novel 3D face similarity measure method based on Fréchet distances of geodesics is proposed in this paper. In our method, the surface similarity between two 3D faces is measured by the similarity between two sets of 3D curves on them. Due to the intrinsic property of geodesics, we select geodesics as the comparison curves. Firstly, the geodesics on each 3D facial model emanating from the nose tip point are extracted in the same initial direction with equal angular increment. Secondly, the Fréchet distances between the two sets of geodesics on the two compared facial models are computed. At last, the similarity between the two facial models is computed based on the Fréchet distances of the geodesics obtained in the second step. We verify our method both theoretically and practically. In theory, we prove that the similarity of our method satisfies three properties: reflexivity, symmetry, and triangle inequality. And in practice, experiments are conducted on the open 3D face database GavaDB, Texas 3D Face Recognition database, and our 3D face database. After the comparison with iso-geodesic and Hausdorff distance method, the results illustrate that our method has good discrimination ability and can not only identify the facial models of the same person, but also distinguish the facial models of any two different persons. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={3D face;  Fréchet distance;  geodesic;  similarity measure},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lv2018,
author={Lv, C. and Zhao, J.},
title={3D Face Recognition based on Local Conformal Parameterization and Iso-Geodesic Stripes Analysis},
journal={Mathematical Problems in Engineering},
year={2018},
volume={2018},
doi={10.1155/2018/4707954},
art_number={4707954},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056267138&doi=10.1155%2f2018%2f4707954&partnerID=40&md5=6b9608dc984f786b68071250cc5e66cb},
affiliation={College of Information Science and Technology, Beijing Normal University, Beijing, China; Engineering Research Center of Virtual Reality and Applications, Ministry of Education, Beijing Key Laboratory of Digital Preservation, Beijing, 100875, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; College of Automation and Electrical Engineering, Qingdao University, Qingdao, China},
abstract={3D face recognition is an important topic in the field of pattern recognition and computer graphic. We propose a novel approach for 3D face recognition using local conformal parameterization and iso-geodesic stripes. In our framework, the 3D facial surface is considered as a Riemannian 2-manifold. The surface is mapped into the 2D circle parameter domain using local conformal parameterization. In the parameter domain, the geometric features are extracted from the iso-geodesic stripes. Combining the relative position measure, Chain 2D Weighted Walkthroughs (C2DWW), the 3D face matching results can be obtained. The geometric features from iso-geodesic stripes in parameter domain are robust in terms of head poses, facial expressions, and some occlusions. In the experiments, our method achieves a high recognition accuracy of 3D facial data from the Texas3D and Bosphorus3D face database. © 2018 Chenlei Lv and Junli Zhao.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ratyal20184903,
author={Ratyal, N. and Taj, I. and Bajwa, U. and Sajid, M.},
title={Pose and expression invariant alignment based multi-view 3d face recognition},
journal={KSII Transactions on Internet and Information Systems},
year={2018},
volume={12},
number={10},
pages={4903-4929},
doi={10.3837/tiis.2018.10.016},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057280833&doi=10.3837%2ftiis.2018.10.016&partnerID=40&md5=b7937933dbf1206dd6e5a81101a545c0},
affiliation={Vision and Pattern Recognition Systems Research Group, Capital University of Science and Technology (CUST), Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan},
abstract={In this study, a fully automatic pose and expression invariant 3D face alignment algorithm is proposed to handle frontal and profile face images which is based on a two pass course to fine alignment strategy. The first pass of the algorithm coarsely aligns the face images to an intrinsic coordinate system (ICS) through a single 3D rotation and the second pass aligns them at fine level using a minimum nose tip-scanner distance (MNSD) approach. For facial recognition, multi-view faces are synthesized to exploit real 3D information and test the efficacy of the proposed system. Due to optimal separating hyper plane (OSH), Support Vector Machine (SVM) is employed in multi-view face verification (FV) task. In addition, a multi stage unified classifier based face identification (FI) algorithm is employed which combines results from seven base classifiers, two parallel face recognition algorithms and an exponential rank combiner, all in a hierarchical manner. The performance figures of the proposed methodology are corroborated by extensive experiments performed on four benchmark datasets: GavabDB, Bosphorus, UMB-DB and FRGC v2.0. Results show mark improvement in alignment accuracy and recognition rates. Moreover, a computational complexity analysis has been carried out for the proposed algorithm which reveals its superiority in terms of computational efficiency as well. © 2018 KSII.},
author_keywords={3D alignment;  3D FR;  Profile face;  SVM;  Unified classifier},
document_type={Article},
source={Scopus},
}

@ARTICLE{Khan2018220,
author={Khan, M.S. and Jehanzeb, M. and Babar, M.I. and Faisal, S. and Ullah, Z. and Amin, S.Z.B.M.},
title={Face recognition analysis using 3D model},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2018},
volume={200},
pages={220-236},
doi={10.1007/978-3-319-95450-9_19},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051123902&doi=10.1007%2f978-3-319-95450-9_19&partnerID=40&md5=3b4f204837bae6e24de550e8aa4fd707},
affiliation={College of Computer Science, Sichuan University, Chengdu, 610065, China; Department of Computer Science, Army Public College of Management & Sciences (APCOMS), Rawalpindi, Punjab, Pakistan; Department of Computer Science, University of Haripur, Hattar Road Near Swat Chowk, Haripur, Khyber Pakhtunkhwa  22620, Pakistan; Federation University Australia, Mt Helen, Ballarat, VIC  3350, Australia; Western China Earthquake and Hazards Mitigation Research Centre, College of Architecture and Environment, Sichuan University, Chengdu, 610065, China},
abstract={Facial Recognition is a commonly used technology in security-related applications. It has been thoroughly studied and scrutinized for its number of practical real-world applications. On the road ahead of understanding this technology, there remain several obstacles. In this paper, methods of 3D face recognition are examined by measuring quantifiable applications and results. In facial recognition, three Dimensional Morphable Model (3DMM) techniques have attracted more and more attention as effectiveness in use increases over time. 3DMM provides automation and more accurate image rendering when compared to other traditional techniques. The accuracy in image rendering comes at a cost; as 3DMM requires more focus on texture estimation, shape-controlling limits, and extrinsic variations, accurately matching fitting models, feature tracking and precision identification. We have underlined different issues in comparison based on these methods. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.},
author_keywords={3D model;  Morphable model;  Recognition;  Reconstruction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Banita20182325,
author={Banita and Tanwar, P.},
title={Evaluation of 3d facial paralysis using fuzzy logic},
journal={International Journal of Engineering and Technology(UAE)},
year={2018},
volume={7},
number={4},
pages={2325-2331},
doi={10.14419/ijet.v7i4.13619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053901681&doi=10.14419%2fijet.v7i4.13619&partnerID=40&md5=f68480ef298793b35ad707b17c64ab59},
affiliation={Lingaya's University, Faridabad, India; Manav Rachana University, Faridabad, India},
abstract={Face recognition are of great interest to researchers in terms of Image processing and Computer Graphics. In recent years, various factors become popular which clearly affect the face model. Which are ageing, universal facial expressions, and muscle movement. Similarly in terms of medical terminology the facial paralysis can be peripheral or central depending on the level of motor neuron lesion which can be below the nucleus of the nerve or supra nuclear. The various medical therapy used for facial paralysis are electroaccupunture, electro-therapy, laser acupuncture, manual acupuncture which is a traditional form of acupuncture. Imaging plays a great role in evaluation of degree of paralysis and also for faces recognition. There is a wide research in terms of facial expressions and facial recognition but lim-ited research work is available in facial paralysis. House- Brackmann Grading system is one of the simplest and easiest method to evalu-ate the degree of facial paralysis. During evaluation common facial expressions are recorded and are further evaluated by considering the focal points of the left or the right side of the face. This paper presents the classification of face recognition and its respective fuzzy rules to remove uncertainty in the result after evaluation of facial paralysis. © 2018 Banita, Dr. Poonam Tanwar.},
author_keywords={3D face recognition;  CNN;  Evaluation of facial paralysis;  MAMDANI model;  Stages of face recognition},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hu2017133,
author={Hu, H. and Shah, S.A.A. and Bennamoun, M. and Molton, M.},
title={2D and 3D face recognition using convolutional neural network},
journal={IEEE Region 10 Annual International Conference, Proceedings/TENCON},
year={2017},
volume={2017-December},
pages={133-138},
doi={10.1109/TENCON.2017.8227850},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044210743&doi=10.1109%2fTENCON.2017.8227850&partnerID=40&md5=12f531513eddb3716404e891cd002a29},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA  6009, Australia},
abstract={Face recognition remains a challenge today as recognition performance is strongly affected by variability such as illumination, expressions and poses. In this work we apply Convolutional Neural Networks (CNNs) on the challenging task of both 2D and 3D face recognition. We constructed two CNN models, namely CNN-1 (two convolutional layers) and CNN-2 (one convolutional layer) for testing on 2D and 3D dataset. A comprehensive parametric study of two CNN models on face recognition is represented in which different combinations of activation function, learning rate and filter size are investigated. We find that CNN-2 has a better accuracy performance on both 2D and 3D face recognition. Our experimental results show that an accuracy of 85.15% was accomplished using CNN-2 on depth images with FRGCv2.0 dataset (4950 images with 557 objectives). An accuracy of 95% was achieved using CNN-2 on 2D raw image with the AT&T dataset (400 images with 40 objectives). The results indicate that the proposed CNN model is capable to handle complex information from facial images in different dimensions. These results provide valuable insights into further application of CNN on 3D face recognition. © 2017 IEEE.},
author_keywords={Convolutional Neural Networks;  Depth Image;  Face Recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Soltanpour2017560,
author={Soltanpour, S. and Wu, Q.M.J.},
title={Multiscale depth local derivative pattern for sparse representation based 3D face recognition},
journal={2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017},
year={2017},
volume={2017-January},
pages={560-565},
doi={10.1109/SMC.2017.8122665},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044201680&doi=10.1109%2fSMC.2017.8122665&partnerID=40&md5=5918c06bbe0b6cc90d03ba306b0d1258},
affiliation={Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada},
abstract={3D face recognition is a popular research area due to its vast application in biometrics and security. Local featurebased methods gain importance in the recent years due to their robustness under degradation conditions. In this paper, a novel high-order local pattern descriptor in combination with sparse representation based classifier (SRC) is proposed for expression robust 3D face recognition. 3D point clouds are converted to depth maps after preprocessing. Multi-directional derivatives are applied in spatial space to encode the depth maps based on the local derivative pattern (LDP) scheme. Directional pattern features are calculated according to local derivative variations. Since LDP computes spatial relationship of neighbors in a local region, it extracts distinct information from the depth map. Multiscale depth-LDP is presented as a novel descriptor for 3D face recognition. The descriptor is employed along with the SRC to increase the range data distinctiveness. A histogram on the derivative pattern creates a spatial feature descriptor that represents the distinctive micro-patterns from 3D data. We evaluate the proposed algorithm on two famous 3D face databases, FRGC v2.0 and Bosphorus. The experimental results demonstrate that the proposed approach achieves acceptable performance under facial expression. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2017,
author={Liu, Z. and Cohen, F.},
title={Synthesis and identification of three-dimensional faces from image(s) and three-dimensional generic models},
journal={Journal of Electronic Imaging},
year={2017},
volume={26},
number={6},
doi={10.1117/1.JEI.26.6.063005},
art_number={063005},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034836161&doi=10.1117%2f1.JEI.26.6.063005&partnerID=40&md5=cbf0b712fa254c1cccec3850f657b1dd},
affiliation={Kepler Group LLC, New York, NY, United States; Drexel University, Electrical and Computer Engineering, Philadelphia, PA, United States},
abstract={We describe an approach for synthesizing a three-dimensional (3-D) face structure from an image or images of a human face taken at a priori unknown poses using gender and ethnicity specific 3-D generic models. The synthesis process starts with a generic model, which is personalized as images of the person become available using preselected landmark points that are tessellated to form a high-resolution triangular mesh. From a single image, two of the three coordinates of the model are reconstructed in accordance with the given image of the person, while the third coordinate is sampled from the generic model, and the appearance is made in accordance with the image. With multiple images, all coordinates and appearance are reconstructed in accordance with the observed images. This method allows for accurate pose estimation as well as face identification in 3-D rendering of a difficult two-dimensional (2-D) face recognition problem into a much simpler 3-D surface matching problem. The estimation of the unknown pose is achieved using the Levenberg-Marquardt optimization process. Encouraging experimental results are obtained in a controlled environment with high-resolution images under a good illumination condition, as well as for images taken in an uncontrolled environment under arbitrary illumination with low-resolution cameras. © 2017 SPIE and IS&T.},
author_keywords={3-D face recognition;  3-D face synthesis;  iterative personalization;  pose estimation;  ray tracing;  subdivision},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Frikha2017,
author={Frikha, T. and Chaabane, F. and Said, B. and Drira, H. and Abid, M. and Ben Amar, C. and Lille, L.},
title={Embedded approach for a Riemannian-based framework of analyzing 3D faces},
journal={Proceedings - 3rd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2017},
year={2017},
doi={10.1109/ATSIP.2017.8075548},
art_number={8075548},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035335463&doi=10.1109%2fATSIP.2017.8075548&partnerID=40&md5=f9c92873ac16b26563e98ecaba5f6bba},
affiliation={REGIM-Lab: REsearch Groups in Intelligent Machines, University of Sfax, ENIS, BP 1173, Gabes University, Higher Institute of Computer Science and Multimedia of Gabes, Sfax, 3038, Tunisia; REGIM-Lab, Sfax, 3038, Tunisia; Multimedia of Gabes, Sfax, 3038, Tunisia; CES-Laboratory Sfax Sud University, National Engineering School of Sfax, Sfax, Tunisia},
abstract={Developing multimedia embedded applications continues to flourish. In fact, a biometric facial recognition system can be used not only on PCs abut also in embedded systems, it is a potential enhancer to meet security and surveillance needs. The analysis of facial recognition consists offoursteps: face analysis, face expressions' recognition, missing data completion and full face recognition. This paper proposes a hardware architecture based on an adaptation approach foran algorithm which has proven good face detection and recognition in 3D space. The proposed application was tested using a co design technique based on a mixed Hardware Software architecture: the FPGA platform. © 2017 IEEE.},
author_keywords={3D face recognition;  Curve analysis;  elastic analysis algorithm;  embedded architecture;  face detection;  Facial analysis;  Facial expressions;  Riemann geometry},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sui201719575,
author={Sui, D. and Hou, D. and Duan, X.},
title={An interpolation algorithm fitted for dynamic 3D face reconstruction},
journal={Multimedia Tools and Applications},
year={2017},
volume={76},
number={19},
pages={19575-19589},
doi={10.1007/s11042-015-3233-x},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954425638&doi=10.1007%2fs11042-015-3233-x&partnerID=40&md5=78e6cc2a30fcda0f0eb7e4d7fd616c46},
affiliation={School of Information Science and Technology, Wuhan University of Technology, Hubei, 430070, China; School of Software Engineering, Anyang Normal University, Anyang, Henan  455000, China; Department of Computer, College of Science California State Polytecnic University-Pomona, California, United States},
abstract={In order to solve the problem of low recognition accuracy in later period which is caused by the too few extracted parameters in the 3D face recognition, and the incapable formation of completed point cloud structure. An automatic iterative interpolation algorithm is proposed. The new and more accurate 3D face data points are obtained by automatic iteration. This algorithm can be used to restore the data point cloud information of 3D facial feature in 2D images by means of facial three-legged structure formed by 3D face and automatic interpolation. Thus, it can realize to shape the 3D facial dynamic model which can be recognized and has high saturability. Experimental results show that the interpolation algorithm can achieve the complete the construction of facial feature based on the facial feature after 3D dynamic reconstruction, and the validity is higher. © 2016, Springer Science+Business Media New York.},
author_keywords={3D face dynamic recognition;  Iterative interpolation algorithm;  Point cloud structure},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng20171305,
author={Deng, X. and Da, F. and Shao, H.},
title={Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition},
journal={Signal, Image and Video Processing},
year={2017},
volume={11},
number={7},
pages={1305-1312},
doi={10.1007/s11760-017-1087-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017095710&doi=10.1007%2fs11760-017-1087-6&partnerID=40&md5=fc06247cc3ca7870221563a085266269},
affiliation={School of Automation, Southeast University, Nanjing, Jiangsu  210096, China; Key Laboratory of Measurement and Control for Complex System, Ministry of Education, Southeast University, Nanjing, Jiangsu  210096, China},
abstract={A novel adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition is proposed in this paper. Firstly, the novel facial coarse-to-fine landmarks localization method based on Active Shape Model and Gabor wavelets transformation is proposed to exactly and automatically locate facial landmarks in range image. Secondly, the multi-scale fusion of the pyramid local binary patterns (F-PLBP) based on the irregular segmentation associated with the located landmarks is proposed to extract the discriminative feature. Thirdly, a sparse representation-based classifier based on the adaptive feature selection (A-SRC) using the distribution of the reconstruction residual is presented to select the expression-robust feature and identify the faces. Finally, the experimental evaluation based on FRGC v2.0 indicates that the adaptive feature selection method using F-PLBP combined with the A-SRC can obtain the high recognition accuracy by performing the higher discriminative power to overcome the influence from the facial expression variations. © 2017, Springer-Verlag London.},
author_keywords={3D face recognition;  Adaptive feature selection;  Facial landmark localization;  Multi-scale fusion},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liang201784,
author={Liang, Y. and Zhang, Y. and Zeng, X.-X.},
title={Pose-invariant 3D face recognition using half face},
journal={Signal Processing: Image Communication},
year={2017},
volume={57},
pages={84-90},
doi={10.1016/j.image.2017.05.004},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020037210&doi=10.1016%2fj.image.2017.05.004&partnerID=40&md5=88180b3e1c893d79c59e39647f3ee0a2},
affiliation={Guangdong University of Technology, School of Automation, No.100, Waihuan Xi Road, Guangzhou Higher Education Mega Centre, Guangzhou, 510006, China; South China Normal University, School of Software, Nanhai Information Technology Park, Foshan, 528225, China},
abstract={Pose variations are still challenging problems in 3D face recognition because large pose variations will cause self-occlusion and result in missing data. In this paper, a new method for pose-invariant 3D face recognition is proposed to handle significant pose variations. For pose estimation and registration, a coarse-to-fine strategy is proposed to detect landmarks under large yaw variations. At the coarse search step, candidate landmarks are detected using HK curvature analysis and subdivided according to a facial geometrical structure-based classification strategy. At the fine search step, candidate landmarks are identified and labeled by comparing with a Facial Landmark Model. By using the half face matching, we perform the matching step with respect to frontal scans and side scans. Experiments carried out on the Bosphorus and UND/FRGC v2.0 databases show that our method has high accuracy and robustness to pose variations. © 2017 Elsevier B.V.},
author_keywords={3D face recognition;  Facial landmark localization;  Half face;  Iso-geodesic stripes;  Pose variation},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang20171141,
author={Wang, X.-Q. and Yuan, J.-Z. and Li, Q.},
title={3D face recognition using spherical vector norms map},
journal={Journal of Information Science and Engineering},
year={2017},
volume={33},
number={5},
pages={1141-1161},
doi={10.6688/JISE.2017.33.5.3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049875700&doi=10.6688%2fJISE.2017.33.5.3&partnerID=40&md5=cd82489caa82b30e6bb8b05ea1dbaae9},
affiliation={Beijing Key Laboratory of Information Service Engineering, China; Computer Technology Institute, Beijing Union University, Beijing, 100101, China; Beijing Advanced Innovation Center for Imaging Technology Capital Normal University, Beijing, 100048, China},
abstract={In this paper, we introduce a novel, automatic method for 3D face recognition. A new feature called a spherical vector norms map of a 3D face is created using the normal vector of each point. This feature contains more detailed information than the original depth image in regions such as the eyes and nose. For certain flat areas of 3D face, such as the forehead and cheeks, this map could increase the distinguishability of different points. In addition, this feature is robust to facial expression due to an adjustment that is made in the mouth region. Then, the facial representations, which are based on Histograms of Oriented Gradients, are extracted from the spherical vector norms map and the original depth image. A new partitioning strategy is proposed to produce the histogram of eight patches of a given image, in which all of the pixels are binned based on the magnitude and direction of their gradients. In this study, SVNs map and depth image are represented compactly with two histograms of oriented gradients; this approach is completed by Linear Discriminant Analysis and a Nearest Neighbor classifier. © 2017 Institute of Information Science. All Rights Reserved.},
author_keywords={3D face recognition;  Face recognition grand challenge database;  Histograms of oriented gradients;  Linear discriminant analysis;  Spherical vector norms map},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tang2017589,
author={Tang, Y. and Chen, L.},
title={3D Facial Geometric Attributes Based Anti-Spoofing Approach against Mask Attacks},
journal={Proceedings - 12th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2017 - 1st International Workshop on Adaptive Shot Learning for Gesture Understanding and Production, ASL4GUP 2017, Biometrics in the Wild, Bwild 2017, Heterogeneous Face Recognition, HFR 2017, Joint Challenge on Dominant and Complementary Emotion Recognition Using Micro Emotion Features and Head-Pose Estimation, DCER and HPE 2017 and 3rd Facial Expression Recognition and Analysis Challenge, FERA 2017},
year={2017},
pages={589-595},
doi={10.1109/FG.2017.74},
art_number={7961795},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026323809&doi=10.1109%2fFG.2017.74&partnerID=40&md5=ed89e52bd051c85dbee8198cd1d7344e},
affiliation={Universite de Lyon, CNRS, Ecole Centrale de Lyon, LIRIS, Lyon, 69134, France},
abstract={3D scanning and 3D printing techniques, as the technical impetus of 3D face recognition, also boost unconsciously the security threat against it from the spoofing attacks via manufactured mask. In order to improve the robustness of 3D face recognition system, several countermeasures against mask attacks based on photometric features have been reported in recent years. However, the anti-spoofing approach involving 3D meshed face scan and the related 3D facial features have not been studied yet. For filling this gap, in this paper, we propose to exploit the anti-spoofing performance of geometric attributes based 3D facial description. It synthesises the advantages of the selected geometric attributes, named principal curvature measures, and the meshSIFT-based feature descriptor. Specifically, the estimation of geometric attributes is coherent to the property of discrete surface, and the feature related to them can accurately describe the shape of facial surface. These characteristics are beneficial to discovering the geometry-based dissimilarity between genuine face and fraud mask. In the experiment part, the baselines of verification and anti-spoofing performance are evaluated on the Morpho database. Furthermore, for simulating a real-world scenario and testing the corresponding anti-spoofing performance, the size of genuine face set is massively extended by uniting the Morpho database and the FRGC v2.0 database to increase the ratio of genuine faces to fraud masks. The evaluation results prove that the proposed 3D face verification system can guarantee competitive verification accuracy for genuine faces and promising anti-spoofing performance against mask attacks. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Emambakhsh2017995,
author={Emambakhsh, M. and Evans, A.},
title={Nasal Patches and Curves for Expression-Robust 3D Face Recognition},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
year={2017},
volume={39},
number={5},
pages={995-1007},
doi={10.1109/TPAMI.2016.2565473},
art_number={7467565},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018498024&doi=10.1109%2fTPAMI.2016.2565473&partnerID=40&md5=e1afb77517c631cf7da8f8d394318b02},
affiliation={Institute of Sensors, Signals and Systems, Heriot-Watt University, Edinburgh, United Kingdom; Department of Electronic and Electrical Engineering, University of Bath, Bath, United Kingdom},
abstract={The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm. © 2016 IEEE.},
author_keywords={Face recognition;  facial landmarking;  feature selection;  Gabor wavelets;  nose region;  surface normals},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Naveen2017112,
author={Naveen, S. and Rugmini, K.P. and Moni, R.S.},
title={3D face reconstruction by pose correction, patch cloning and texture wrapping},
journal={2016 International Conference on Communication Systems and Networks, ComNet 2016},
year={2017},
pages={112-116},
doi={10.1109/CSN.2016.7823997},
art_number={7823997},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014911379&doi=10.1109%2fCSN.2016.7823997&partnerID=40&md5=d83e42a8548567d921eea89900252c10},
affiliation={Dept. of ECE, LBSITW, Thiruvananthapuram Kerala, India; Dept. of ECE Marian Engineering College, Thiruvananthapuram Kerala, India},
abstract={Face is being considered as one of the most commonly used biometric modality. The inaccuracy in two dimensional face recognition systems is mainly due to pose variations, occlusions, illumination etc. Among this, changes in illumination condition do not affect 3D face recognition systems. But pose variation drastically changes the appearance of face images. To solve the problems with depth map and texture images corrupted by head pose variations and the occlusions generated due to these pose variations, a reconstruction method is proposed which consist of three stages. In the first stage, the pose correction is done by Iterative Closest Point (ICP) algorithm and in the second stage the occluded region of the face is reconstructed by a resurfacing method called patch cloning. It is followed by the wrapping of reconstructed depth map by its texture to generate a 3D model. The statistical error between the original face and the reconstructed face is also evaluated. In this work, facial symmetry is used as a prior knowledge. Experiments are done with the FRAV3D database. © 2016 IEEE.},
author_keywords={Face recognition;  Face Resurfacing;  ICP algorithm;  Patch Cloning;  Pose Correction},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hariri2017187,
author={Hariri, W. and Tabia, H. and Farah, N. and Declercq, D. and Benouareth, A.},
title={Geometrical and visual feature quantization for 3D face recognition},
journal={VISIGRAPP 2017 - Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
year={2017},
volume={5},
pages={187-193},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013991858&partnerID=40&md5=fd026eef10dcc4922fe7269db34feb6c},
affiliation={ETIS, ENSEA, University of Cergy-Pontoise, CNRS, UMR 8051, Cergy-Pontoise, France; Labged Laboratory, Computer Science Department, Badji Mokhtar Annaba University, Annaba, Algeria},
abstract={In this paper, we present an efficient method for 3D face recognition based on vector quantization of both geometrical and visual proprieties of the face. The method starts by describing each 3D face using a set of orderless features, and use then the Bag-of-Features paradigm to construct the face signature. We analyze the performance of three well-known classifiers: the Naïve Bayes, the Multilayer perceptron and the Random forests. The results reported on the FRGCv2 dataset show the effectiveness of our approach and prove that the method is robust to facial expression. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Bag-of-Features;  Codebook;  Depth image;  HoS;  LBP;  Term vector},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2017633,
author={Zhang, T. and Mu, Z. and Li, Y. and Liu, Q. and Zhang, Y.},
title={3D face and ear recognition based on partial mars map},
journal={ICPRAM 2017 - Proceedings of the 6th International Conference on Pattern Recognition Applications and Methods},
year={2017},
volume={2017-January},
pages={633-637},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049438191&partnerID=40&md5=142925806e53f82e08f8cdf1fe8539c6},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China},
abstract={This paper proposes a 3D face recognition approach based on facial pose estimation, which is robust to large pose variations in the unconstrained scene. Deep learning method is used to facial pose estimation, and the generation of partial MARS (Multimodal fAce and eaR Spherical) map reduces the probability of feature points appearing in the deformed region. Then we extract the features from the depth and texture maps. Finally, the matching scores from two types of maps should be calculated by Bayes decision to generate the final result. In the large pose variations, the recognition rate of the method in this paper is 94.6%. The experimental results show that our approach has superior performance than the existing methods used on the MARS map, and has potential to deal with 3D face recognition in unconstrained scene. Copyright © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={3d face recognition;  Deep learning;  Head pose estimation;  Partial mars map},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Deng201713,
author={Deng, X. and Da, F. and Shao, H.},
title={Expression-robust 3D face recognition based on feature-level fusion and feature-region fusion},
journal={Multimedia Tools and Applications},
year={2017},
volume={76},
number={1},
pages={13-31},
doi={10.1007/s11042-015-3012-8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945315051&doi=10.1007%2fs11042-015-3012-8&partnerID=40&md5=5f6b0d57d4d091b3769e974b26751540},
affiliation={Department of Automation, Southeast University, Nanjing, Jiangsu  210096, China; Key Laboratory of Measurement and Control for Complex System of Ministry of Education, Southeast University, Nanjing, Jiangsu  210096, China},
abstract={3D face shape is essentially a non-rigid free-form surface, which will produce non-rigid deformation under expression variations. In terms of that problem, a promising solution named Coherent Point Drift (CPD) non-rigid registration for the non-rigid region is applied to eliminate the influence from the facial expression while guarantees 3D surface topology. In order to take full advantage of the extracted discriminative feature of the whole face under facial expression variations, the novel expression-robust 3D face recognition method using feature-level fusion and feature-region fusion is proposed. Furthermore, the Principal Component Analysis and Linear Discriminant Analysis in combination with Rotated Sparse Regression (PL-RSR) dimensionality reduction method is presented to promote the computational efficiency and provide a solution to the curse of dimensionality problem, which benefit the performance optimization. The experimental evaluation indicates that the proposed strategy has achieved the rank-1 recognition rate of 97.91 % and 96.71 % based on Face Recognition Grand Challenge (FRGC) v2.0 and Bosphorus respectively, which means the proposed approach outperforms state-of-the-art approach. © 2015, Springer Science+Business Media New York.},
author_keywords={3D face recognition;  Dimensionality reduction;  Feature-level fusion;  Feature-region fusion;  Non-rigid point set registration},
document_type={Article},
source={Scopus},
}

@ARTICLE{Keshwani2017333,
author={Keshwani, L. and Pete, D.},
title={Comparative analysis of frontal face recognition using radial curves and back propagation neural network},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={469},
pages={333-344},
doi={10.1007/978-981-10-1678-3_32},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984944723&doi=10.1007%2f978-981-10-1678-3_32&partnerID=40&md5=8786b9edc61be7625d9311c127d87030},
affiliation={Datta Meghe College of Engineering, Airoli, Navi Mumbai, India; Electronics and Telecommunication Department, Datta Meghe College of Engineering, Airoli, Navi Mumbai, India},
abstract={Person identification using face as a cue is one of the most prominent and robust technique. This paper presents 3D face recognition system using Radial curves and Back Propagation Neural Networks (BPNN). The face images used for experimentation are under various challenges like illumination, pose variation, expression and occlusions. The features of images are extracted using Eigen vectors. These features are compared using radial curves on the face starting from center of the face to the end of the face. Each corresponding curve is matched using Euclidean Distance classifier. The BPNN is used to train the features for face matching. The proposed algorithms are tested on ORL and DMCE database. The performance analysis is based on recognition rate accuracy of the system. The proposed radial curve system yields recognition rate accuracy of 100 % for images from the ORL database and 98 % for the images from DMCE database. © Springer Science+Business Media Singapore 2017.},
author_keywords={Back propagation neural networks;  Face recognition;  ORL database;  Radial curves},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wei201766,
author={Wei, X. and Li, H. and Gu, X.D.},
title={Three Dimensional Face Recognition via Surface Harmonic Mapping and Deep Learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10568 LNCS},
pages={66-76},
doi={10.1007/978-3-319-69923-3_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032656852&doi=10.1007%2f978-3-319-69923-3_8&partnerID=40&md5=598d2aabb96d1b2d7f9963542a2fcddf},
affiliation={School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science and Department of Mathematics, State University of New York at Stony Brook, New York, United States},
abstract={In this paper, we propose a general 3D face recognition framework by combining the idea of surface harmonic mapping and deep learning. In particular, given a 3D face scan, we first run the pre-processing pipeline and detect three main facial landmarks (i.e., nose tip and two inner eye corners). Then, harmonic mapping is employed to map the 3D coordinates and differential geometry quantities (e.g., normal vectors, curvatures) of each 3D face scan to a 2D unit disc domain, generating a group of 2D harmonic shape images (HSI). The 2D rotation of the harmonic shape images are removed by using the three detected landmarks. All these pose normalized harmonic shape images are fed into a pre-trained deep convolutional neural network (DCNN) to generate their deep representations. Finally, sparse representation classifier with score-level fusion is used for face similarity measurement and the final decision. The advantage of our method is twofold: (i) it is a general framework and can be easily extended to other surface mapping and deep learning algorithms. (ii) it is registration-free and only needs three landmarks. The effectiveness of the proposed framework was demonstrated on the BU-3DFE database, and reporting a rank-one recognition rate of 89.38% on the whole database. © 2017, Springer International Publishing AG.},
author_keywords={3D face recognition;  Deep learning;  Surface harmonic mapping},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tang201741,
author={Tang, Y. and Chen, L.},
title={Shape analysis based anti-spoofing 3D face recognition with mask attacks},
journal={Communications in Computer and Information Science},
year={2017},
volume={684},
pages={41-55},
doi={10.1007/978-3-319-60654-5_4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025122871&doi=10.1007%2f978-3-319-60654-5_4&partnerID=40&md5=ee21d18278533c54c55ae227daf6a772},
affiliation={Université de Lyon, Ecole Centrale de Lyon, LIRIS laboratory, UMR CNRS 5205, Lyon, 69134, France},
abstract={With the growth of face recognition, the spoofing mask attacks attract more attention in biometrics research area. In recent years, the countermeasures based on the texture and depth image against spoofing mask attacks have been reported, but the research based on 3D meshed sample has not been studied yet. In this paper, we propose to apply 3D shape analysis based on principal curvature measures to describe the meshed facial surface. Meanwhile, a verification protocol based on this feature descriptor is designed to verify person identity and to evaluate the anti-spoofing performance on Morpho database. Furthermore, for simulating a real-life testing scenario, FRGCv2 database is enrolled as an extension of face scans to augment the ratio of genuine face samples to fraud mask samples. The experimental results show that our system can guarantee a high verification rate for genuine faces and the satisfactory anti-spoofing performance against spoofing mask attacks in parallel. © Springer International Publishing AG 2017.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yu2016,
author={Yu, X. and Gao, Y. and Zhou, J.},
title={Boosting Radial Strings for 3D Face Recognition with Expressions and Occlusions},
journal={2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016},
year={2016},
doi={10.1109/DICTA.2016.7797014},
art_number={7797014},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011088593&doi=10.1109%2fDICTA.2016.7797014&partnerID=40&md5=b22aac1e03b48565af8c230b46a10822},
affiliation={School of Engineering, Griffith University, Nathan, QLD, Australia; School of Information and Communication Technology, Griffith University, Nathan, QLD, Australia},
abstract={In this paper, we present a new radial string representation and matching approach for 3D face recognition under expression variations and partial occlusions. The radial strings are an indexed collection of strings emanating from the nose tip of a face scan. The matching between two radial strings is conducted through a dynamic programming process, in which a partial matching mechanism is established to effectively find those un-occluded substrings. Moreover, the most discriminative and stable radial strings are selected optimally by the well-known AdaBoost algorithm to achieve a composite classifier for 3D face recognition under facial expression changes. Experimental results on the GavabDB and the Bosphorus databases show that the proposed approach achieves promising results for human face recognition with expressions and occlusions. © 2016 IEEE.},
author_keywords={face recognition;  facial curves;  feature selection;  machine learning;  string matching},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gilani2016,
author={Gilani, S.Z. and Mian, A.},
title={Towards Large-Scale 3D Face Recognition},
journal={2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016},
year={2016},
doi={10.1109/DICTA.2016.7797090},
art_number={7797090},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011072173&doi=10.1109%2fDICTA.2016.7797090&partnerID=40&md5=8e7de072eb2e5794e1830d7699cecbb6},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, Australia},
abstract={3D face recognition holds great promise in achieving robustness to pose, expressions and occlusions. However, 3D face recognition algorithms are still far behind their 2D counterparts due to the lack of large-scale datasets. We present a model based algorithm for 3D face recognition and test its performance by combining two large public datasets of 3D faces. We propose a Fully Convolutional Deep Network (FCDN) to initialize our algorithm. Reliable seed points are then extracted from each 3D face by evolving level set curves with a single curvature dependent adaptive speed function. We then establish dense correspondence between the faces in the training set by matching the surface around the seed points on a template face to the ones on the target faces. A morphable model is then fitted to probe faces and face recognition is performed by matching the parameters of the probe and gallery faces. Our algorithm achieves state of the art landmark localization results. Face recognition results on the combined FRGCv2 and Bosphorus datasets show that our method is effective in recognizing query faces with real world variations in pose and expression, and with occlusion and missing data despite a huge gallery. Comparing results of individual and combined datasets show that the recognition accuracy drops when the size of the gallery increases. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shah2016,
author={Shah, S.A.A. and Bennamoun, M. and Boussaid, F.},
title={Automatic 3D face landmark localization based on 3D vector field analysis},
journal={International Conference Image and Vision Computing New Zealand},
year={2016},
volume={2016-November},
doi={10.1109/IVCNZ.2015.7761526},
art_number={7761526},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006942604&doi=10.1109%2fIVCNZ.2015.7761526&partnerID=40&md5=5da7d80624be2691571e8fafab5b9dbf},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Perth, Australia; School of Electrical, Electronic and Computer Engineering, University of Western Australia, 35 Stirling Highway, Perth, WA, Australia},
abstract={In applications such as 3D face synthesis and animation, a prominent face landmark is required to enable 3D face normalization, pose correction, 3D face recognition and reconstruction. Due to variations in facial expressions, automatic 3D face landmark localization remains a challenge. Nose tip is one of the salient landmarks in a human face. In this paper, a novel nose tip localization technique is proposed. In the proposed approach, the rotation of the 3D vector field is analyzed for robust and efficient nose tip localization. The proposed technique has the following three characteristics: (1) it does not require any training; (2) it does not rely on any particular model; (3) it is very efficient, requiring an average time of only 1.9s for nose tip detection. We tested the proposed technique on BU3DFE and Shrec'10 datasets. Experimental results show that the proposed technique is robust to variations in facial expressions, achieving a 100% detection rate on these publicly available 3D face datasets. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li201693,
author={Li, B.Y.L. and Xue, M. and Mian, A. and Liu, W. and Krishna, A.},
title={Robust RGB-D face recognition using Kinect sensor},
journal={Neurocomputing},
year={2016},
volume={214},
pages={93-108},
doi={10.1016/j.neucom.2016.06.012},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977478475&doi=10.1016%2fj.neucom.2016.06.012&partnerID=40&md5=df18014ab4a68d40273fdbb72a7a85ae},
affiliation={Department of Computing, Curtin University, Kent Street, Perth, WA  6102, Australia; Dalian Key Lab of Digital Technology for National Culture, Dalian Minzu University, Liaoning, Dalian  116600, China; Computer Science and Software Engineering, The University of Western Australia, 35 Stirling Highway, Crawley, WA  6009, Australia},
abstract={In this paper we propose a robust face recognition algorithm for low resolution RGB-D Kinect data. Many techniques are proposed for image preprocessing due to the noisy depth data. First, facial symmetry is exploited based on the 3D point cloud to obtain a canonical frontal view image irrespective of the initial pose and then depth data is converted to XYZ normal maps. Secondly, multi-channel Discriminant Transforms are then used to project RGB to DCS (Discriminant Color Space) and normal maps to DNM (Discriminant Normal Maps). Finally, a Multi-channel Robust Sparse Coding method is proposed that codes the multiple channels (DCS or DNM) of a test image as a sparse combination of training samples with different pixel weighting. Weights are calculated dynamically in an iterative process to achieve robustness against variations in pose, illumination, facial expressions and disguise. In contrast to existing techniques, our multi-channel approach is more robust to variations. Reconstruction errors of the test image (DCS and DNM) are normalized and fused to decide its identity. The proposed algorithm is evaluated on four public databases. It achieves 98.4% identification rate on CurtinFaces, a Kinect database with 4784 RGB-D images of 52 subjects. Using a first versus all protocol on the Bosphorus, CASIA and FRGC v2 databases, the proposed algorithm achieves 97.6%, 95.6% and 95.2% identification rates respectively. To the best of our knowledge, these are the highest identification rates reported so far for the first three databases. © 2016 Elsevier B.V.},
author_keywords={3D face recognition;  Kinect;  Multi-channel discriminant transform;  Sparse coding},
document_type={Article},
source={Scopus},
}

@ARTICLE{Guo2016403,
author={Guo, Y. and Lei, Y. and Liu, L. and Wang, Y. and Bennamoun, M. and Sohel, F.},
title={EI3D: Expression-invariant 3D face recognition based on feature and shape matching},
journal={Pattern Recognition Letters},
year={2016},
volume={83},
pages={403-412},
doi={10.1016/j.patrec.2016.04.003},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966659227&doi=10.1016%2fj.patrec.2016.04.003&partnerID=40&md5=b09b19b7a5436b53278c02d001e93910},
affiliation={College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan  410073, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan  610065, China; College of Information System and Management, National University of Defense Technology, Changsha, Hunan  410073, China; College of Computer Science, Sichuan University, Chengdu, Sichuan, China; School of Computer Science and Software Engineering, The University of Western Australia, Perth, WA  6009, Australia; School of Engineering and Information Technology, Murdoch University, Perth, WA  6150, Australia},
abstract={This paper presents a local feature based shape matching algorithm for expression-invariant 3D face recognition. Each 3D face is first automatically detected from a raw 3D data and normalized to achieve pose invariance. The 3D face is then represented by a set of keypoints and their associated local feature descriptors to achieve robustness to expression variations. During face recognition, a probe face is compared against each gallery face using both local feature matching and 3D point cloud registration. The number of feature matches, the average distance of matched features, and the number of closest point pairs after registration are used to measure the similarity between two 3D faces. These similarity metrics are then fused to obtain the final results. The proposed algorithm has been tested on the FRGC v2 benchmark and a high recognition performance has been achieved. It obtained the state-of-the-art results by achieving an overall rank-1 identification rate of 97.0% and an average verification rate of 99.01% at 0.001 false acceptance rate for all faces with neutral and non-neutral expressions. Further, the robustness of our algorithm under different occlusions has been demonstrated on the Bosphorus dataset. © 2016 Elsevier B.V.},
author_keywords={3D face recognition;  Face identification;  Facial expression;  Keypoint detection;  Local feature;  Shape matching},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lei2016994,
author={Lei, Y. and Feng, S. and Zhou, X. and Guo, Y.},
title={An efficient 3D partial face recognition approach with single sample},
journal={Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016},
year={2016},
pages={994-999},
doi={10.1109/ICIEA.2016.7603727},
art_number={7603727},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997335714&doi=10.1109%2fICIEA.2016.7603727&partnerID=40&md5=05e7f7f4b11d4caaaace67a1698a150c},
affiliation={College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan, 610065, China; College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, 410073, China},
abstract={3D partial face recognition under missing parts, occlusions and data corruptions is a major challenge for the practical application of the techniques of 3D face recognition. Moreover, one individual can only provide one sample for training in most practical scenarios, and thus the face recognition with single sample problem is another highly challenging task. We propose an efficient framework for 3D partial face recognition with single sample addressing both of the two problems. First, we represent a facial scan with a set of keypoint based local geometrical descriptors, which gains sufficient robustness to partial facial data along with expression/pose variations. Then, a two-step modified collaborative representation classification scheme is proposed to address the single sample recognition problem. A class-based probability estimation is given during the first classification step, and the obtained result is then incorporated into the modified collaborative representation classification as a locality constraint to improve its classification performance. Extensive experiments on the Bosphorus and FRGC v2.0 datasets demonstrate the efficiency of the proposed approach when addressing the problem of 3D partial face recognition with single sample. © 2016 IEEE.},
author_keywords={3D facial representation;  3D partial face recognition;  collaborative representation;  locality constraint;  single sample problem},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2016,
author={Zhang, J. and Huang, D. and Wang, Y. and Sun, J.},
title={Lock3DFace: A large-scale database of low-cost Kinect 3D faces},
journal={2016 International Conference on Biometrics, ICB 2016},
year={2016},
doi={10.1109/ICB.2016.7550062},
art_number={7550062},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988432113&doi=10.1109%2fICB.2016.7550062&partnerID=40&md5=b25394bb9ffda22d92409c2cd0a74cfa},
affiliation={IRIP Lab, School of Computer Science and Engineering, Beihang University, Beijing, 100191, China},
abstract={In this paper, we present a large-scale database consisting of low cost Kinect 3D face videos, namely Lock3DFace, for 3D face analysis, particularly for 3D Face Recognition (FR). To the best of our knowledge, Lock3DFace is currently the largest low cost 3D face database for public academic use. The 3D samples are highly noisy and contain a diversity of variations in expression, pose, occlusion, time lapse, and their corresponding texture and near infrared channels have changes in lighting condition and radiation intensity, allowing for evaluating FR methods in complex situations. Furthermore, based on Lock3DFace, we design the standard experimental protocol for low-cost 3D FR, and give the baseline performance of individual subsets belonging to different scenarios for fair comparison in the future. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kim20163011,
author={Kim, D. and Choi, J. and Leksut, J.T. and Medioni, G.},
title={Accurate 3D face modeling and recognition from RGB-D stream in the presence of large pose changes},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2016},
volume={2016-August},
pages={3011-3015},
doi={10.1109/ICIP.2016.7532912},
art_number={7532912},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006789474&doi=10.1109%2fICIP.2016.7532912&partnerID=40&md5=132fb651cb89c0d50239c14c3a7104ae},
affiliation={Institute for Robotics and Intelligent Systems, University of Southern California, 3737 Watt way PHE 101, Los Angeles, CA  90089, United States},
abstract={We propose a 3D face modeling and recognition system using an RGB-D stream in the presence of large pose changes. In the previous work, all facial data points are registered with a reference to improve the accuracy of 3D face model from a low-resolution depth sequence. This registration often fails when applied to non-frontal faces. It causes inaccurate 3D face models and poor performance of matching. We address this problem by pre-aligning each input face ('frontalization') before the registration, which avoids registration failures. For each frame, our method estimates the 3D face pose, assesses the quality of data, segments the facial region, frontalizes it, and performs an accurate registration with the previous 3D model. The 3D-3D recognition system using accurate 3D models from our method outperforms other face recognition systems and shows 100% rank 1 recognition accuracy on a dataset with 30 subjects. © 2016 IEEE.},
author_keywords={3D Face Modeling;  3D Face Recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yu20163016,
author={Yu, X. and Gao, Y. and Zhou, J.},
title={3D face recognition under partial occlusions using radial strings},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2016},
volume={2016-August},
pages={3016-3020},
doi={10.1109/ICIP.2016.7532913},
art_number={7532913},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006713653&doi=10.1109%2fICIP.2016.7532913&partnerID=40&md5=dd468caaf8cc8593dad5e05e0c040b9c},
affiliation={School of Engineering, Griffith University, Nathan, QLD, Australia; School of Information and Communication Technology, Griffith University, Nathan, QLD, Australia},
abstract={3D face recognition with partial occlusions is a highly challenging problem. In this paper, we propose a novel radial string representation and matching approach to recognize 3D facial scans in the presence of partial occlusions. Here we encode 3D facial surfaces into an indexed collection of radial strings emanating from the nosetips and Dynamic Programming (DP) is then used to measure the similarity between two radial strings. In order to address the recognition problems with partial occlusions, a partial matching mechanism is established in our approach that effectively eliminates those occluded parts and finds the most discriminative parts during the matching process. Experimental results on the Bosphorus database demonstrate that the proposed approach yields superior performance on partially occluded data. © 2016 IEEE.},
author_keywords={3D face recognition;  Partial occlusions;  Radial string matching;  Structural recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Torkhani2016447,
author={Torkhani, G. and Ladgham, A. and Mansouri, M.N. and Sakly, A.},
title={Gabor-SVM applied to 3D-2D deformed mesh model},
journal={2nd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2016},
year={2016},
pages={447-452},
doi={10.1109/ATSIP.2016.7523133},
art_number={7523133},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984607903&doi=10.1109%2fATSIP.2016.7523133&partnerID=40&md5=a94aa03e640ea81c789823dfdf4c35ed},
affiliation={CSR Research Unit, E e Laboratory, National School of Engineering, Ibn Eljazzar, Monastir, 5019, Tunisia; Electrical Departement, National School of Engineering, Ibn Eljazzar, Monastir, 5019, Tunisia},
abstract={We propose a robust method for 3D face recognition using 3D to 2D modeling and facial curvatures detection. The 3D-2D algorithm permits to transform 3D images into 3D triangular mesh, then the mesh model is deformed and fitted to the 2D space in order to obtain a 2D smoother mesh. Then, we apply Gabor wavelets to the deformed model in order to exploit surface curves in the detection of salient face features. The classification of the final Gabor facial model is performed using the support vector machines (SVM). To demonstrate the quality of our technique, we give some experiments using the 3D AJMAL faces database. The experimental results prove that the proposed method is able to give a good recognition quality and a high accuracy rate. © 2016 IEEE.},
author_keywords={3D face recognition;  deformed mesh model;  facial curvatures;  Gabor wavelet;  salient points;  SVM},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Werghi2016964,
author={Werghi, N. and Tortorici, C. and Berretti, S. and Del Bimbo, A.},
title={Boosting 3D LBP-Based Face Recognition by Fusing Shape and Texture Descriptors on the Mesh},
journal={IEEE Transactions on Information Forensics and Security},
year={2016},
volume={11},
number={5},
pages={964-979},
doi={10.1109/TIFS.2016.2515505},
art_number={7373633},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963974403&doi=10.1109%2fTIFS.2016.2515505&partnerID=40&md5=376f43714248cb873d28dcb663ac1bb5},
affiliation={Electrical and Computer Engineering Department, Khalifa University, Abu Dhabi, 127788, United Arab Emirates; Department of Information Engineering, University of Florence, Florence, 50139, Italy},
abstract={In this paper, we present a novel approach for fusing shape and texture local binary patterns (LBPs) on a mesh for 3D face recognition. Using a recently proposed framework, we compute LBP directly on the face mesh surface, then we construct a grid of the regions on the facial surface that can accommodate global and partial descriptions. Compared with its depth-image counterpart, our approach is distinguished by the following features: 1) inherits the intrinsic advantages of mesh surface (e.g., preservation of the full geometry); 2) does not require normalization; and 3) can accommodate partial matching. In addition, it allows early level fusion of texture and shape modalities. Through experiments conducted on the BU-3DFE and Bosphorus databases, we assess different variants of our approach with regard to facial expressions and missing data, also in comparison to the state-of-the-art solutions. © 2016 IEEE.},
author_keywords={3D face recognition;  feature and score fusion;  mesh-LBP},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ganguly2016275,
author={Ganguly, S. and Bhattachaijee, D. and Nasipuri, M.},
title={3D face recognition from complement component range face images},
journal={2015 IEEE International Conference on Computer Graphics, Vision and Information Security, CGVIS 2015},
year={2016},
pages={275-278},
doi={10.1109/CGVIS.2015.7449936},
art_number={7449936},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966632732&doi=10.1109%2fCGVIS.2015.7449936&partnerID=40&md5=ac5698f1d98fa8b29941ffc837f84a7b},
affiliation={Department of Computer Science and Engineering, Jadavpur University, Kolkata-32, India},
abstract={Face and facial attributes represent meaningful definition about a variety of information to discriminate an individual from others and for developing a computational model for automatic face recognition purpose. However, in this work, selection of relevant features from newly created face space is the pivotal contribution of the authors. Here, authors have demonstrated a new face space 'Complement Component' that have been used to extract the four basic components along X, and Y axes in four directions. Later, authors have experimented the discriminative attributes from these face spaces for recognition purpose. Here, comparison of the proposed method has been reported by examining its success on two well accepted 3D face databases, namely: Frav3D and Texas3D. In case of 2D face images, it does not contain depth like information i.e. Z-values in X-Y plane through intensity values. Therefore, it has not been undertaken during this investigation. © 2015 IEEE.},
author_keywords={3D face image;  Complement Component;  Face recognition;  range face image},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lei2016218,
author={Lei, Y. and Guo, Y. and Hayat, M. and Bennamoun, M. and Zhou, X.},
title={A Two-Phase Weighted Collaborative Representation for 3D partial face recognition with single sample},
journal={Pattern Recognition},
year={2016},
volume={52},
pages={218-237},
doi={10.1016/j.patcog.2015.09.035},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947306090&doi=10.1016%2fj.patcog.2015.09.035&partnerID=40&md5=50ca73115b78f6746739042c1f293a0e},
affiliation={College of Electronics and Information Engineering, Sichuan University, Chengdu, Sichuan, China; College of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China; School of Computer Science and Software Engineering, University of Western Australia, Crawley, WA, Australia; IBM Research Australia, Carlton, VIC, Australia},
abstract={3D face recognition with the availability of only partial data (missing parts, occlusions and data corruptions) and single training sample is a highly challenging task. This paper presents an efficient 3D face recognition approach to address this challenge. We represent a facial scan with a set of local Keypoint-based Multiple Triangle Statistics (KMTS), which is robust to partial facial data, large facial expressions and pose variations. To address the single sample problem, we then propose a Two-Phase Weighted Collaborative Representation Classification (TPWCRC) framework. A class-based probability estimation is first calculated based on the extracted local descriptors as a prior knowledge. The resulting class-based probability estimation is then incorporated into the proposed classification framework as a locality constraint to further enhance its discriminating power. Experimental results on six challenging 3D facial datasets show that the proposed KMTS-TPWCRC framework achieves promising results for human face recognition with missing parts, occlusions, data corruptions, expressions and pose variations. © 2015 Elsevier Ltd. All rights reserved.},
author_keywords={3D face recognition;  3D representation;  Partial facial data;  Single sample problem;  Sparse representation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Echeagaray-Patron2016843,
author={Echeagaray-Patron, B.A. and Miramontes-Jaramillo, D. and Kober, V.},
title={Conformal parameterization and curvature analysis for 3D facial recognition},
journal={Proceedings - 2015 International Conference on Computational Science and Computational Intelligence, CSCI 2015},
year={2016},
pages={843-844},
doi={10.1109/CSCI.2015.133},
art_number={7424213},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964412211&doi=10.1109%2fCSCI.2015.133&partnerID=40&md5=6a3fc9e7dac95a6f25aacc425aa40af5},
affiliation={Department of Computer Science, CICESE, Ensenada, B.C., 22860, Mexico; Department of Mathematics, Chelyabinsk State University, Russian Federation},
abstract={This work proposes a new algorithm for 3D face recognition. The algorithm uses 3D shape data without color or texture information and exploits local curvature information which is a measure with high discriminant capability and robust to deformations such as rotation and scaling. In order to reduce high dimensionality of typical face surfaces our approach uses a conformal parameterization, preserving angles of original faces and simplifies the correspondence problem. Experimental results are presented and discussed using CASIA and Gavab databases. © 2015 IEEE.},
author_keywords={3D face recognition;  Conformal parameterization;  Curvature analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhou2016109,
author={Zhou, W. and Chen, J.-X. and Wang, L.},
title={A RGB-D face recognition approach without confronting the camera},
journal={Proceedings of 2015 IEEE International Conference on Computer and Communications, ICCC 2015},
year={2016},
pages={109-114},
doi={10.1109/CompComm.2015.7387550},
art_number={7387550},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963938690&doi=10.1109%2fCompComm.2015.7387550&partnerID=40&md5=d5bfca843f857fa39877a526fa1c2108},
affiliation={Key Lab of Broadband Wireless Communication and Sensor Network Technology, Ministry of Education, Nanjing, 210003, China},
abstract={Face recognition research mainly focuses on traditional 2D color images, which is extremely susceptible to be affected by external factors such as various viewpoints and has limited recognition accuracy. In order to achieve improved recognition performance, as well as the 3D face holds more abundant information than 2D, we present a 3D human face recognition algorithm using the Microsoft's Kinect. The proposed approach integrates the depth data with the RGB data to generate 3D face raw data and then extracts feature points, identifies the target via a two-level cascade classifier. Also, we build a 3D-face database including 16 individuals captured exclusively using Kinect. The experimental results indicate that the introduced algorithm can not only achieve better recognition accuracy in comparison to existing 2D and 3D face recognition algorithms when the probe face is exactly in front of Kinect sensor, but also can increase 9.3% of recognition accuracy compared to the PCA-3D algorithm when it is not confronting the camera. © 2015 IEEE.},
author_keywords={3D face recognition;  classifier;  Kinect;  RGB-D images;  XML file},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Starczewski2016210,
author={Starczewski, J.T. and Pabiasz, S. and Vladymyrska, N. and Marvuglia, A. and Napoli, C. and Wózniak, M.},
title={Self organizing maps for 3D face understanding},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9693},
pages={210-217},
doi={10.1007/978-3-319-39384-1_19},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977471207&doi=10.1007%2f978-3-319-39384-1_19&partnerID=40&md5=7f993d82b7b04337f5466c3ed735ff72},
affiliation={Institute of Computational Intelligence, Czestochowa University of Technology, Czestochowa, Poland; Radom Academy of Economics, Radom, Poland; Environmental Research and Innovation Department, Luxembourg Institute of Science and Technology, Esch-sur-Alzette, Luxembourg; Department of Mathematics and Informatics, University of Catania, Catania, Italy; Institute of Mathematics, Silesian University of Technology, Gliwice, Poland},
abstract={Landmarks are unique points that can be located on every face. Facial landmarks typically recognized by people are correlated with anthropomorphic points. Our purpose is to employ in 3D face recognition such landmarks that are easy to interpret. Face understanding is construed as identification of face characteristic points with automatic labeling of them. In this paper, we apply methods based on Self Organizing Maps to understand 3D faces. © Springer International Publishing Switzerland 2016.},
author_keywords={3D face recognition;  Self organizing maps;  Understanding of images},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Galbally2016199,
author={Galbally, J. and Satta, R.},
title={Biometric sensor interoperability: A case study in 3D face recognition},
journal={ICPRAM 2016 - Proceedings of the 5th International Conference on Pattern Recognition Applications and Methods},
year={2016},
pages={199-204},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969988967&partnerID=40&md5=80af1e7c3fa3ef4e303e144e6927af47},
affiliation={European Commission - Joint Research Centre, IPSC, Via Enrico Fermi 2749, Ispra, 21027, Italy},
abstract={Biometric systems typically suffer a significant loss of performance when the acquisition sensor is changed between enrolment and authentication. Such a problem, commonly known as sensor interoperability, poses a serious challenge to the accuracy of matching algorithms. The present work addresses for the first time the sensor interoperability issue in 3D face recognition systems, analysing the performance of two popular and well known techniques for 3D facial authentication. For this purpose, a new gender-balanced database comprising 3D data of 26 subjects has been acquired using two devices belonging to the new generation of low-cost 3D sensors. The results show the high sensor-dependency of the tested systems and the need to develop matching algorithms robust to the variation in the sensor resolution. © Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={3D face database;  3D face recognition;  Interoperability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Song2016,
author={Song, D. and Luo, J. and Zi, C. and Tian, H.},
title={3D Face Recognition Using Anthropometric and Curvelet Features Fusion},
journal={Journal of Sensors},
year={2016},
volume={2016},
doi={10.1155/2016/6859364},
art_number={6859364},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954447014&doi=10.1155%2f2016%2f6859364&partnerID=40&md5=145d972d12039ce0cfdea217aaa57214},
affiliation={College of Electrical Engineering and Automation, Tianjin Polytechnic University, Tianjin, 300387, China; Key Laboratory of Advanced Electrical Engineering and Energy Technology, Tianjin, 300387, China; School of Electrical, Computer and Telecommunications Engineering, University of Wollongong, Sydney, NSW  2522, Australia},
abstract={Curvelet transform can describe the signal by multiple scales, and multiple directions. In order to improve the performance of 3D face recognition algorithm, we proposed an Anthropometric and Curvelet features fusion-based algorithm for 3D face recognition (Anthropometric Curvelet Fusion Face Recognition, ACFFR). First, the eyes, nose, and mouth feature regions are extracted by the Anthropometric characteristics and curvature features of the human face. Second, Curvelet energy features of the facial feature regions at different scales and different directions are extracted by Curvelet transform. At last, Euclidean distance is used as the similarity between template and objectives. To verify the performance, the proposed algorithm is compared with Anthroface3D and Curveletface3D on the Texas 3D FR database. The experimental results have shown that the proposed algorithm performs well, with equal error rate of 1.75% and accuracy of 97.0%. The algorithm we proposed in this paper has better robustness to expression and light changes than Anthroface3D and Curveletface3D. © 2016 Dan Song et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bellil2016365,
author={Bellil, W. and Brahim, H. and Ben Amar, C.},
title={Gappy wavelet neural network for 3D occluded faces: detection and recognition},
journal={Multimedia Tools and Applications},
year={2016},
volume={75},
number={1},
pages={365-380},
doi={10.1007/s11042-014-2294-6},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953638822&doi=10.1007%2fs11042-014-2294-6&partnerID=40&md5=e5d7d42e44edd21d1de8b6e4cc7bdd48},
affiliation={REGIM: REsearch Groups on Intelligent Machines, University of Sfax, National Engineering School of Sfax (ENIS), Sfax, Tunisia},
abstract={The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 % which represents a competitive result compared to the state of the art. © 2014, Springer Science+Business Media New York.},
author_keywords={3D face recognition; Wavelets;  Gappy data;  Occlusion detection;  Wavelet neural network},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gaonkar201615,
author={Gaonkar, A.A. and Gad, M.D. and Vetrekar, N.T. and Tilve, V.S. and Gad, R.S.},
title={Experimental evaluation of 3D kinect face database},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10481 LNCS},
pages={15-26},
doi={10.1007/978-3-319-68124-5_2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057824711&doi=10.1007%2f978-3-319-68124-5_2&partnerID=40&md5=3a104665aebdb39c053c8b83ce35c8fb},
affiliation={Department of Electronics, Goa University, Taleigao Plateau, Goa, India; Goa Engineering College, Farmagudi, Goa, India; School of Earth and Space Exploration, Arizona State University, Tempe, United States},
abstract={3D face recognition has gain a paramount importance over 2D due to its potential to address the limitations of 2D face recognition against the variation in facial poses, angles, occlusions etc. Research in 3D face recognition has accelerated in recent years due to the development of low cost 3D Kinect camera sensor. This has leads to the development of few RGB-D database across the world. Here in this paper we introduce the base results of our 3D facial database (GU-RGBD database) comprising variation in pose (0°, 45°, 90°, −45°, −90°), expression (smile, eyes closed), occlusion (half face covered with paper) and illumination variation using Kinect. We present a proposed noise removal non-linear interpolation filter for the patches present in the depth images. The results were obtained on three face recognition algorithms and fusion at matching score level for recognition and verification rate. The obtained results indicated that the performance with our proposed filter shows improvement over pose with score level fusion using sum rule. © Springer International Publishing AG 2017.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Boukamcha2015,
author={Boukamcha, H. and Elhallek, M. and Atri, M. and Smach, F.},
title={3D face landmark auto detection},
journal={2015 World Symposium on Computer Networks and Information Security, WSCNIS 2015},
year={2015},
doi={10.1109/WSCNIS.2015.7368276},
art_number={7368276},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962430025&doi=10.1109%2fWSCNIS.2015.7368276&partnerID=40&md5=13ae6691c8afd0ea13bb469882ec0aea},
affiliation={University of Sciences of Monastir, Monastir, Tunisia; Université of Bourgogne, France},
abstract={This paper presents our methodology for Landmark Point detection to improve 3D face recognition in a presence of variant facial expression. The objective was to develop an automatic process for distinguishing and segmenting to be embedded in a 3D face recognition system using only 3D Point Distribution Model (PDM) as input. The approach used hydride method to extract this features from the surface curvature information. Landmark Localization is done on the segmented face via finding the change that decreases the deviation of the model from the mean profile. Face registering is achieved using previous anthropometric information and the localized landmarks. The results confirm that the method used is accurate and robust for the proposed application. © 2015 IEEE.},
author_keywords={3D Face;  Graph Matching;  Labelling;  Registration},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lv20153635,
author={Lv, S. and Da, F. and Deng, X.},
title={A 3D face recognition method using region-based extended local binary pattern},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2015},
volume={2015-December},
pages={3635-3639},
doi={10.1109/ICIP.2015.7351482},
art_number={7351482},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956668987&doi=10.1109%2fICIP.2015.7351482&partnerID=40&md5=2c0948e184ab3751c8c447b235e50e0a},
affiliation={School of Automation, Southeast University, Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, 210096, China},
abstract={A 3D face recognition method using region-based extended local binary pattern (eLBP) is proposed. First, the depth image converted from the preprocessed 3D pointclouds is normalized. Then, different regions according to their distortions under facial expressions are extracted by binary masks and represented by the uniform pattern of extended LBP. Finally, sparse representation classifier (SRC) is adopted for classification on the single region. Feature-level and score-level fusion with weight-sparse representation classifier (W-SRC) are also tested and compared, and the latter has better performance. The experiments on FRGC v2.0 database demonstrate that the proposed method is robust and efficient. © 2015 IEEE.},
author_keywords={3D face recognition;  binary mask;  depth image;  extended local binary pattern;  weight-sparse representation classifier},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tortorici20152670,
author={Tortorici, C. and Werghi, N. and Berretti, S.},
title={Boosting 3D LBP-based face recognition by fusing shape and texture descriptors on the mesh},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2015},
volume={2015-December},
pages={2670-2674},
doi={10.1109/ICIP.2015.7351287},
art_number={7351287},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956639911&doi=10.1109%2fICIP.2015.7351287&partnerID=40&md5=6ea1b56b061b463d4fc6e850dc9c85e6},
affiliation={Khalifa University, Abu Dhabi, United Arab Emirates; University of Florence, Florence, Italy},
abstract={In this paper, we present a novel approach for fusing shape and texture local binary patterns (LBP) for 3D face recognition. Using the framework proposed in [1], we compute LBP directly on the face mesh surface, then we construct a grid of the regions on the facial surface that can accommodate global and partial descriptions. Compared to its depth-image counterpart, our approach is distinguished by the following features: a) inherits the intrinsic advantages of mesh surface; b) does not require normalization; c) can accommodate partial matching. In addition, it allows early-level fusion of texture and shape modalities. Through experiments conducted on the BU-3DFE and Bosphorus databases, we assess different variants of our approach with regard to facial expressions and missing data. © 2015 IEEE.},
author_keywords={3D face recognition;  fusion;  mesh-LBP},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Patil2015393,
author={Patil, H. and Kothari, A. and Bhurchandi, K.},
title={3-D face recognition: features, databases, algorithms and challenges},
journal={Artificial Intelligence Review},
year={2015},
volume={44},
number={3},
pages={393-441},
doi={10.1007/s10462-015-9431-0},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941419993&doi=10.1007%2fs10462-015-9431-0&partnerID=40&md5=c90b8821f623bcb40665d0010a316ef6},
affiliation={Visvesvaraya National Institute of Technology, Nagpur, India},
abstract={Face recognition is being widely accepted as a biometric technique because of its non-intrusive nature. Despite extensive research on 2-D face recognition, it suffers from poor recognition rate due to pose, illumination, expression, ageing, makeup variations and occlusions. In recent years, the research focus has shifted toward face recognition using 3-D facial surface and shape which represent more discriminating features by the virtue of increased dimensionality. This paper presents an extensive survey of recent 3-D face recognition techniques in terms of feature detection, classifiers as well as published algorithms that address expression and occlusion variation challenges followed by our critical comments on the published work. It also summarizes remarkable 3-D face databases and their features used for performance evaluation. Finally we suggest vital steps of a robust 3-D face recognition system based on the surveyed work and identify a few possible directions for research in this area. © 2015, Springer Science+Business Media Dordrecht.},
author_keywords={3-D Face databases;  3-D faces;  Biometrics;  Classifiers;  Face matching;  Face recognition;  Feature extraction},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng20155509,
author={Deng, X. and Da, F. and Shao, H.},
title={Expression-robust 3D face recognition using region-based multiscale wavelet feature fusion},
journal={Journal of Computational Information Systems},
year={2015},
volume={11},
number={15},
pages={5509-5517},
doi={10.12733/jcis14953},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950271521&doi=10.12733%2fjcis14953&partnerID=40&md5=da8d93edfc030808fb309b097e409e94},
affiliation={Department of Automation, Southeast University, Nanjing, 210096, China; Key Laboratory of Measurement and Control for Complex System of Ministry of Education, Southeast University, Nanjing, 210096, China},
abstract={In order to eliminate the impact of facial expressions and improve the efficiency of calculation, this paper proposes a novel expression-robust 3D face recognition algorithm using region-based feature fusion technique based on multiscale wavelet transformations. The discrete wavelet transformation is applied to extract frequency component features of geometric image based on the semi-rigid face region as well as the non-rigid face region in order to reduce the influence from the facial expression using the Coherent Point Drift non-rigid point set registration. The dimensionality reduction methods are utilized to promote the computational efficiency, and the experimental results show that our algorithm outperforms state-of-the-art methods based on FRGC v2.0. Copyright © 2015 Binary Information Press.},
author_keywords={3D face recognition;  Dimensionality reduction;  Multiscale wavelet transform;  Non-rigid point set registration},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang20151817,
author={Zhang, C. and Gu, Y.-Z. and Hu, K.-L. and Wang, Y.-G.},
title={Face recognition using SIFT features under 3D meshes},
journal={Journal of Central South University},
year={2015},
volume={22},
number={5},
pages={1817-1825},
doi={10.1007/s11771-015-2700-x},
art_number={2700},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930008100&doi=10.1007%2fs11771-015-2700-x&partnerID=40&md5=569ac008f1ef201b7fcbffd9e0faa163},
affiliation={Key Laboratory of Wireless Sensor Network & Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, 201800, China; Department of Computer Science and Engineering, Shaoxing University, Shaoxing, 312000, China},
abstract={Expression, occlusion, and pose variations are three main challenges for 3D face recognition. A novel method is presented to address 3D face recognition using scale-invariant feature transform (SIFT) features on 3D meshes. After preprocessing, shape index extrema on the 3D facial surface are selected as keypoints in the difference scale space and the unstable keypoints are removed after two screening steps. Then, a local coordinate system for each keypoint is established by principal component analysis (PCA). Next, two local geometric features are extracted around each keypoint through the local coordinate system. Additionally, the features are augmented by the symmetrization according to the approximate left-right symmetry in human face. The proposed method is evaluated on the Bosphorus, BU-3DFE, and Gavab databases, respectively. Good results are achieved on these three datasets. As a result, the proposed method proves robust to facial expression variations, partial external occlusions and large pose changes. © 2015, Central South University Press and Springer-Verlag Berlin Heidelberg.},
author_keywords={3D face recognition;  3D meshes;  expression;  large pose changes;  occlusion;  scale-invariant feature transform (SIFT)},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Beumier20152291,
author={Beumier, C.},
title={Design of coded structured light pattern for 3D facial surface capture},
journal={European Signal Processing Conference},
year={2015},
volume={06-10-September-2004},
pages={2291-2294},
art_number={7079884},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979948896&partnerID=40&md5=b09f05fe749fab292462602ba77b999e},
affiliation={Signal and Image Centre, Royal Military Academy, Avenue de la Renaissance, 30, Brussels, B-1000, Belgium},
abstract={In the context of 3D face recognition, facial surfaces are advantageously captured by a structured light acquisition system, which is typically quick, low cost and uses off-the-shelve components. The light pattern projected, a key aspect of the structured light approach, makes the major difference between developed systems. In most of them, elements of the light pattern must be identified by a property such as element thickness or colour. We present in this paper the design of projected patterns that led to the realisation of three 3D acquisition prototypes. © 2004 EUSIPCO.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Elaiwat20151235,
author={Elaiwat, S. and Bennamoun, M. and Boussaid, F. and El-Sallam, A.},
title={A Curvelet-based approach for textured 3D face recognition},
journal={Pattern Recognition},
year={2015},
volume={48},
number={4},
pages={1235-1246},
doi={10.1016/j.patcog.2014.10.013},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920743471&doi=10.1016%2fj.patcog.2014.10.013&partnerID=40&md5=dde3d88e6412c83672a1a30bbf49b936},
affiliation={School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Electrical, Electronic and Computer Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Sport Science, Exercise and Health, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia},
abstract={In this paper, we present a fully automated multimodal Curvelet-based approach for textured 3D face recognition. The proposed approach relies on a novel multimodal keypoint detector capable of repeatably identifying keypoints on textured 3D face surfaces. Unique local surface descriptors are then constructed around each detected keypoint by integrating Curvelet elements of different orientations, resulting in highly descriptive rotation invariant features. Unlike previously reported Curvelet-based face recognition algorithms which extract global features from textured faces only, our algorithm extracts both texture and 3D local features. In addition, this is achieved across a number of frequency bands to achieve robust and accurate recognition under varying illumination conditions and facial expressions. The proposed algorithm was evaluated using three well-known and challenging datasets, namely FRGC v2, BU-3DFE and Bosphorus datasets. Reported results show superior performance compared to prior art, with 99.2%, 95.1% and 91% verification rates at 0.001 FAR for FRGC v2, BU-3DFE and Bosphorus datasets, respectively. © 2014 Elsevier Ltd. All rights reserved.},
author_keywords={Digital Curvelet transform;  Face recognition;  Keypoint detection;  Local features},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li201575,
author={Li, Y. and Wang, Y. and Wang, B. and Sui, L.},
title={Nose tip detection on three-dimensional faces using pose-invariant differential surface features},
journal={IET Computer Vision},
year={2015},
volume={9},
number={1},
pages={75-84},
doi={10.1049/iet-cvi.2014.0070},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988269675&doi=10.1049%2fiet-cvi.2014.0070&partnerID=40&md5=9b44b1684d50589e30f8aa93abe2e4b3},
affiliation={School of Computer Science and Engineering, Xi'an University of Technology, 5 South Jinhua Road, Xi'an, 710048, China},
abstract={Three-dimensional (3D) facial data offer the potential to overcome the difficulties caused by the variation of head pose and illumination in 2D face recognition. In 3D face recognition, localisation of nose tip is essential to face normalisation, face registration and pose correction etc. Most of the existing methods of nose tip detection on 3D face deal mainly with frontal or near-frontal poses or are rotation sensitive. Many of them are training-based or model-based. In this study, a novel method of nose tip detection is proposed. Using pose-invariant differential surface features - high-order and low-order curvatures, it can detect nose tip on 3D faces under various poses automatically and accurately. Moreover, it does not require training and does not depend on any particular model. Experimental results on GavabDB verify the robustness and accuracy of the proposed method. © The Institution of Engineering and Technology 2015.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liang2015406,
author={Liang, R. and Shen, W. and Li, X.-X. and Wang, H.},
title={Bayesian multi-distribution-based discriminative feature extraction for 3D face recognition},
journal={Information Sciences},
year={2015},
volume={320},
pages={406-417},
doi={10.1016/j.ins.2015.03.063},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937521792&doi=10.1016%2fj.ins.2015.03.063&partnerID=40&md5=ea6a6994deb813d32a7a1d39602f0d94},
affiliation={College of Information Engineering, Zhejiang University of TechnologyHangzhou, China},
abstract={Due to the difficulties associated with the collection of 3D samples, 3D face recognition technologies often have to work with smaller than desirable sample sizes. With the aim of enlarging the training number for each subject, we divide each training image into several patches. However, this immediately introduces two further problems for 3D models: high computational cost and dispersive features caused by the divided 3D image patches. We therefore first map 3D face images into 2D depth images, which greatly reduces the dimension of the samples. Though the depth images retain most of the robust features of 3D images, such as pose and illumination invariance, they lose many discriminative features of the original 3D samples. In this study, we propose a Bayesian learning framework to extract the discriminative features from the depth images. Specifically, we concentrate the features of the intra-class patches to a mean feature by maximizing the multivariate Gaussian likelihood function, and, simultaneously, enlarge the distances between the inter-class mean features by maximizing the exponential priori distribution of the mean features. For classification, we use the nearest neighbor classifier combined with the Mahalanobis distance to calculate the distance between the features of the test image and items in the training set. Experiments on two widely-used 3D face databases demonstrate the efficiency and accuracy of our proposed method compared to relevant state-of-the-art methods. © 2015 Elsevier Inc. All rights reserved.},
author_keywords={3D face recognition;  Bayesian learning;  Depth image;  Single training sample per person},
document_type={Article},
source={Scopus},
}

@ARTICLE{Quan2015199,
author={Quan, W. and Matuszewski, B.J. and Shark, L.-K.},
title={3-d face recognition using geodesic-map representation and statistical shape modelling},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9493},
pages={199-212},
doi={10.1007/978-3-319-27677-9_13},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955314982&doi=10.1007%2f978-3-319-27677-9_13&partnerID=40&md5=e85737d15347f5ea197969c838869be9},
affiliation={Applied Digital Signal and Image Processing (ADSIP) Research Centre, University of Central Lancashire, Preston, PR1 2HE, United Kingdom},
abstract={3-D face recognition research has received significant attention in the past two decades because of the rapid development in imaging technology and ever increasing security demand of modern society. One of its challenges is to cope with non-rigid deformation among faces, which is often caused by the changes of appearance and facial expression. Popular solutions to deal with this problem are to detect the deformable parts of the face and exclude them, or to represent a face in terms of sparse signature points, curves or patterns that are invariant to deformation. Such approaches, however, may lead to loss of information which is important for classification. In this paper, we propose a new geodesic-map representation with statistical shape modelling for handling the non-rigid deformation challenge in face recognition. The proposed representation captures all geometrical information from the entire 3-D face and provides a compact and expression-free map that preserves intrinsic geometrical information. As a result, the search for dense points correspondence in the face recognition task can be speeded up by using a simple image-based method instead of time-consuming, recursive closest distance search in 3-D space. An experimental investigation was conducted on 3-D face scans using publicly available databases and compared with the benchmark approaches. The experimental results demonstrate that the proposed scheme provides a highly competitive new solution for 3-D face recognition. © Springer International Publishing Switzerland 2015.},
author_keywords={3-D face recognition;  Geodesic-map representation;  Non-rigid deformation;  Shape modeling},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ming201514,
author={Ming, Y.},
title={Robust regional bounding spherical descriptor for 3D face recognition and emotion analysis},
journal={Image and Vision Computing},
year={2015},
volume={35},
pages={14-22},
doi={10.1016/j.imavis.2014.12.003},
note={cited By 26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921669860&doi=10.1016%2fj.imavis.2014.12.003&partnerID=40&md5=fe785e43fe879b32d41aadd4abc61953},
affiliation={School of Electronic Engineering, Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, 100876, China},
abstract={3D face recognition and emotion analysis play important roles in many fields of communication and edutainment. An effective facial descriptor, with higher discriminating capability for face recognition and higher descriptiveness for facial emotion analysis, is a challenging issue. However, in the practical applications, the descriptiveness and discrimination are independent and contradictory to each other. 3D facial data provide a promising way to balance these two aspects. In this paper, a robust regional bounding spherical descriptor (RBSR) is proposed to facilitate 3D face recognition and emotion analysis. In our framework, we first segment a group of regions on each 3D facial point cloud by shape index and spherical bands on the human face. Then the corresponding facial areas are projected to regional bounding spheres to obtain our regional descriptor. Finally, a regional and global regression mapping (RGRM) technique is employed to the weighted regional descriptor for boosting the classification accuracy. Three largest available databases, FRGC v2, CASIA and BU-3DFE, are contributed to the performance comparison and the experimental results show a consistently better performance for 3D face recognition and emotion analysis. © 2015 Elsevier B.V. All rights reserved.},
author_keywords={3D face recognition;  Emotion analysis;  Kullback-Leiber divergence (KLD);  Regional and global regression;  Regional bounding spherical descriptor},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang201527,
author={Wang, H. and Mu, Z. and Zeng, H. and Huang, M.},
title={3D face recognition using local features matching on sphere depth representation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9428},
pages={27-34},
doi={10.1007/978-3-319-25417-3_4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950245926&doi=10.1007%2f978-3-319-25417-3_4&partnerID=40&md5=a7ea7b117fa5089c7a6e2e77750229fd},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China},
abstract={This paper proposes a 3D face recognition approach using sphere depth image, which is robust to pose variations in unconstrained environments. The input 3D face point clouds is first transformed into sphere depth images, and then represented as a 3DLBP image to enhance the distinctiveness of smooth and similar facial depth images. An improved SIFT algorithm is applied in the following matching process. The improved SIFT algorithm employs the learning to rank approach to select the keypoints with higher stability and repeatability instead of manually rule-based method used by the original SIFT algorithm. The proposed face recognition method is evaluated on CASIA 3D face database. And the experimental results show our approach has superior performance than many existing methods for 3D face recognition and handles pose variations quite well. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  Learning to rank;  Local binary patterns;  Sphere depth image},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ming2015352,
author={Ming, Y. and Jin, Y.},
title={Robust 3D local SIFT features for 3D face recognition},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9246},
pages={352-359},
doi={10.1007/978-3-319-22873-0_31},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985029352&doi=10.1007%2f978-3-319-22873-0_31&partnerID=40&md5=4448fcb45dc3bae2a2c99810502b1ce7},
affiliation={School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, 100044, China},
abstract={In this paper, a robust 3D local SIFT feature is proposed for 3D face recognition. For preprocessing the original 3D face data, facial regional segmentation is first employed by fusing curvature characteristics and shape band mechanism. Then, we design a new local descriptor for the extracted regions, called 3D local Scale-Invariant Feature Transform (3D LSIFT). The key point detection based on 3D LSIFT can effectively reflect the geometric characteristic of 3D facial surface by encoding the gray and depth information captured by 3D face data. Then, 3D LSIFT descriptor extends to describe the discrimination on 3D faces. Experimental results based on the common international 3D face databases demonstrate the higher-qualified performance of our proposed algorithm with effectiveness, robustness, and universality. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  3D local Scale-Invariant feature transform;  Depth information;  Facial region segmentation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Echeagaray-Patrón2015,
author={Echeagaray-Patrón, B.A. and Kober, V.},
title={3D face recognition based on matching of facial surfaces},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9598},
doi={10.1117/12.2186695},
art_number={95980V},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951325808&doi=10.1117%2f12.2186695&partnerID=40&md5=cb5a757e08c6a66683fc0706f09faf95},
affiliation={Department of Computer Science, CICESE, Ensenada, B.C.22860, Mexico; Department of Mathematics, Chelyabinsk State University, Russian Federation},
abstract={Face recognition is an important task in pattern recognition and computer vision. In this work a method for 3D face recognition in the presence of facial expression and poses variations is proposed. The method uses 3D shape data without color or texture information. A new matching algorithm based on conformal mapping of original facial surfaces onto a Riemannian manifold followed by comparison of conformal and isometric invariants computed in the manifold is suggested. Experimental results are presented using common 3D face databases that contain significant amount of expression and pose variations. © 2015 SPIE.},
author_keywords={3D face recognition;  3D facial shape analysis;  Conformal mapping},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Guo2015,
author={Guo, Z. and Liu, S. and Wang, Y. and Lei, T.},
title={Learning deformation model for expression-robust 3D face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9817},
doi={10.1117/12.2228002},
art_number={98170O},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028295582&doi=10.1117%2f12.2228002&partnerID=40&md5=42fcb3ae1a1a8506c08003ac3fd73bc1},
affiliation={School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China; School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lanzhou, 730070, China},
abstract={Expression change is the major cause of local plastic deformation of the facial surface. The intra-class differences with large expression change somehow are larger than the inter-class differences as it's difficult to distinguish the same individual with facial expression change. In this paper, an expression-robust 3D face recognition method is proposed by learning expression deformation model. The expression of the individuals on the training set is modeled by principal component analysis, the main components are retained to construct the facial deformation model. For the test 3D face, the shape difference between the test and the neutral face in training set is used for reconstructing the expression change by the constructed deformation model. The reconstruction residual error is used for face recognition. The average recognition rate on GavabDB and self-built database reaches 85.1% and 83%, respectively, which shows strong robustness for expression changes. © 2015 SPIE.},
author_keywords={3D face recognition;  Facial deformation model;  Principal component analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Luo2015,
author={Luo, J. and Geng, S.Z. and Xiao, Z.X. and Xiu, C.B.},
title={A review of recent advances in 3d face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9443},
doi={10.1117/12.2178750},
art_number={944303},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925431201&doi=10.1117%2f12.2178750&partnerID=40&md5=f8e793b50759be140f6e5bf45667a121},
affiliation={Key Laboratory of Advanced of Electrical Engineering and Energy Technology, Tianjin Polytechnic University, Tianjin, 300387, China; College of Electrical Engineering and Automation, Tianjin Polytechnic University, Tianjin, 300387, China},
abstract={Face recognition based on machine vision has achieved great advances and been widely used in the various fields. However, there are some challenges on the face recognition, such as facial pose, variations in illumination, and facial expression. So, this paper gives the recent advances in 3D face recognition. 3D face recognition approaches are categorized into four groups: minutiae approach, space transform approach, geometric features approach, model approach. Several typical approaches are compared in detail, including feature extraction, recognition algorithm, and the performance of the algorithm. Finally, this paper summarized the challenge existing in 3D face recognition and the future trend. This paper aims to help the researches majoring on face recognition. © 2015 SPIE.},
author_keywords={3D face recognition;  geometric features;  minutiae approach.;  space transform},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Belghini2015317,
author={Belghini, N. and Ezghari, S. and Zahi, A.},
title={3D face recognition using facial curves, sparse random projection and fuzzy similarity measure},
journal={Colloquium in Information Science and Technology, CIST},
year={2015},
volume={2015-January},
number={January},
pages={317-322},
doi={10.1109/CIST.2014.7016639},
art_number={7016639},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938075627&doi=10.1109%2fCIST.2014.7016639&partnerID=40&md5=bca04cb8b40640821dbbc277a0cf6e71},
affiliation={System Intelligent and Application Laboratory (SIA) FST, Fez, Morocco},
abstract={In this paper, we propose a fuzzy similarity based classification approach for 3D face recognition. In the feature extraction method, we exploit curve concept to represent the 3D facial data, two types of curves was considered: depth-level and depth-radial curves. As the dimension of the obtained features is high, the problem 'curse of dimensionality' appears. To solve this problem, the Random Projection (RP) method was used. The proposed classifier performs Fuzzification operation using triangular membership functions for input data and ordered weighted averaging operators to measure similarity. Experiment was conducted using vrml files from 3D Database considering only one training sample per person. The obtained results are very promising for depth-level and depth-radial curves, besides the recognition rates are higher than 98%. © 2014 IEEE.},
author_keywords={3D face recognition;  facial curves;  fuzzy logic;  OWA operator;  similarity measure;  sparse random projection},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tang2015466,
author={Tang, Y. and Sun, X. and Huang, D. and Morvan, J.-M. and Wang, Y. and Chen, L.},
title={3D face recognition with asymptotic cones based principal curvatures},
journal={Proceedings of 2015 International Conference on Biometrics, ICB 2015},
year={2015},
pages={466-472},
doi={10.1109/ICB.2015.7139111},
art_number={7139111},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943279293&doi=10.1109%2fICB.2015.7139111&partnerID=40&md5=bd52f57fa0f04d14b00dab8a5d4e64e2},
affiliation={Université de Lyon, CNRS, Ecole Centrale de Lyon, LIRIS, Lyon, 69134, France; King Abdullah University of Science and Technology, V.C.C. Research Center, Thuwal, 23955-6900, Saudi Arabia; IRIP, School of Computer Science and Engineering, Beihang Universtiy, Beijing, 100191, China; Université de Lyon, CNRS, Université Claude Bernard Lyon 1, ICJ UMR 5208, Villeurbanne, F-69622, France},
abstract={The classical curvatures of smooth surfaces (Gaussian, mean and principal curvatures) have been widely used in 3D face recognition (FR). However, facial surfaces resulting from 3D sensors are discrete meshes. In this paper, we present a general framework and define three principal curvatures on discrete surfaces for the purpose of 3D FR. These principal curvatures are derived from the construction of asymptotic cones associated to any Borel subset of the discrete surface. They describe the local geometry of the underlying mesh. First two of them correspond to the classical principal curvatures in the smooth case. We isolate the third principal curvature that carries out meaningful geometric shape information. The three principal curvatures in different Borel subsets scales give multi-scale local facial surface descriptors. We combine the proposed principal curvatures with the LNP-based facial descriptor and SRC for recognition. The identification and verification experiments demonstrate the practicability and accuracy of the third principal curvature and the fusion of multi-scale Borel subset descriptors on 3D face from FRGC v2.0. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ratyal2015241,
author={Ratyal, N.I. and Taj, I.A. and Bajwa, U.I. and Sajid, M.},
title={3D face recognition based on pose and expression invariant alignment},
journal={Computers and Electrical Engineering},
year={2015},
volume={46},
pages={241-255},
doi={10.1016/j.compeleceng.2015.06.007},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931030581&doi=10.1016%2fj.compeleceng.2015.06.007&partnerID=40&md5=a95f41db3d492d423152cf1d2907956a},
affiliation={Vision and Pattern Recognition Systems Research Group, Mohammad Ali Jinnah University, Islamabad, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan},
abstract={In this paper we present a novel pose and expression invariant approach for 3D face registration based on intrinsic coordinate system characterized by nose tip, horizontal nose plane and vertical symmetry plane of the face. It is observed that distance of nose tip from 3D scanner is reduced after pose correction which is presented as a quantifying heuristic for proposed registration scheme. In addition, motivated by the fact that a single classifier cannot be generally efficient against all face regions, a two tier ensemble classifier based 3D face recognition approach is presented which employs Principal Component Analysis (PCA) for feature extraction and Mahalanobis Cosine (MahCos) matching score for classification of facial regions with weighted Borda Count (WBC) based combination and a re-ranking stage. The performance of proposed approach is corroborated by extensive experiments performed on two databases: GavabDB and FRGC v2.0, confirming effectiveness of fusion strategies to improve performance. © 2015 Elsevier Ltd. All rights reserved.},
author_keywords={3D face recognition;  3D registration;  Ensemble classifier;  Fusion;  Intrinsic coordinate system},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wang2015192,
author={Wang, X. and Ruan, Q. and Jin, Y. and An, G.},
title={3D face recognition using closest point coordinates and spherical vector norms},
journal={IET Conference Publications},
year={2015},
volume={2015},
number={CP681},
pages={192-196},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983122121&partnerID=40&md5=4a26023e54f7fb05eaa6d68668c88d60},
affiliation={Institution of Information Science, Beijing Jiaotong University, Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, 100044, China},
abstract={In this paper, we introduce a new feature named spherical vector norms for 3D face recognition. The proposed feature is efficient, insensitive to facial expression and contains discriminatory information of 3D face. The feature extraction method is firstly finding a set of the points with the closest distance to the standard face, denoted as closest point coordinates, and then extracting the spherical vector norms of these points. This paper combines point coordinates and spherical vector norms for improving recognition. Finally this approach is finished by Linear Discriminant Analysis (LDA) and Nearest Neighbor classifier. We have performed different experiments on the Face Recognition Grand Challenge database. It achieves the verification rate of 97.11% on All vs. All experiment at 0.1% FAR and 96.64% verification rate on Neutral vs. Expression experiment.},
author_keywords={3D face recognition;  Linear discriminant analysis;  Spherical vector norms},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhang20153357,
author={Zhang, C. and Gu, Y. and Wang, Y. and Li, F. and Zhan, Y. and Pi, J. and Qu, L.},
title={Adaptive multiple regions matching for 3D face recognition under expression and pose variations},
journal={Journal of Computational Information Systems},
year={2015},
volume={11},
number={9},
pages={3357-3369},
doi={10.12733/jcis14297},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938320850&doi=10.12733%2fjcis14297&partnerID=40&md5=af76d7b96bb6eca2db8bc3e1babc780a},
affiliation={Key Laboratory of Wireless Sensor Network & Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, 200050, China; University of Chinese Academy of Sciences, Beijing, 100049, China; Shanghai Internet of Things Co., Ltd., Shanghai, 201800, China},
abstract={Expression and pose variations are two major challenges for 3D face recognition. This paper presents a method to cope with these two challenges by fusing the matching results of adaptive multiple regions on the 3D face. First, one approach is proposed for pose correction of 3D face based on three landmark points: nose tip, nasion, and subnasale. Then multiple regions are adaptively chosen from the facial surface, which include nose, left and right eye-forehead regions, left and right cheeks, and mouth-chin region. Next, a least trimmed square Hausdorff distance method is applied for region matching. Moreover, to obtain a better overall performance, several score-level and rank-level fusion schemes are used to fuse the contribution of each region. The proposed approach is evaluated on the Bosphorus and the BU-3DFE databases, and yields good results. The study shows that the proposed algorithm is robust to expression and pose changes. ©, 2015, Binary Information Press. All right reserved.},
author_keywords={3D face recognition;  Expression;  Pose correction;  Pose rotation;  Region matching},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chouchane2015,
author={Chouchane, A. and Belahcene, M. and Ouamane, A. and Bourennane, S.},
title={3D face recognition based on histograms of local descriptors},
journal={2014 4th International Conference on Image Processing Theory, Tools and Applications, IPTA 2014},
year={2015},
doi={10.1109/IPTA.2014.7001925},
art_number={7001925},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921721830&doi=10.1109%2fIPTA.2014.7001925&partnerID=40&md5=4bbf52130cd2484d05cce4611c376687},
affiliation={LMSE, University of Biskra, Biskra, R.P.07000, Algeria; Centre de Développement des Technologies Avancées, ASM Alger, Algeria; Institut Fresnel, UMR CNRS 7249, Ecole Centrale Marseille, France},
abstract={Face recognition in an uncontrolled condition such as illumination and expression variations is a challenging task. Local descriptor is one of the most efficient methods used to deal with these problems. In this paper, we present an automatic 3D face recognition approach based on three local descriptors, local phase quantization (LPQ), Three-Patch Local Binary Patterns (TPLBP) and Four-Patch Local Binary Patterns (TPLBP). Facial images are passing through one of the three descriptors and divided into sub-regions or rectangular blocks. The histogram of each sub-region is extracted and concatenated into a single feature vector. PCA (Principal Component Analysis) and EFM (Enhanced Fisher linear discriminant Model) are used to reduce the dimensionality of the resulting feature vectors. Finally, these vectors are sent to the classification step, when we use two methods; SVM (Support Victor Machine) and similarity measures. CASIA 3D face database is introduced to experimental evaluation. The experimental results illustrate a high recognition performance of the proposed approach. © 2014 IEEE.},
author_keywords={3D face recognition;  FPLBP;  Local phase quantization;  Locale descriptors;  Support vector machines;  TPLBP},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chouchane201550,
author={Chouchane, A. and Belahcene, M. and Bourennane, S.},
title={3D and 2D face recognition using integral projection curves based depth and intensity images},
journal={International Journal of Intelligent Systems Technologies and Applications},
year={2015},
volume={14},
number={1},
pages={50-69},
doi={10.1504/IJISTA.2015.072219},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964744543&doi=10.1504%2fIJISTA.2015.072219&partnerID=40&md5=e5008a255876319ef73de7c015360bc8},
affiliation={Faculty of Science and Technology, Department of Electrical Engineering, University of Mohamed Khider, Biskra, BP 145 RP, Biskra, 07000, Algeria; Institut Fresnel, UMR CNRS 7249, Ecole Centrale Marseille, France},
abstract={This paper presents an automatic face recognition system in the presence of illumination, expressions and pose variations based on depth and intensity information. At first, the registration of 3D faces is achieved using iterative closest point (ICP). Nose tip point must be located using Maximum Intensity Method. This point usually has the largest depth value; however there is a problem with some unnecessary data such as: shoulders, hair, neck and parts of clothes; to cope with this issue, we propose the integral projection curves (IPC)-based facial area segmentation to extract the facial area. After that, the combined method principal component analysis (PCA) with enhanced fisher model (EFM) is used to obtain the feature matrix vectors. Finally, the classification is performed using distance measurement and support vector machine (SVM). The experiments are implemented on two face databases CASIA3D and GavabDB; our results show that the proposed method achieves a high recognition performance. Copyright © 2015 Inderscience Enterprises Ltd.},
author_keywords={2D and 3D face recognition;  EFM;  Enhanced fisher model;  IPC-based facial area segmentation;  Nose tip;  PCA;  Principal component analysis;  Support vector machine;  SVM},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lagorio2015,
author={Lagorio, A. and Cadoni, M. and Grosso, E. and Tistarelli, M.},
title={A 3D algorithm for unsupervised face identification},
journal={3rd International Workshop on Biometrics and Forensics, IWBF 2015},
year={2015},
doi={10.1109/IWBF.2015.7110239},
art_number={7110239},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936101701&doi=10.1109%2fIWBF.2015.7110239&partnerID=40&md5=65b942c6e6bd6ec99d853a5a632cd56f},
affiliation={VisionLab - Computer Vision Laboratory, United Kingdom},
abstract={With the increasing availability of low-cost 3D data acquisition devices, the use of 3D face data for the recognition of individuals is becoming more appealing and computationally feasible. This paper proposes a completely automatic algorithm for face registration and matching. The algorithm is based on the extraction of stable 3D facial features characterizing the face and the subsequent construction of a signature manifold. The facial features are extracted by performing a continuous-to-discrete scale-space analysis. Registration is driven from the matching of triplets of feature points and the registration error is computed as shape matching score. Conversely to most techniques in the literature, a major advantage of the proposed method is that no data pre-processing is required. Therefore all presented results have been obtained exclusively from the raw data available from the 3D acquisition device. The method has been tested on the Bosphorus 3D face database and the performances compared to the ICP baseline algorithm. Even in presence of noise in the data, the algorithm proved to be very robust and reported identification performances which are aligned to the current state of the art, but without requiring any pre-processing of the raw data. © 2015 IEEE.},
author_keywords={3D Face recognition;  Face recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Said2015,
author={Said, S. and Jemai, O. and Zaied, M. and Ben Amar, C.},
title={3D fast wavelet network model-assisted 3D face recognition},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9875},
doi={10.1117/12.2228368},
art_number={98750E},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958206236&doi=10.1117%2f12.2228368&partnerID=40&md5=e95e90acc2067f0a5a38e384b37d87d2},
affiliation={REsearch Groups in Intelligent Machines (REGIM-Lab), University of Sfax, National Engineering School of Sfax, BP 1173, Sfax, 3038, Tunisia},
abstract={In last years, the emergence of 3D shape in face recognition is due to its robustness to pose and illumination changes. These attractive benefits are not all the challenges to achieve satisfactory recognition rate. Other challenges such as facial expressions and computing time of matching algorithms remain to be explored. In this context, we propose our 3D face recognition approach using 3D wavelet networks. Our approach contains two stages: learning stage and recognition stage. For the training we propose a novel algorithm based on 3D fast wavelet transform. From 3D coordinates of the face (x,y,z), we proceed to voxelization to get a 3D volume which will be decomposed by 3D fast wavelet transform and modeled after that with a wavelet network, then their associated weights are considered as vector features to represent each training face. For the recognition stage, an unknown identity face is projected on all the training WN to obtain a new vector features after every projection. A similarity score is computed between the old and the obtained vector features. To show the efficiency of our approach, experimental results were performed on all the FRGC v.2 benchmark. © 2015 SPIE.},
author_keywords={3D face recognition;  Fast wavelet transform;  Wavelet network},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2015151,
author={Liu, S. and Mu, Z. and Huang, H.},
title={3D face recognition fusing spherical depth map and spherical texture map},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9428},
pages={151-159},
doi={10.1007/978-3-319-25417-3_19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950277767&doi=10.1007%2f978-3-319-25417-3_19&partnerID=40&md5=828cf646ebe1b2dd0a70ea3a6fdb0939},
affiliation={School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Computing Center, Beijing Information Science and Technology University, Beijing, 100192, China},
abstract={Face recognition in unconstrained environments is often influenced by pose variations. And the problem is basically the identification that uses partial data. In this paper, a method fusing structure and texture information is proposed to solve the problem. In the register phase, the approximate 180 degree information of face is acquired, and the data used to identify individual is obtained from a random single view. Pure face is extracted from 3D data first, then convert the original data to the form of spherical depth map (SDM) and spherical texture map (STM), which are invariant to out-plane rotation, subsequently facilitating the successive alignment-free identification that is robust to pose variations. We make identification through sparse representation for its well performance with the two maps. Experiments show that our proposed method gets a high recognition rate with pose and expression variations. © Springer International Publishing Switzerland 2015.},
author_keywords={Face recognition;  Sparse representation;  Spherical Depth Map;  Spherical Texture Map},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Svoboda2015452,
author={Svoboda, J. and Bronstein, M.M. and Drahansky, M.},
title={Contactless biometric hand geometry recognition using a low-cost 3D camera},
journal={Proceedings of 2015 International Conference on Biometrics, ICB 2015},
year={2015},
pages={452-457},
doi={10.1109/ICB.2015.7139109},
art_number={7139109},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943329089&doi=10.1109%2fICB.2015.7139109&partnerID=40&md5=088b980bbb44eef1cfc61d3c229e1b06},
affiliation={Faculty of Informatics, Universita della Svizzera Italiana, Lugano, Switzerland; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic},
abstract={In the past decade, the interest in using 3D data for biometric person authentication has increased significantly, propelled by the availability of affordable 3D sensors. The adoption of 3D features has been especially successful in face recognition applications, leading to several commercial 3D face recognition products. In other biometric modalities such as hand recognition, several studies have shown the potential advantage of using 3D geometric information, however, no commercial-grade systems are currently available. In this paper, we present a contactless 3D hand recognition system based on the novel Intel RealSense camera, the first mass-produced embeddable 3D sensor. The small form factor and low cost make this sensor especially appealing for commercial biometric applications, however, they come at the price of lower resolution compared to more expensive 3D scanners used in previous research. We analyze the robustness of several existing 2D and 3D features that can be extracted from the images captured by the RealSense camera and study the use of metric learning for their fusion. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tian2015499,
author={Tian, L. and Fan, C. and Ming, Y. and Shi, J.},
title={SRDANet: An efficient deep learning algorithm for face analysis},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9244},
pages={499-510},
doi={10.1007/978-3-319-22879-2_46},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985006693&doi=10.1007%2f978-3-319-22879-2_46&partnerID=40&md5=677312dc329735134faf0a8467c2ea50},
affiliation={Beijing Key Laboratory of Work Safety Intelligent Monitoring, School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China},
abstract={In this work, we take advantage of the superiority of Spectral Graph Theory in classification application and propose a novel deep learning framework for face analysis which is called Spectral Regression Discriminant Analysis Network (SRDANet). Our SRDANet model shares the same basic architecture of Convolutional Neural Network (CNN),which comprises three basic components: convolutional filter layer, nonlinear processing layer and feature pooling layer. While it is different from traditional deep learning network that in our convolutional layer, we extract the leading eigenvectors from patches in facial image which are used as filter kernels instead of randomly initializing kernels and update them by stochastic gradient descent (SGD). And the output of all cascaded convolutional filter layers is used as the input of nonlinear processing layer. In the following nonlinear processing layer, we use hashing method for nonlinear processing. In feature pooling layer, the block-based histograms are employed to pooling output features instead of max-pooling technique. At last, the output of feature pooling layer is considered as one final feature output of our model. Different from the previous single-task research for face analysis, our proposed approach demonstrates an excellent performance in face recognition and expression recognition with 2D/3D facial images simultaneously. Extensive experiments conducted on many different face analysis databases demonstrate the efficiency of our proposed SRDANet model. Databases such as Extended Yale B, PIE, ORL are used for 2D face recognition, FRGC v2 is used for 3D face recognition and BU-3DFE is used for 3D expression recognition. © Springer International Publishing Switzerland 2015.},
author_keywords={Deep learning;  Expression recognition;  Face recognition;  Spectral regression discriminant analysis;  SRDA network},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{MatíasdiMartino2015176,
author={Matías di Martino, J. and Fernández, A. and Ferrari, J.},
title={One-shot 3D-gradient method applied to face recognition},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9423},
pages={176-183},
doi={10.1007/978-3-319-25751-8_22},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983485990&doi=10.1007%2f978-3-319-25751-8_22&partnerID=40&md5=d1ca3b0d2eb47528de1f16f2734dc918},
affiliation={Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay},
abstract={In this work we describe a novel one-shot face recognition setup. Instead of using a 3D scanner to reconstruct the face, we acquire a single photo of the face of a person while a rectangular pattern is been projected over it. Using this unique image, it is possible to extract 3D low-level geometrical features without the explicit 3D reconstruction. To handle expression variations and occlusions that may occur (e.g. wearing a scarf or a bonnet), we extract information just from the eyes-forehead and nose regions which tend to be less influenced by facial expressions. Once features are extracted, SVM hyper-planes are obtained from each subject on the database (one vs all approach), then new instances can be classified according to its distance to each of those hyper-planes. The advantage of our method with respect to other ones published in the literature, is that we do not need and explicit 3D reconstruction. Experiments with the Texas 3D Database and with new acquired data are presented, which shows the potential of the presented framework to handle different illumination conditions, pose and facial expressions. © Springer International Publishing Switzerland 2015.},
author_keywords={3D face recognition;  Differential 3D reconstruction},
document_type={Conference Paper},
source={Scopus},
}
