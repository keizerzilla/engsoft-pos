@article{ISI:000457666900036,
abstract = {We propose a novel method for measuring the nasal similarity among 3D faces. Firstly, we construct a representation for the nose shape, which is composed of a set of geodesic curves, each crosses the bridge of the nose. Next, using these geodesic curves, we formulate a similarity measure to compare among noses in the curve shape space. Under the Riemannian framework, the shape space is a quotient space for which the scaling, translation and rotation are removed. Since the nose similarity measure is based on the shape comparison, the proposed method has the following advantages: (1) the similarity measure is robust to facial expressions since the nose is not affected by facial expressions; (2) the geometric features of the nose shape match well with the human perception; (3) the similarity measure is independent of the mesh grid because the chosen nose curves are not sensitive to the triangular mesh model. We construct a nasal hierarchical structure for noses organization which is based on nose similarity measure results. In our experiments, we evaluate the performance of the proposed method and compare it with competing methods on three public face databases namely, FRGC2.0, Texas3D and BosphorusDB. The results show superiority of the proposed method in terms of both the speed and the accuracy when the nasal measurements are processed in the nasal hierarchical structure and the nasal samples with low sampling rate (5{\%}-25{\%} of original point cloud). (C) 2018 Elsevier Ltd. All rights reserved.},
author = {Lv, Chenlei and Wu, Zhongke and Wang, Xingce and Zhou, Mingquan and Toh, Kar-Ann},
doi = {10.1016/j.patcog.2018.12.006},
issn = {0031-3203},
journal = {PATTERN RECOGNITION},
keywords = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
pages = {458--469},
title = {{Nasal similarity measure of 3D faces based on curve shape space}},
volume = {88},
year = {2019}
}
@inproceedings{7424213,
abstract = {This work proposes a new algorithm for 3D face recognition. The algorithm uses 3D shape data without color or texture information and exploits local curvature information which is a measure with high discriminant capability and robust to deformations such as rotation and scaling. In order to reduce high dimensionality of typical face surfaces our approach uses a conformal parameterization, preserving angles of original faces and simplifies the correspondence problem. Experimental results are presented and discussed using CASIA and Gavab databases.},
annote = {From Duplicate 1 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

cited By 20

From Duplicate 2 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

From Duplicate 1 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

cited By 20},
author = {Echeagaray-Patron, B A and Miramontes-Jaramillo, D and Kober, V},
booktitle = {2015 International Conference on Computational Science and Computational Intelligence (CSCI)},
doi = {10.1109/CSCI.2015.133},
keywords = {3D facial recogn,face recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1,visual databases},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
pages = {843--844},
title = {{Conformal parameterization and curvature analysis for 3D facial recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964412211{\&}doi=10.1109{\%}2FCSCI.2015.133{\&}partnerID=40{\&}md5=6a3fc9e7dac95a6f25aacc425aa40af5},
year = {2016}
}
@conference{Ganguly2016275,
abstract = {Face and facial attributes represent meaningful definition about a variety of information to discriminate an individual from others and for developing a computational model for automatic face recognition purpose. However, in this work, selection of relevant features from newly created face space is the pivotal contribution of the authors. Here, authors have demonstrated a new face space 'Complement Component' that have been used to extract the four basic components along X, and Y axes in four directions. Later, authors have experimented the discriminative attributes from these face spaces for recognition purpose. Here, comparison of the proposed method has been reported by examining its success on two well accepted 3D face databases, namely: Frav3D and Texas3D. In case of 2D face images, it does not contain depth like information i.e. Z-values in X-Y plane through intensity values. Therefore, it has not been undertaken during this investigation. {\textcopyright} 2015 IEEE.},
annote = {cited By 1},
author = {Ganguly, S and Bhattachaijee, D and Nasipuri, M},
booktitle = {2015 IEEE International Conference on Computer Graphics, Vision and Information Security, CGVIS 2015},
doi = {10.1109/CGVIS.2015.7449936},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {275--278},
title = {{3D face recognition from complement component range face images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966632732{\&}doi=10.1109{\%}2FCGVIS.2015.7449936{\&}partnerID=40{\&}md5=ac5698f1d98fa8b29941ffc837f84a7b},
year = {2016}
}
@inproceedings{ISI:000446968900004,
abstract = {With the growth of face recognition, the spoofing mask attacks attract more attention in biometrics research area. In recent years, the countermeasures based on the texture and depth image against spoofing mask attacks have been reported, but the research based on 3D meshed sample has not been studied yet. In this paper, we propose to apply 3D shape analysis based on principal curvature measures to describe the meshed facial surface. Meanwhile, a verification protocol based on this feature descriptor is designed to verify person identity and to evaluate the anti-spoofing performance on Morpho database. Furthermore, for simulating a real-life testing scenario, FRGCv2 database is enrolled as an extension of face scans to augment the ratio of genuine face samples to fraud mask samples. The experimental results show that our system can guarantee a high verification rate for genuine faces and the satisfactory anti-spoofing performance against spoofing mask attacks in parallel.},
annote = {6th International Workshop on Representations, Analysis and Recognition
of Shape and Motion from Imaging Data (RFMI), Sidi Bou Said, TUNISIA,
OCT 27-29, 2016},
author = {Tang, Yinhang and Chen, Liming},
booktitle = {REPRESENTATIONS, ANALYSIS AND RECOGNITION OF SHAPE AND MOTION FROM IMAGING DATA},
doi = {10.1007/978-3-319-60654-5_4},
editor = {{BenAmor, B and Chaieb, F and Ghorbel}, F},
isbn = {978-3-319-60654-5; 978-3-319-60653-8},
issn = {1865-0929},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {41--55},
series = {Communications in Computer and Information Science},
title = {{Shape Analysis Based Anti-spoofing 3D Face Recognition with Mask Attacks}},
volume = {684},
year = {2017}
}
@article{ISI:000395034500021,
abstract = {Techniques of 2D-3D superimposition are widely used in cases of personal identification from video surveillance systems. However, the progressive improvement of 3D image acquisition technology will enable operators to perform also 3D-3D facial superimposition. This study aims at analyzing the possible applications of 3D-3D superimposition to personal identification, although from a theoretical point of view. Twenty subjects underwent a facial 3D scan by stereophotogrammetry twice at different time periods. Scans were superimposed two by two according to nine landmarks, and root-mean-square (RMS) value of point-to-point distances was calculated. When the two superimposed models belonged to the same individual, RMS value was 2.10 mm, while it was 4.47 mm in mismatches with a statistically significant difference (p {\textless} 0.0001). This experiment shows the potential of 3D-3D superimposition: Further studies are needed to ascertain technical limits which may occur in practice and to improve methods useful in the forensic practice.},
author = {Gibelli, Daniele and {De Angelis}, Danilo and Poppa, Pasquale and Sforza, Chiarella and Cattaneo, Cristina},
doi = {10.1111/1556-4029.13290},
issn = {0022-1198},
journal = {JOURNAL OF FORENSIC SCIENCES},
keywords = {revisao{\_}V2,revisao{\_}webofscience,tutui2},
mendeley-tags = {revisao{\_}V2,revisao{\_}webofscience,tutui2},
month = {mar},
number = {2},
pages = {457--461},
title = {{A View to the Future: A Novel Approach for 3D-3D Superimposition and Quantification of Differences for Identification from Next-Generation Video Surveillance Systems}},
volume = {62},
year = {2017}
}
@inproceedings{7453907,
abstract = {In this paper, we introduce a new feature named spherical vector norms for 3D face recognition. The proposed feature is efficient, insensitive to facial expression and contains discriminatory information of 3D face. The feature extraction method is firstly finding a set of the points with the closest distance to the standard face, denoted as closest point coordinates, and then extracting the spherical vector norms of these points. This paper combines point coordinates and spherical vector norms for improving recognition. Finally this approach is finished by Linear Discriminant Analysis (LDA) and Nearest Neighbor classifier. We have performed different experiments on the Face Recognition Grand Challenge database. It achieves the verification rate of 97.11{\%} on All vs. All experiment at 0.1{\%} FAR and 96.64{\%} verification rate on Neutral vs. Expression experiment.},
annote = {28/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
28/04 Exclu{\'{i}}do (etapa 1)},
author = {{Gaoyun An} and {Yi Jin} and {Xueqiao Wang} and {Qiuqi Ruan}},
booktitle = {6th International Conference on Wireless, Mobile and Multi-Media (ICWMMN 2015)},
doi = {10.1049/cp.2015.0943},
isbn = {978-1-78561-046-2},
keywords = {etapa1,face recognition,feature extraction,id356,ieeexplore,image classifi,poly,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {etapa1,id356,ieeexplore,poly,revisao{\_}V1,revisao{\_}scopus,tutui1},
month = {nov},
pages = {5 .--5 .},
publisher = {Institution of Engineering and Technology},
title = {{3D face recognition using closest point coordinates and spherical vector norms}},
url = {https://digital-library.theiet.org/content/conferences/10.1049/cp.2015.0943},
year = {2015}
}
@article{Guo2016403,
abstract = {This paper presents a local feature based shape matching algorithm for expression-invariant 3D face recognition. Each 3D face is first automatically detected from a raw 3D data and normalized to achieve pose invariance. The 3D face is then represented by a set of keypoints and their associated local feature descriptors to achieve robustness to expression variations. During face recognition, a probe face is compared against each gallery face using both local feature matching and 3D point cloud registration. The number of feature matches, the average distance of matched features, and the number of closest point pairs after registration are used to measure the similarity between two 3D faces. These similarity metrics are then fused to obtain the final results. The proposed algorithm has been tested on the FRGC v2 benchmark and a high recognition performance has been achieved. It obtained the state-of-the-art results by achieving an overall rank-1 identification rate of 97.0{\%} and an average verification rate of 99.01{\%} at 0.001 false acceptance rate for all faces with neutral and non-neutral expressions. Further, the robustness of our algorithm under different occlusions has been demonstrated on the Bosphorus dataset. {\textcopyright} 2016 Elsevier B.V.},
annote = {cited By 7
28/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
28/04 Exclu{\'{i}}do (etapa 1)},
author = {Guo, Y and Lei, Y and Liu, L and Wang, Y and Bennamoun, M and Sohel, F},
doi = {10.1016/j.patrec.2016.04.003},
journal = {Pattern Recognition Letters},
keywords = {etapa1,id384,isi,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
mendeley-tags = {etapa1,id384,isi,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
pages = {403--412},
title = {{EI3D: Expression-invariant 3D face recognition based on feature and shape matching}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966659227{\&}doi=10.1016{\%}2Fj.patrec.2016.04.003{\&}partnerID=40{\&}md5=b09b19b7a5436b53278c02d001e93910},
volume = {83},
year = {2016}
}
@inproceedings{ISI:000374793400019,
abstract = {Face recognition in unconstrained environments is often influenced by pose variations. And the problem is basically the identification that uses partial data. In this paper, a method fusing structure and texture information is proposed to solve the problem. In the register phase, the approximate 180 degree information of face is acquired, and the data used to identify individual is obtained from a random single view. Pure face is extracted from 3D data first, then convert the original data to the form of spherical depth map (SDM) and spherical texture map (STM), which are invariant to out-plane rotation, subsequently facilitating the successive alignment-free identification that is robust to pose variations. We make identification through sparse representation for its well performance with the two maps. Experiments show that our proposed method gets a high recognition rate with pose and expression variations.},
annote = {10th Chinese Conference on Biometric Recognition (CCBR), Tianjin,
PEOPLES R CHINA, NOV 13-15, 2015},
author = {Liu, Shuai and Mu, Zhichun and Huang, Hongbo},
booktitle = {BIOMETRIC RECOGNITION, CCBR 2015},
doi = {10.1007/978-3-319-25417-3_19},
editor = {{Yang, J and Yang, J and Sun, Z and Shan, S and Zheng, W and Feng}, J},
isbn = {978-3-319-25417-3; 978-3-319-25416-6},
issn = {0302-9743},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Chinese Assoc Artificial Intelligence; Springer; Civil Aviat Univ China; Tianjin Univ Sci {\&} Technol; CASIA, Inst Intelligent Recognit},
pages = {151--159},
series = {Lecture Notes in Computer Science},
title = {{3D Face Recognition Fusing Spherical Depth Map and Spherical Texture Map}},
volume = {9428},
year = {2015}
}
@inproceedings{8122665,
abstract = {3D face recognition is a popular research area due to its vast application in biometrics and security. Local feature-based methods gain importance in the recent years due to their robustness under degradation conditions. In this paper, a novel high-order local pattern descriptor in combination with sparse representation based classifier (SRC) is proposed for expression robust 3D face recognition. 3D point clouds are converted to depth maps after preprocessing. Multi-directional derivatives are applied in spatial space to encode the depth maps based on the local derivative pattern (LDP) scheme. Directional pattern features are calculated according to local derivative variations. Since LDP computes spatial relationship of neighbors in a local region, it extracts distinct information from the depth map. Multiscale depth-LDP is presented as a novel descriptor for 3D face recognition. The descriptor is employed along with the SRC to increase the range data distinctiveness. A histogram on the derivative pattern creates a spatial feature descriptor that represents the distinctive micro-patterns from 3D data. We evaluate the proposed algorithm on two famous 3D face databases, FRGC v2.0 and Bosphorus. The experimental results demonstrate that the proposed approach achieves acceptable performance under facial expression.},
annote = {15/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
15/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Soltanpour, Sima and Wu, Q. M. Jonathan},
booktitle = {2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
doi = {10.1109/SMC.2017.8122665},
isbn = {978-1-5386-1645-1},
keywords = {emotion recognition,etapa1,face recognition,feature extra,gil,id54,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {etapa1,gil,id54,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {oct},
pages = {560--565},
publisher = {IEEE},
title = {{Multiscale depth local derivative pattern for sparse representation based 3D face recognition}},
url = {http://ieeexplore.ieee.org/document/8122665/},
year = {2017}
}
@inproceedings{ISI:000460471100001,
abstract = {This paper presents an efficient 3D face recognition method to handle facial expression. The proposed method uses the Surfaces Empirical Mode Decomposition (SEMD), facial curves and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. The basic idea is that, the face is presented at different scales by SEMD. Then the isometric invariant features on each scale are extracted. After that, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Finally, the feature vectors on each scale are associated with their corresponding geometric information. The presented method is validated on GavabDB database resulting a rank 1 recognition rate (RR) of 98.9{\%} for all faces with neutral and non-neutral expressions. This result outperforms other 3D expression-invariant face recognition methods on the same database.},
annote = {2nd Mediterranean Conference on Pattern Recognition and Artificial
Intelligence (MedPRAI), Ibn Tofail Univ, Rabat, MOROCCO, MAR 27-28, 2018},
author = {Abbad, Abdelghafour and Abbad, Khalid and Tairi, Hamid},
booktitle = {PROCEEDINGS OF THE 2ND MEDITERRANEAN CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (MEDPRAI-2018)},
doi = {10.1145/3177148.3180087},
isbn = {978-1-4503-5290-1},
keywords = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Bahria Univ; Univ Larbi Tebessi Tebessa; OCP; ENSIAS; Int Assoc Pattern Recognit},
pages = {1--6},
title = {{3D face recognition in the presence of facial expressions based on empirical mode decomposition}},
year = {2018}
}
@inproceedings{ISI:000402657200006,
abstract = {Using of 3D images for the identification was in a field of the interest of many researchers which developed a few methods offering good results. However, there are few techniques exploiting the 3D asymmetry amongst these methods. We propose fast algorithm for rough extraction face asymmetry that is used to 3D face recognition with hidden Markov models. This paper presents conception of fast method for determine 3D face asymmetry. The research results indicate that face recognition with 3D face asymmetry may be used in biometrics systems.},
annote = {8th International Conference on Image Processing and Communications
(IP{\&}C), UTP Univ Technol {\&} Sci, Inst Telecommunicat {\&} Comp Sci,
Bydgoszcz, POLAND, SEP 07-09, 2016},
author = {Bobulski, Janusz},
booktitle = {IMAGE PROCESSING AND COMMUNICATIONS CHALLENGES 8},
doi = {10.1007/978-3-319-47274-4_6},
editor = {Choras, RS},
isbn = {978-3-319-47274-4; 978-3-319-47273-7},
issn = {2194-5357},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {UTP Univ Technol {\&} Sci},
pages = {53--60},
series = {Advances in Intelligent Systems and Computing},
title = {{Face Recognition with 3D Face Asymmetry}},
volume = {525},
year = {2017}
}
@article{Liang:2015:BMD:2805325.2805648,
abstract = {Due to the difficulties associated with the collection of 3D samples, 3D face recognition technologies often have to work with smaller than desirable sample sizes. With the aim of enlarging the training number for each subject, we divide each training image into several patches. However, this immediately introduces two further problems for 3D models: high computational cost and dispersive features caused by the divided 3D image patches. We therefore first map 3D face images into 2D depth images, which greatly reduces the dimension of the samples. Though the depth images retain most of the robust features of 3D images, such as pose and illumination invariance, they lose many discriminative features of the original 3D samples. In this study, we propose a Bayesian learning framework to extract the discriminative features from the depth images. Specifically, we concentrate the features of the intra-class patches to a mean feature by maximizing the multivariate Gaussian likelihood function, and, simultaneously, enlarge the distances between the inter-class mean features by maximizing the exponential priori distribution of the mean features. For classification, we use the nearest neighbor classifier combined with the Mahalanobis distance to calculate the distance between the features of the test image and items in the training set. Experiments on two widely-used 3D face databases demonstrate the efficiency and accuracy of our proposed method compared to relevant state-of-the-art methods.},
address = {New York, NY, USA},
annote = {26/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Liang, Ronghua and Shen, Wenjia and Li, Xiao-Xin and Wang, Haixia},
doi = {10.1016/j.ins.2015.03.063},
issn = {00200255},
journal = {Information Sciences},
keywords = {3D face recognition,Bayesian learning,Depth image,Single training sample per person,acm,estela,etapa1,id283,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id283,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
number = {C},
pages = {406--417},
publisher = {Elsevier Science Inc.},
title = {{Bayesian multi-distribution-based discriminative feature extraction for 3D face recognition}},
url = {http://dx.doi.org/10.1016/j.ins.2015.03.063 http://linkinghub.elsevier.com/retrieve/pii/S0020025515002364},
volume = {320},
year = {2015}
}
@article{ISI:000423587100013,
abstract = {3D face similarity is a critical issue in computer vision, computer graphics and face recognition and so on. Since Fr,chet distance is an effective metric for measuring curve similarity, a novel 3D face similarity measure method based on Fr,chet distances of geodesics is proposed in this paper. In our method, the surface similarity between two 3D faces is measured by the similarity between two sets of 3D curves on them. Due to the intrinsic property of geodesics, we select geodesics as the comparison curves. Firstly, the geodesics on each 3D facial model emanating from the nose tip point are extracted in the same initial direction with equal angular increment. Secondly, the Fr,chet distances between the two sets of geodesics on the two compared facial models are computed. At last, the similarity between the two facial models is computed based on the Fr,chet distances of the geodesics obtained in the second step. We verify our method both theoretically and practically. In theory, we prove that the similarity of our method satisfies three properties: reflexivity, symmetry, and triangle inequality. And in practice, experiments are conducted on the open 3D face database GavaDB, Texas 3D Face Recognition database, and our 3D face database. After the comparison with iso-geodesic and Hausdorff distance method, the results illustrate that our method has good discrimination ability and can not only identify the facial models of the same person, but also distinguish the facial models of any two different persons.},
author = {Zhao, Jun-Li and Wu, Zhong-Ke and Pan, Zhen-Kuan and Duan, Fu-Qing and Li, Jin-Hua and Lv, Zhi-Han and Wang, Kang and Chen, Yu-Cong},
doi = {10.1007/s11390-018-1814-7},
issn = {1000-9000},
journal = {JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY},
keywords = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {207--222},
title = {{3D Face Similarity Measure by Fr,chet Distances of Geodesics}},
volume = {33},
year = {2018}
}
@inproceedings{ISI:000368591300013,
abstract = {In last years, the emergence of 3D shape in face recognition is due to its robustness to pose and illumination changes. These attractive benefits are not all the challenges to achieve satisfactory recognition rate. Other challenges such as facial expressions and computing time of matching algorithms remain to be explored. In this context, we propose our 3D face recognition approach using 3D wavelet networks. Our approach contains two stages: learning stage and recognition stage. For the training we propose a novel algorithm based on 3D fast wavelet transform. From 3D coordinates of the face (x,y,z), we proceed to voxelization to get a 3D volume which will be decomposed by 3D fast wavelet transform and modeled after that with a wavelet network, then their associated weights are considered as vector features to represent each training face. For the recognition stage, an unknown identity face is projected on all the training WN to obtain a new vector features after every projection. A similarity score is computed between the old and the obtained vector features. To show the efficiency of our approach, experimental results were performed on all the FRGC v.2 benchmark.},
annote = {8th International Conference on Machine Vision (ICMV), Barcelona, SPAIN,
NOV 19-21, 2015},
author = {Said, Salwa and Jemai, Olfa and Zaied, Mourad and {Ben Amar}, Chokri},
booktitle = {EIGHTH INTERNATIONAL CONFERENCE ON MACHINE VISION (ICMV 2015)},
doi = {10.1117/12.2228368},
editor = {{Verikas, A and Radeva, P and Nikolaev}, D},
isbn = {978-1-5106-0116-1},
issn = {0277-786X},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
series = {Proceedings of SPIE},
title = {{3D Fast Wavelet Network Model-Assisted 3D Face Recognition}},
volume = {9875},
year = {2015}
}
@article{Bellil:2016:GWN:2877705.2877756,
abstract = {{\textcopyright} 2014, Springer Science+Business Media New York. The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 {\%} which represents a competitive result compared to the state of the art.},
address = {Hingham, MA, USA},
annote = {22/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
22/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Bellil, Wajdi and Brahim, Hajer and {Ben Amar}, Chokri},
doi = {10.1007/s11042-014-2294-6},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {3D face recognition,Gappy data,Occlusion detection,Wavelet neural network,Wavelets,acm,etapa1,gil,id125,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id125,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {365--380},
publisher = {Kluwer Academic Publishers},
title = {{Gappy wavelet neural network for 3D occluded faces: detection and recognition}},
url = {http://dx.doi.org/10.1007/s11042-014-2294-6 http://link.springer.com/10.1007/s11042-014-2294-6},
volume = {75},
year = {2016}
}
@article{Quan2015199,
abstract = {3-D face recognition research has received significant attention in the past two decades because of the rapid development in imaging technology and ever increasing security demand of modern society. One of its challenges is to cope with non-rigid deformation among faces, which is often caused by the changes of appearance and facial expression. Popular solutions to deal with this problem are to detect the deformable parts of the face and exclude them, or to represent a face in terms of sparse signature points, curves or patterns that are invariant to deformation. Such approaches, however, may lead to loss of information which is important for classification. In this paper, we propose a new geodesic-map representation with statistical shape modelling for handling the non-rigid deformation challenge in face recognition. The proposed representation captures all geometrical information from the entire 3-D face and provides a compact and expression-free map that preserves intrinsic geometrical information. As a result, the search for dense points correspondence in the face recognition task can be speeded up by using a simple image-based method instead of time-consuming, recursive closest distance search in 3-D space. An experimental investigation was conducted on 3-D face scans using publicly available databases and compared with the benchmark approaches. The experimental results demonstrate that the proposed scheme provides a highly competitive new solution for 3-D face recognition. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 0},
author = {Quan, W and Matuszewski, B J and Shark, L.-K.},
doi = {10.1007/978-3-319-27677-9_13},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {199--212},
title = {3-d face recognition using geodesic-map representation and statistical shape modelling},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955314982{\&}doi=10.1007{\%}2F978-3-319-27677-9{\_}13{\&}partnerID=40{\&}md5=e85737d15347f5ea197969c838869be9},
volume = {9493},
year = {2015}
}
@incollection{Ming:2015:RLS:2940229.2940265,
abstract = {In this paper, a robust 3D local SIFT feature is proposed for 3D face recognition. For preprocessing the original 3D face data, facial regional segmentation is first employed by fusing curvature characteristics and shape band mechanism. Then, we design a new local descriptor for the extracted regions, called 3D local Scale-Invariant Feature Transform (3D LSIFT). The key point detection based on 3D LSIFT can effectively reflect the geometric characteristic of 3D facial surface by encoding the gray and depth information captured by 3D face data. Then, 3D LSIFT descriptor extends to describe the discrimination on 3D faces. Experimental results based on the common international 3D face databases demonstrate the higher-qualified performance of our proposed algorithm with effectiveness, robustness, and universality.},
address = {New York, NY, USA},
annote = {26/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Ming, Yue and Jin, Yi},
booktitle = {Proceedings of the 8th International Conference on Intelligent Robotics and Applications - Volume 9246},
doi = {10.1007/978-3-319-22873-0_31},
isbn = {978-3-319-22872-3},
keywords = {3D Local Scale-Invariant Feature Transform,3D face recognition,Depth information,Facial region segmentation,acm,estela,etapa1,id278,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id278,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {352--359},
publisher = {Springer-Verlag New York, Inc.},
series = {ICIRA 2015},
title = {{Robust 3D Local SIFT Features for 3D Face Recognition}},
url = {http://dx.doi.org/10.1007/978-3-319-22873-0{\_}31 http://link.springer.com/10.1007/978-3-319-22873-0{\_}31},
year = {2015}
}
@inproceedings{ISI:000367310300024,
abstract = {Expression change is the major cause of local plastic deformation of the facial surface. The intra-class differences with large expression change somehow are larger than the inter-class differences as it's difficult to distinguish the same individual with facial expression change. In this paper, an expression-robust 3D face recognition method is proposed by learning expression deformation model. The expression of the individuals on the training set is modeled by principal component analysis, the main components are retained to construct the facial deformation model. For the test 3D face, the shape difference between the test and the neutral face in training set is used for reconstructing the expression change by the constructed deformation model. The reconstruction residual error is used for face recognition. The average recognition rate on GavabDB and self-built database reaches 85.1{\%} and 83{\%}, respectively, which shows strong robustness for expression changes.},
annote = {7th International Conference on Graphic and Image Processing (ICGIP),
Singapore, SINGAPORE, OCT 23-25, 2015},
author = {Guo, Zhe and Liu, Shu and Wang, Yi and Lei, Tao},
booktitle = {SEVENTH INTERNATIONAL CONFERENCE ON GRAPHIC AND IMAGE PROCESSING (ICGIP 2015)},
doi = {10.1117/12.2228002},
editor = {{Wang, Y and Jiang}, X},
isbn = {978-1-5106-0058-4},
issn = {0277-786X},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Wuhan Univ; Int Assoc Comp Sci {\&} Informat Technol},
series = {Proceedings of SPIE},
title = {{Learning Deformation Model for Expression-Robust 3D Face Recognition}},
volume = {9817},
year = {2015}
}
@inproceedings{7443802,
abstract = {Face recognition has broad excitement in the latest trend in image processing. Face recognition refers to identify a specific individual in digital image by analyzing and comparing patterns. It has numerous benefits which attract every sector but there are some issues such as more time consumption and lesser accuracy which degrade the user services. To solve this problem we proposed a highly accurate and fast method to reduce the execution time. The proposed method uses average half face approach because overall system's accuracy is better in it rather than using the original full face image. The proposed method can be used to recognize both 2D and 3D images. It mainly includes the average half face creation, feature detection, full face recognition through average half face using distance metrics and finally checking system's accuracy along with time consumption. The proposed method is based on eye, nose and mouth detection.},
author = {Arora, S and Chawla, S},
booktitle = {2015 Annual IEEE India Conference (INDICON)},
doi = {10.1109/INDICON.2015.7443802},
issn = {2325-9418},
keywords = {face recogniti,face recognition,feature extraction,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
month = {dec},
pages = {1--6},
title = {{An intensified approach to face recognition through average half face}},
year = {2015}
}
@inproceedings{Geetha20181882,
abstract = {Face Recognition is one of the biometric technique to vestige the given faces. We present a 3D face recognition method using Hadoop to recognize 3D faces under varying expressions, lighting and different poses to overcome the challenges of the 2D face recognition. In this paper, a threshold facial region of an image is detected and preprocessing is done based through the image excellence. If the selected face is frontal face with good lighting, extract the prerequisite features and do the necessary comparison steps to recognize the faces. In case, if the selected face is in bad lighting, then perform histogram equalization and normalization to increase the contrast. Different Poses and expressions are the very challenging zones which require surplus pre-processing to improve the performance of the face recognition system. Hence an enhanced normalization method called 3D Morphable Model are used as a pre- processing technique to create a frontal view from a non-frontal view and also merge images with different views in to a single frontal view. Next to diminish the number of features used for recognition process; we emulate the linear discriminant analysis method for further classification. Eventually, we used an open-source Hadoop Image Processing Interface (HIPI) to act as an interface for MapReduce technology for recognition. {\textcopyright} 2017 IEEE.},
annote = {From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0},
author = {Geetha, G and Safa, M and Fancy, C and Chittal, K},
booktitle = {2017 International Conference on Energy, Communication, Data Analytics and Soft Computing, ICECDS 2017},
doi = {10.1109/ICECDS.2017.8389776},
keywords = {biometrics (access control),face recognition,featu,revisao{\_}V1,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
pages = {1882--1885},
title = {{3D face recognition using Hadoop}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050073609{\&}doi=10.1109{\%}2FICECDS.2017.8389776{\&}partnerID=40{\&}md5=426f7e7f8b23f4019df744e279422d63},
year = {2018}
}
@inproceedings{7797090,
abstract = {3D face recognition holds great promise in achieving robustness to pose, expressions and occlusions. However, 3D face recognition algorithms are still far behind their 2D counterparts due to the lack of large-scale datasets. We present a model based algorithm for 3D face recognition and test its performance by combining two large public datasets of 3D faces. We propose a Fully Convolutional Deep Network (FCDN) to initialize our algorithm. Reliable seed points are then extracted from each 3D face by evolving level set curves with a single curvature dependent adaptive speed function. We then establish dense correspondence between the faces in the training set by matching the surface around the seed points on a template face to the ones on the target faces. A morphable model is then fitted to probe faces and face recognition is performed by matching the parameters of the probe and gallery faces. Our algorithm achieves state of the art landmark localization results. Face recognition results on the combined FRGCv2 and Bosphorus datasets show that our method is effective in recognizing query faces with real world variations in pose and expression, and with occlusion and missing data despite a huge gallery. Comparing results of individual and combined datasets show that the recognition accuracy drops when the size of the gallery increases.},
annote = {23/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
23/04/2018 Exclu{\'{i}}do (etapa 1)
04/05/2018 Revisado (etapa 1)},
author = {Gilani, S Z and Mian, A},
booktitle = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
doi = {10.1109/DICTA.2016.7797090},
keywords = {convolution,estela,etapa1,face recognition,feature extraction,id181,ieeexplore,im,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {estela,etapa1,id181,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
pages = {1--8},
title = {{Towards Large-Scale 3D Face Recognition}},
year = {2016}
}
@article{Gaonkar201615,
abstract = {3D face recognition has gain a paramount importance over 2D due to its potential to address the limitations of 2D face recognition against the variation in facial poses, angles, occlusions etc. Research in 3D face recognition has accelerated in recent years due to the development of low cost 3D Kinect camera sensor. This has leads to the development of few RGB-D database across the world. Here in this paper we introduce the base results of our 3D facial database (GU-RGBD database) comprising variation in pose (0°, 45°, 90°, −45°, −90°), expression (smile, eyes closed), occlusion (half face covered with paper) and illumination variation using Kinect. We present a proposed noise removal non-linear interpolation filter for the patches present in the depth images. The results were obtained on three face recognition algorithms and fusion at matching score level for recognition and verification rate. The obtained results indicated that the performance with our proposed filter shows improvement over pose with score level fusion using sum rule. {\textcopyright} Springer International Publishing AG 2017.},
annote = {cited By 0},
author = {Gaonkar, A A and Gad, M D and Vetrekar, N T and Tilve, V S and Gad, R S},
doi = {10.1007/978-3-319-68124-5_2},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {lerdepois,revisao{\_}V2,revisao{\_}scopus,tutui2},
mendeley-tags = {lerdepois,revisao{\_}V2,revisao{\_}scopus,tutui2},
pages = {15--26},
title = {{Experimental evaluation of 3D kinect face database}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057824711{\&}doi=10.1007{\%}2F978-3-319-68124-5{\_}2{\&}partnerID=40{\&}md5=3a104665aebdb39c053c8b83ce35c8fb},
volume = {10481 LNCS},
year = {2016}
}
@inproceedings{ISI:000374793400004,
abstract = {This paper proposes a 3D face recognition approach using sphere depth image, which is robust to pose variations in unconstrained environments. The input 3D face point clouds is first transformed into sphere depth images, and then represented as a 3DLBP image to enhance the distinctiveness of smooth and similar facial depth images. An improved SIFT algorithm is applied in the following matching process. The improved SIFT algorithm employs the learning to rank approach to select the keypoints with higher stability and repeatability instead of manually rule-based method used by the original SIFT algorithm. The proposed face recognition method is evaluated on CASIA 3D face database. And the experimental results show our approach has superior performance than many existing methods for 3D face recognition and handles pose variations quite well.},
annote = {10th Chinese Conference on Biometric Recognition (CCBR), Tianjin,
PEOPLES R CHINA, NOV 13-15, 2015},
author = {Wang, Hanchao and Mu, Zhichun and Zeng, Hui and Huang, Mingming},
booktitle = {BIOMETRIC RECOGNITION, CCBR 2015},
doi = {10.1007/978-3-319-25417-3_4},
editor = {{Yang, J and Yang, J and Sun, Z and Shan, S and Zheng, W and Feng}, J},
isbn = {978-3-319-25417-3; 978-3-319-25416-6},
issn = {0302-9743},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Chinese Assoc Artificial Intelligence; Springer; Civil Aviat Univ China; Tianjin Univ Sci {\&} Technol; CASIA, Inst Intelligent Recognit},
pages = {27--34},
series = {Lecture Notes in Computer Science},
title = {{3D Face Recognition Using Local Features Matching on Sphere Depth Representation}},
volume = {9428},
year = {2015}
}
@conference{Ahdid201873,
abstract = {In this paper, we present an automatic 3D face recognition system. This system is based on the representation of human faces surfaces as collections of Iso-Geodesic Curves (IGC) using 3D Fast Marching algorithm. To compare two facial surfaces, we compute a geodesic distance between a pair of facial curves using a Riemannian geometry. In the classifying step, we use: Neural Networks (NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this method and evaluate its performance, a simulation series of experiments were performed on 3D Shape REtrieval Contest 2008 database (SHREC2008). {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Ahdid, R and Taifi, K and Said, S and Fakir, M and Manaut, B},
booktitle = {Proceedings - 2017 14th International Conference on Computer Graphics, Imaging and Visualization, CGiV 2017},
doi = {10.1109/CGiV.2017.25},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {73--78},
title = {{Automatic face recognition system using iso-geodesic curves in riemanian manifold}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048323921{\&}doi=10.1109{\%}2FCGiV.2017.25{\&}partnerID=40{\&}md5=73b9e65d367cee00cdcb28e7b5ef55cb},
year = {2018}
}
@article{ISI:000412265100009,
abstract = {Pose variations are still challenging problems in 3D face recognition because large pose variations will cause self-occlusion and result in missing data. In this paper, a new method for pose-invariant 3D face recognition is proposed to handle significant pose variations. For pose estimation and registration, a coarse-to-fine strategy is proposed to detect landmarks under large yaw variations. At the coarse search step, candidate landmarks are detected using HK curvature analysis and subdivided according to a facial geometrical structure-based classification strategy. At the fine search step, candidate landmarks are identified and labeled by comparing with a Facial Landmark Model. By using the half face matching, we perform the matching step with respect to frontal scans and side scans. Experiments carried out on the Bosphorus and UND/FRGC v2.0 databases show that our method has high accuracy and robustness to pose variations. (C) 2017 Elsevier B.V. All rights reserved.},
author = {Liang, Yan and Zhang, Yun and Zeng, Xian-Xian},
doi = {10.1016/j.image.2017.05.004},
issn = {0923-5965},
journal = {SIGNAL PROCESSING-IMAGE COMMUNICATION},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {84--90},
title = {{Pose-invariant 3D face recognition using half face}},
volume = {57},
year = {2017}
}
@inproceedings{8578301,
abstract = {Deep networks trained on millions of facial images are believed to be closely approaching human-level performance in face recognition. However, open world face recognition still remains a challenge. Although, 3D face recognition has an inherent edge over its 2D counterpart, it has not benefited from the recent developments in deep learning due to the unavailability of large training as well as large test datasets. Recognition accuracies have already saturated on existing 3D face datasets due to their small gallery sizes. Unlike 2D photographs, 3D facial scans cannot be sourced from the web causing a bottleneck in the development of deep 3D face recognition networks and datasets. In this backdrop, we propose a method for generating a large corpus of labeled 3D face identities and their multiple instances for training and a protocol for merging the most challenging existing 3D datasets for testing. We also propose the first deep CNN model designed specifically for 3D face recognition and trained on 3.1 Million 3D facial scans of 100K identities. Our test dataset comprises 1,853 identities with a single 3D scan in the gallery and another 31K scans as probes, which is several orders of magnitude larger than existing ones. Without fine tuning on this dataset, our network already outperforms state of the art face recognition by over 10{\%}. We fine tune our network on the gallery set to perform end-to-end large scale 3D face recognition which further improves accuracy. Finally, we show the efficacy of our method for the open world face recognition problem.},
author = {{Zulqarnain Gilani}, S and Mian, A},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00203},
issn = {2575-7075},
keywords = {convolutional neural nets,face recognition,learnin,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
pages = {1896--1905},
title = {{Learning from Millions of 3D Scans for Large-Scale 3D Face Recognition}},
year = {2018}
}
@inproceedings{ISI:000390782003008,
abstract = {3D face recognition with partial occlusions is a highly challenging problem. In this paper, we propose a novel radial string representation and matching approach to recognize 3D facial scans in the presence of partial occlusions. Here we encode 3D facial surfaces into an indexed collection of radial strings emanating from the nosetips and Dynamic Programming (DP) is then used to measure the similarity between two radial strings. In order to address the recognition problems with partial occlusions, a partial matching mechanism is established in our approach that effectively eliminates those occluded parts and finds the most discriminative parts during the matching process. Experimental results on the Bosphorus database demonstrate that the proposed approach yields superior performance on partially occluded data.},
annote = {23rd IEEE International Conference on Image Processing (ICIP), Phoenix,
AZ, SEP 25-28, 2016},
author = {Yu, Xun and Gao, Yongsheng and Zhou, Jun},
booktitle = {2016 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)},
isbn = {978-1-4673-9961-6},
issn = {1522-4880},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Inst Elect {\&} Elect Engineers; Inst Elect {\&} Elect Engineers, Signal Proc Soc},
pages = {3016--3020},
series = {IEEE International Conference on Image Processing ICIP},
title = {{3D FACE RECOGNITION UNDER PARTIAL OCCLUSIONS USING RADIAL STRINGS}},
year = {2016}
}
@article{Siqueira2018,
abstract = {This work presents a multiple slicing model for 3D images of human face, using the Frontal, Sagittal and Transverse orthogonal planes. The definition of the segments depends on just one key point, the nose tip, which makes it simple and independent of the detection of several key points. For facial recognition, attributes based on adapted 2D spatial moments of Hu and 3D spatial Invariant Rotation Moments are extracted from each segment. Tests with the proposed model using the Bosphorus Database for neutral vs non-neutral ROC I experiment, applying Linear Discriminant Analysis as classifier and more than one sample for training, achieved 98.7{\%} of verification rate at 0.1{\%} of false acceptance rate. By using the Support Vector Machine as classifier the rank1 experiment recognition rates of 99{\%} and 95.4{\%} have been achieved for a neutral vs neutral and for a neutral vs non-neutral, respectively. These results approach the state-of-the-art using Bosphorus Database and even surpasses it when Anger and Disgust expressions are evaluated. In addition, we also evaluate the generalization of our method using the FRGC v2.0 database and achieve competitive results, making the technique promising, especially for its simplicity.},
author = {Siqueira, Robson S. and Alexandre, Gilderlane R. and Soares, Jose M. and The, George A.P.},
doi = {10.1109/LRA.2018.2854295},
file = {:home/artur/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siqueira et al. - 2018 - Triaxial Slicing for 3-D Face Recognition From Adapted Rotational Invariants Spatial Moments and Minimal Keypoi.pdf:pdf},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Computer vision for automation,recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,surveillance systems,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {oct},
number = {4},
pages = {3513--3520},
title = {{Triaxial slicing for 3-D face recognition from adapted rotational invariants spatial moments and minimal keypoints dependence}},
url = {https://ieeexplore.ieee.org/document/8408720/},
volume = {3},
year = {2018}
}
@article{Wei201766,
abstract = {In this paper, we propose a general 3D face recognition framework by combining the idea of surface harmonic mapping and deep learning. In particular, given a 3D face scan, we first run the pre-processing pipeline and detect three main facial landmarks (i.e., nose tip and two inner eye corners). Then, harmonic mapping is employed to map the 3D coordinates and differential geometry quantities (e.g., normal vectors, curvatures) of each 3D face scan to a 2D unit disc domain, generating a group of 2D harmonic shape images (HSI). The 2D rotation of the harmonic shape images are removed by using the three detected landmarks. All these pose normalized harmonic shape images are fed into a pre-trained deep convolutional neural network (DCNN) to generate their deep representations. Finally, sparse representation classifier with score-level fusion is used for face similarity measurement and the final decision. The advantage of our method is twofold: (i) it is a general framework and can be easily extended to other surface mapping and deep learning algorithms. (ii) it is registration-free and only needs three landmarks. The effectiveness of the proposed framework was demonstrated on the BU-3DFE database, and reporting a rank-one recognition rate of 89.38{\%} on the whole database. {\textcopyright} 2017, Springer International Publishing AG.},
annote = {cited By 0},
author = {Wei, X and Li, H and Gu, X D},
doi = {10.1007/978-3-319-69923-3_8},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {66--76},
title = {{Three Dimensional Face Recognition via Surface Harmonic Mapping and Deep Learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032656852{\&}doi=10.1007{\%}2F978-3-319-69923-3{\_}8{\&}partnerID=40{\&}md5=598d2aabb96d1b2d7f9963542a2fcddf},
volume = {10568 LNCS},
year = {2017}
}
@article{ISI:000408398200010,
abstract = {Recognition of faces typically occurs via holistic processing where individual features are combined to provide an overall facial representation. However, when faces are inverted, there is greater reliance on featural processing where faces are recognized based on their individual features. These findings are based on a substantial number of studies using 2-dimensional (2D) faces and it is unknown whether these results can be extended to 3-dimensional (3D) faces, which have more depth information that is absent in the typical 2D stimuli used in face recognition literature. The current study used the face inversion paradigm as a means to investigate how holistic and featural processing are differentially influenced by 2D and 3D faces. Twenty-five participants completed a delayed face-matching task consisting of upright and inverted faces that were presented as both 2D and 3D stereoscopic images. Recognition accuracy was significantly higher for 3D upright faces compared to 2D upright faces, providing support that the enriched visual information in 3D stereoscopic images facilitates holistic processing that is essential for the recognition of upright faces. Typical face inversion effects were also obtained, regardless of whether the faces were presented in 2D or 3D. Moreover, recognition performances for 2D inverted and 3D inverted faces did not differ. Taken together, these results demonstrated that 3D stereoscopic effects influence face recognition during holistic processing but not during featural processing. Our findings therefore provide a novel perspective that furthers our understanding of face recognition mechanisms, shedding light on how the integration of stereoscopic information in 3D faces influences face recognition processes. (c) 2017 Elsevier Ltd. All rights reserved.},
author = {Eng, Z H D and Yick, Y Y and Guo, Y and Xu, H and Reiner, M and Cham, T J and Chen, S H A},
doi = {10.1016/j.visres.2017.06.004},
issn = {0042-6989},
journal = {VISION RESEARCH},
keywords = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
pages = {78--85},
title = {{3D faces are recognized more accurately and faster than 2D faces, but with similar inversion effects}},
volume = {138},
year = {2017}
}
@article{ISI:000370290900001,
abstract = {Curvelet transform can describe the signal by multiple scales, and multiple directions. In order to improve the performance of 3D face recognition algorithm, we proposed an Anthropometric and Curvelet features fusion-based algorithm for 3D face recognition (Anthropometric Curvelet Fusion Face Recognition, ACFFR). First, the eyes, nose, and mouth feature regions are extracted by the Anthropometric characteristics and curvature features of the human face. Second, Curvelet energy features of the facial feature regions at different scales and different directions are extracted by Curvelet transform. At last, Euclidean distance is used as the similarity between template and objectives. To verify the performance, the proposed algorithm is compared with Anthroface3D and Curveletface3D on the Texas 3D FR database. The experimental results have shown that the proposed algorithm performs well, with equal error rate of 1.75{\%} and accuracy of 97.0{\%}. The algorithm we proposed in this paper has better robustness to expression and light changes than Anthroface3D and Curveletface3D.},
author = {Song, Dan and Luo, Jing and Zi, Chunyuan and Tian, Huixin},
doi = {10.1155/2016/6859364},
issn = {1687-725X},
journal = {JOURNAL OF SENSORS},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
title = {{3D Face Recognition Using Anthropometric and Curvelet Features Fusion}},
year = {2016}
}
@inproceedings{ISI:000380516600072,
abstract = {The classical curvatures of smooth surfaces (Gaussian, mean and principal curvatures) have been widely used in 3D face recognition (FR). However, facial surfaces resulting from 3D sensors are discrete meshes. In this paper, we present a general framework and define three principal curvatures on discrete surfaces for the purpose of 3D FR. These principal curvatures are derived from the construction of asymptotic cones associated to any Borel subset of the discrete surface. They describe the local geometry of the underlying mesh. First two of them correspond to the classical principal curvatures in the smooth case. We isolate the third principal curvature that carries out meaningful geometric shape information. The three principal curvatures in different Borel subsets scales give multi-scale local facial surface descriptors. We combine the proposed principal curvatures with the LNP-based facial descriptor and SRC for recognition. The identification and verification experiments demonstrate the practicability and accuracy of the third principal curvature and the fusion of multi-scale Borel subset descriptors on 3D face from FRGC v2.0.},
annote = {International Conference on Biometrics (ICB), Phuket, THAILAND, MAY
19-22, 2015},
author = {Tang, Yinhang and Sun, Xiang and Huang, Di and Morvan, Jean-Marie and Wang, Yunhong and Chen, Liming},
booktitle = {2015 INTERNATIONAL CONFERENCE ON BIOMETRICS (ICB)},
isbn = {978-1-4799-7824-3},
issn = {2376-4201},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {SIEW-SNGIEM AWARD; Kasetsart Univ; CHANWANICH; ST Elect; SAFRAN Morpho},
pages = {466--472},
series = {International Conference on Biometrics},
title = {{3D Face Recognition with Asymptotic Cones based Principal Curvatures}},
year = {2015}
}
@conference{Soltanpour20182811,
abstract = {This paper proposes a novel descriptor based on the local derivative pattern (LDP) for 3D face recognition. Compared to the local binary pattern (LBP), LDP can capture more detailed information by encoding directional pattern features. It is based on the local derivative variations that extract high-order local information. We propose a novel discriminative facial shape descriptor, local normal derivative pattern (LNDP) that extracts LDP from the surface normal. Using surface normal, the orientation of a surface at each point is determined as a first-order surface differential. Three normal component images are extracted by estimating three components of normal vectors in x, y, and z channels. Each normal component is divided into several patches and encoded using LDP. The final descriptor is created by concatenating histograms of the LNDP on each patch. Experimental results on two famous 3D face databases, FRGC v2.0 and Bosphorus illustrate the effectiveness of the proposed descriptor. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Soltanpour, S and Wu, Q M J},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2017.8296795},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {2811--2815},
title = {{High-order local normal derivative pattern (LNDP) for 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045292850{\&}doi=10.1109{\%}2FICIP.2017.8296795{\&}partnerID=40{\&}md5=12c33512c432220af4c4c49f5116433e},
volume = {2017-Septe},
year = {2018}
}
@article{Gilani:2017:DDA:3103259.3103504,
abstract = {We present a multilinear algorithm to automatically establish dense point-to-point correspondence over an arbitrarily large number of population specific 3D faces across identities, facial expressions and poses. The algorithm is initialized with a subset of anthropometric landmarks detected by our proposed Deep Landmark Identification Network which is trained on synthetic images. The landmarks are used to segment the 3D face into Voronoi regions by evolving geodesic level set curves. Exploiting the intrinsic features of these regions, we extract discriminative keypoints on the facial manifold to elastically match the regions across faces for establishing dense correspondence. Finally, we generate a Region based 3D Deformable Model which is fitted to unseen faces to transfer the correspondences. We evaluate our algorithm on the tasks of facial landmark detection and recognition using two benchmark datasets. Comparison with thirteen state-of-the-art techniques shows the efficacy of our algorithm.},
address = {New York, NY, USA},
annote = {18/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
18/05/2018 Exclu{\'{i}}do (etapa 1)},
author = {Gilani, Syed Zulqarnain and Mian, Ajmal and Eastwood, Peter},
doi = {10.1016/j.patcog.2017.04.013},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D face morphing,Deep learning,Dense 3D face correspondence,Face recognition,Keypoint detection,Landmark identification,Shape descriptor,acm,estela,etapa1,id488,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id488,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {sep},
number = {C},
pages = {238--250},
publisher = {Elsevier Science Inc.},
title = {{Deep, dense and accurate 3D face correspondence for generating population specific deformable models}},
url = {https://doi.org/10.1016/j.patcog.2017.04.013 http://linkinghub.elsevier.com/retrieve/pii/S0031320317301644},
volume = {69},
year = {2017}
}
@article{ISI:000463462600049,
abstract = {Extracting efficient features from the large volume of 3D facial data directly is extremely difficult in 3D face recognition (3D-FR) with the latest methods, which mostly require heavy computations and manual processing steps. This paper presents a computationally efficient 3D-FR system based on a novel Frenet frame-based feature that is derived from the 3D facial iso-geodesic curves. In terms of the evaluation of the proposed method, we conducted a number of experiments on the CASIA 3D face database, and a superior recognition performance has been achieved. The performance evaluation suggests that the pose invariance attribute of the features relieves the need of an expensive 3D face registration in the face preprocessing procedure, where we take less time to process conversely. Our experiments further demonstrate that the proposed method not only achieves competitive recognition performance when compared with some existing techniques for 3D-FR, but also is computationally efficient. (C) 2019 Elsevier Inc. All rights reserved.},
author = {Shi, Biao and Zang, Huaijuan and Zheng, Rongsheng and Zhan, Shu},
doi = {10.1016/j.jvcir.2019.02.002},
issn = {1047-3203},
journal = {JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
pages = {455--460},
title = {{An efficient 3D face recognition approach using Frenet feature of iso-geodesic curves}},
volume = {59},
year = {2019}
}
@article{Hajati2019936,
abstract = {We propose Polar Topographic Derivatives (PTD) to fuse the shape and texture information of a facial surface for 3D face recognition. Polar Average Absolute Deviations (PAADs) of the Gabor topography maps are extracted as features. High-order polar derivative patterns are obtained by encoding texture variations in a polar neighborhood. By using the and Bosphorus 3D face database, our method shows that it is robust to expression and pose variations comparing to existing state-of-the-art benchmark approaches. {\textcopyright} 2019, Springer Nature Switzerland AG.},
annote = {cited By 0},
author = {Hajati, F and Cheraghian, A and {Ameri Sianaki}, O and Zeinali, B and Gheisari, S},
doi = {10.1007/978-3-030-15035-8_92},
journal = {Advances in Intelligent Systems and Computing},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutui2},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui2},
pages = {936--945},
title = {{Polar Topographic Derivatives for 3D Face Recognition: Application to Internet of Things Security}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064875340{\&}doi=10.1007{\%}2F978-3-030-15035-8{\_}92{\&}partnerID=40{\&}md5=a1997efd234042ace42c04b05607ab05},
volume = {927},
year = {2019}
}
@inproceedings{8227850,
abstract = {Face recognition remains a challenge today as recognition performance is strongly affected by variability such as illumination, expressions and poses. In this work we apply Convolutional Neural Networks (CNNs) on the challenging task of both 2D and 3D face recognition. We constructed two CNN models, namely CNN-1 (two convolutional layers) and CNN-2 (one convolutional layer) for testing on 2D and 3D dataset. A comprehensive parametric study of two CNN models on face recognition is represented in which different combinations of activation function, learning rate and filter size are investigated. We find that CNN-2 has a better accuracy performance on both 2D and 3D face recognition. Our experimental results show that an accuracy of 85.15{\%} was accomplished using CNN-2 on depth images with FRGCv2.0 dataset (4950 images with 557 objectives). An accuracy of 95{\%} was achieved using CNN-2 on 2D raw image with the AT{\&}T dataset (400 images with 40 objectives). The results indicate that the proposed CNN model is capable to handle complex information from facial images in different dimensions. These results provide valuable insights into further application of CNN on 3D face recognition.},
annote = {26/04 em processo
26/04 exclus{\~{a}}o},
author = {Hu, H and Shah, S A A and Bennamoun, M and Molton, M},
booktitle = {TENCON 2017 - 2017 IEEE Region 10 Conference},
doi = {10.1109/TENCON.2017.8227850},
keywords = {etapa1,face recognition,feature extraction,feedforward ne,id314,ieeexplore,poly,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {etapa1,id314,ieeexplore,poly,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
pages = {132--133},
title = {{2D and 3D face recognition using convolutional neural network}},
year = {2017}
}
@conference{Chouchane2015,
abstract = {Face recognition in an uncontrolled condition such as illumination and expression variations is a challenging task. Local descriptor is one of the most efficient methods used to deal with these problems. In this paper, we present an automatic 3D face recognition approach based on three local descriptors, local phase quantization (LPQ), Three-Patch Local Binary Patterns (TPLBP) and Four-Patch Local Binary Patterns (TPLBP). Facial images are passing through one of the three descriptors and divided into sub-regions or rectangular blocks. The histogram of each sub-region is extracted and concatenated into a single feature vector. PCA (Principal Component Analysis) and EFM (Enhanced Fisher linear discriminant Model) are used to reduce the dimensionality of the resulting feature vectors. Finally, these vectors are sent to the classification step, when we use two methods; SVM (Support Victor Machine) and similarity measures. CASIA 3D face database is introduced to experimental evaluation. The experimental results illustrate a high recognition performance of the proposed approach. {\textcopyright} 2014 IEEE.},
annote = {cited By 4},
author = {Chouchane, A and Belahcene, M and Ouamane, A and Bourennane, S},
booktitle = {2014 4th International Conference on Image Processing Theory, Tools and Applications, IPTA 2014},
doi = {10.1109/IPTA.2014.7001925},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
title = {{3D face recognition based on histograms of local descriptors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921721830{\&}doi=10.1109{\%}2FIPTA.2014.7001925{\&}partnerID=40{\&}md5=4bbf52130cd2484d05cce4611c376687},
year = {2015}
}
@inproceedings{8314888,
abstract = {This manuscript introduces a novel 3D face authentication system inspired from the advantageous capacities of Gabor-Edge filters. The approach studies 3D face difficulties such as expression variety, different rotations and exposure to illuminations. The proposed systems starts by preprocessing the 3D face images to resolve acquisition problems. Then, a filtering process is performed by implanting our 3D Gabor-Edge technique extended based on the classic 3D Gabor masks. The next step is to achieve the classification of facial features from the edge saliency by the artificial Neural Network Classifier (NNC). The evaluation of the adopted system is achieved by exporting common datasets from GavabDB database. Experimental results are reported to prove the high accuracy rates of our method compared to the recent researches in the same biometric field.},
annote = {05/06/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
05/06/2018 Exclu{\'{i}}do (etapa 1)},
author = {Torkhani, G and Ladgham, A and Sakly, A},
booktitle = {2017 18th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA)},
doi = {10.1109/STA.2017.8314888},
keywords = {Authentication,Face,Face recognition,Feature extra,estela,etapa1,fatima,id511,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {estela,etapa1,fatima,id511,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
pages = {578--582},
title = {{3D Gabor-Edge filters applied to face depth images}},
year = {2017}
}
@conference{Belghini2015317,
abstract = {In this paper, we propose a fuzzy similarity based classification approach for 3D face recognition. In the feature extraction method, we exploit curve concept to represent the 3D facial data, two types of curves was considered: depth-level and depth-radial curves. As the dimension of the obtained features is high, the problem 'curse of dimensionality' appears. To solve this problem, the Random Projection (RP) method was used. The proposed classifier performs Fuzzification operation using triangular membership functions for input data and ordered weighted averaging operators to measure similarity. Experiment was conducted using vrml files from 3D Database considering only one training sample per person. The obtained results are very promising for depth-level and depth-radial curves, besides the recognition rates are higher than 98{\%}. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Belghini, N and Ezghari, S and Zahi, A},
booktitle = {Colloquium in Information Science and Technology, CIST},
doi = {10.1109/CIST.2014.7016639},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {January},
pages = {317--322},
title = {{3D face recognition using facial curves, sparse random projection and fuzzy similarity measure}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938075627{\&}doi=10.1109{\%}2FCIST.2014.7016639{\&}partnerID=40{\&}md5=bca04cb8b40640821dbbc277a0cf6e71},
volume = {2015-Janua},
year = {2015}
}
@article{Lei:2016:TWC:2875518.2875660,
abstract = {3D face recognition with the availability of only partial data (missing parts, occlusions and data corruptions) and single training sample is a highly challenging task. This paper presents an efficient 3D face recognition approach to address this challenge. We represent a facial scan with a set of local Keypoint-based Multiple Triangle Statistics (KMTS), which is robust to partial facial data, large facial expressions and pose variations. To address the single sample problem, we then propose a Two-Phase Weighted Collaborative Representation Classification (TPWCRC) framework. A class-based probability estimation is first calculated based on the extracted local descriptors as a prior knowledge. The resulting class-based probability estimation is then incorporated into the proposed classification framework as a locality constraint to further enhance its discriminating power. Experimental results on six challenging 3D facial datasets show that the proposed KMTS-TPWCRC framework achieves promising results for human face recognition with missing parts, occlusions, data corruptions, expressions and pose variations.},
address = {New York, NY, USA},
annote = {21/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
21/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Lei, Yinjie and Guo, Yulan and Hayat, Munawar and Bennamoun, Mohammed and Zhou, Xinzhi},
doi = {10.1016/j.patcog.2015.09.035},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D face recognition,3D representation,Partial facial data,Single sample problem,Sparse representation,acm,etapa1,gil,id111,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id111,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {apr},
number = {C},
pages = {218--237},
publisher = {Elsevier Science Inc.},
title = {{A Two-Phase Weighted Collaborative Representation for 3D partial face recognition with single sample}},
url = {http://dx.doi.org/10.1016/j.patcog.2015.09.035 http://linkinghub.elsevier.com/retrieve/pii/S0031320315003660},
volume = {52},
year = {2016}
}
@inproceedings{ISI:000426973200029,
abstract = {This paper presents a straight-forward yet efficient, and expression-robust 3D face recognition approach by exploring location sensitive sparse representation of deep normal patterns (DNP). In particular given raw 3D facial surfaces, we first run 3D face pre-processing pipeline, including nose tip detection, face region cropping, and pose normalization. The 3D coordinates of each normalized 3D facial surface are then projected into 2D plane to generate geometry images, from which three images of facial surface normal components are estimated. Each normal image is then fed into a pre-trained deep face net to generate deep representations of facial surface normals, i.e., deep normal patterns. Considering the importance of different facial locations, we propose a location sensitive sparse representation classifier (LS-SRC) for similarity measure among deep normal patterns associated with different 3D faces. Finally, simple score-level fusion of different normal components are used for the final decision. The proposed approach achieves significantly high performance, and reporting rank-one scores of 98.01{\%}, 97.60{\%}, and 96.13{\%} on the FRGC v2.0, Bosphorus, and BU-3DFE databases when only one sample per subject is used in the gallery. These experimental results reveals that the performance of 3D face recognition would be constantly improved with the aid of training deep models from massive 2D face images, which opens the door for future directions of 3D face recognition.},
annote = {IEEE International Joint Conference on Biometrics (IJCB), Denver, CO,
OCT 01-04, 2017},
author = {Li, Huibin and Sun, Jian and Chen, Liming},
booktitle = {2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB)},
isbn = {978-1-5386-1124-1},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
organization = {IEEE},
pages = {234--242},
title = {{Location-Sensitive Sparse Representation of Deep Normal Patterns for Expression-robust 3D Face Recognition}},
year = {2017}
}
@article{ISI:000351796000002,
abstract = {3D face recognition and emotion analysis play important roles in many fields of communication and edutainment An effective facial descriptor, with higher discriminating capability for face recognition and higher descriptiveness for facial emotion analysis, is a challenging issue. However, in the practical applications, the descriptiveness and discrimination are independent and contradictory to each other. 3D facial data provide a promising way to balance these two aspects. In this paper, a robust regional bounding spherical descriptor (RBSR) is proposed to facilitate 3D face recognition and emotion analysis. In our framework, we first segment a group of regions on each 3D facial point cloud by shape index and spherical bands on the human face. Then the corresponding facial areas are projected to regional bounding spheres to obtain our regional descriptor. Finally, a regional and global regression mapping (RGRM) technique is employed to the weighted regional descriptor for boosting the classification accuracy. Three largest available databases, FRGC v2, CASIA and BU-3DFE, are contributed to the performance comparison and the experimental results show a consistently better performance for 3D face recognition and emotion analysis. (C) 2015 Elsevier B.V. All rights reserved.},
author = {Ming, Yue},
doi = {10.1016/j.imavis.2014.12.003},
issn = {0262-8856},
journal = {IMAGE AND VISION COMPUTING},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {mar},
pages = {14--22},
title = {{Robust regional bounding spherical descriptor for 3D face recognition and emotion analysis}},
volume = {35},
year = {2015}
}
@article{Ratyal2015241,
abstract = {In this paper we present a novel pose and expression invariant approach for 3D face registration based on intrinsic coordinate system characterized by nose tip, horizontal nose plane and vertical symmetry plane of the face. It is observed that distance of nose tip from 3D scanner is reduced after pose correction which is presented as a quantifying heuristic for proposed registration scheme. In addition, motivated by the fact that a single classifier cannot be generally efficient against all face regions, a two tier ensemble classifier based 3D face recognition approach is presented which employs Principal Component Analysis (PCA) for feature extraction and Mahalanobis Cosine (MahCos) matching score for classification of facial regions with weighted Borda Count (WBC) based combination and a re-ranking stage. The performance of proposed approach is corroborated by extensive experiments performed on two databases: GavabDB and FRGC v2.0, confirming effectiveness of fusion strategies to improve performance. {\^{A}}{\textcopyright} 2015 Elsevier Ltd. All rights reserved.},
annote = {cited By 5
24/04/2018 Em processo de sele{\c{c}}{\~{a}}o (Etapa 1)
24/04/2018 Exclu{\'{i}}do (Etapa 1)},
author = {Ratyal, N I and Taj, I A and Bajwa, U I and Sajid, M},
doi = {10.1016/j.compeleceng.2015.06.007},
journal = {Computers and Electrical Engineering},
keywords = {acm,artur,etapa1,id183,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,robson,scopus,tutui1},
mendeley-tags = {acm,artur,etapa1,id183,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,robson,scopus,tutui1},
pages = {241--255},
title = {{3D face recognition based on pose and expression invariant alignment}},
volume = {46},
year = {2015}
}
@article{Peter201977,
abstract = {Face recognition is commonly used for biometric security purposes in video surveillance and user authentications. The nature of face exhibits non-linear shapes due to appearance deformations, and face variations presented by facial expressions. Recognizing faces reliably across changes in facial expression has proved to be a more difficult problem leading to low recognition rates in many face recognition experiments. This is mainly due to the tens degree-of-freedom in a non-linear space. Recently, non-linear PCA has been revived as it posed a significant advantage for data representation in high dimensionality space. In this paper, we experimented the use of non-linear kernel approach in 3D face recognition and the results of the recognition rates have shown that the kernel method outperformed the standard PCA. {\textcopyright} Springer Nature Singapore Pte Ltd. 2019.},
annote = {cited By 0},
author = {Peter, M and Minoi, J.-L. and Hipiny, I H M},
doi = {10.1007/978-981-13-2622-6_8},
journal = {Lecture Notes in Electrical Engineering},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {77--86},
title = {{3D face recognition using kernel-based PCA approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053242189{\&}doi=10.1007{\%}2F978-981-13-2622-6{\_}8{\&}partnerID=40{\&}md5=c4b90626b4453034107d227cbd63ef3d},
volume = {481},
year = {2019}
}
@inproceedings{ISI:000390782003007,
abstract = {We propose a 3D face modeling and recognition system using an RGB-D stream in the presence of large pose changes. In the previous work, all facial data points are registered with a reference to improve the accuracy of 3D face model from a low-resolution depth sequence. This registration often fails when applied to non-frontal faces. It causes inaccurate 3D face models and poor performance of matching. We address this problem by pre-aligning each input face ('frontalization') before the registration, which avoids registration failures. For each frame, our method estimates the 3D face pose, assesses the quality of data, segments the facial region, frontalizes it. and performs an accurate registration with the previous 3D model. The 3D 3D recognition system using accurate 3D models from our method outperforms other face recognition systems and shows 100{\%} rank 1 recognition accuracy on a dataset with 30 subjects.},
annote = {23rd IEEE International Conference on Image Processing (ICIP), Phoenix,
AZ, SEP 25-28, 2016},
author = {Kim, Donghyun and Choi, Jongmoo and Leksut, Jatuporn Toy and Medioni, Gerard},
booktitle = {2016 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)},
isbn = {978-1-4673-9961-6},
issn = {1522-4880},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Inst Elect {\&} Elect Engineers; Inst Elect {\&} Elect Engineers, Signal Proc Soc},
pages = {3011--3015},
series = {IEEE International Conference on Image Processing ICIP},
title = {{ACCUTE 3D FACE MODELING AND RECOGNITION FROM RGB-D STREAM IN THE PRESENCE OF LARGE POSE CNGES}},
year = {2016}
}
@inproceedings{Galbally:2016:BSI:2982636.2982657,
abstract = {Biometric systems typically suffer a significant loss of performance when the acquisition sensor is changed between enrolment and authentication. Such a problem, commonly known as sensor interoperability, poses a serious challenge to the accuracy of matching algorithms. The present work addresses for the first time the sensor interoperability issue in 3D face recognition systems, analysing the performance of two popular and well known techniques for 3D facial authentication. For this purpose, a new gender-balanced database comprising 3D data of 26 subjects has been acquired using two devices belonging to the new generation of low-cost 3D sensors. The results show the high sensor-dependency of the tested systems and the need to develop matching algorithms robust to the variation in the sensor resolution.},
address = {Portugal},
annote = {13/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
13/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Galbally, Javier and Satta, Riccardo},
booktitle = {Proceedings of the 5th International Conference on Pattern Recognition Applications and Methods},
doi = {10.5220/0005682501990204},
isbn = {978-989-758-173-1},
keywords = {3D Face Database.,3D Face Recognition,Interoperability,acm,etapa1,gil,id51,revisao{\_}V1,revisao{\_}scopus,tutui2},
mendeley-tags = {acm,etapa1,gil,id51,revisao{\_}V1,revisao{\_}scopus,tutui2},
pages = {199--204},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
series = {ICPRAM 2016},
title = {{Biometric Sensor Interoperability: A Case Study in 3D Face Recognition}},
url = {http://dx.doi.org/10.5220/0005682501990204},
year = {2016}
}
@conference{Echeagaray-Patrón2015,
abstract = {Face recognition is an important task in pattern recognition and computer vision. In this work a method for 3D face recognition in the presence of facial expression and poses variations is proposed. The method uses 3D shape data without color or texture information. A new matching algorithm based on conformal mapping of original facial surfaces onto a Riemannian manifold followed by comparison of conformal and isometric invariants computed in the manifold is suggested. Experimental results are presented using common 3D face databases that contain significant amount of expression and pose variations. {\textcopyright} 2015 SPIE.},
annote = {cited By 14},
author = {Echeagaray-Patr{\'{o}}n, B A and Kober, V},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2186695},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
title = {{3D face recognition based on matching of facial surfaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951325808{\&}doi=10.1117{\%}2F12.2186695{\&}partnerID=40{\&}md5=cb5a757e08c6a66683fc0706f09faf95},
volume = {9598},
year = {2015}
}
@inproceedings{ISI:000386931400187,
abstract = {3D partial face recognition under missing parts, occlusions and data corruptions is a major challenge for the practical application of the techniques of 3D face recognition. Moreover, one individual can only provide one sample for training in most practical scenarios, and thus the face recognition with single sample problem is another highly challenging task. We propose an efficient framework for 3D partial face recognition with single sample addressing both of the two problems. First, we represent a facial scan with a set of keypoint based local geometrical descriptors, which gains sufficient robustness to partial facial data along with expression/pose variations. Then, a two-step modified collaborative representation classification scheme is proposed to address the single sample recognition problem. A class-based probability estimation is given during the first classification step, and the obtained result is then incorporated into the modified collaborative representation classification as a locality constraint to improve its classification performance. Extensive experiments on the Bosphorus and FRGC v2.0 datasets demonstrate the efficiency of the proposed approach when addressing the problem of 3D partial face recognition with single sample.},
annote = {IEEE 11th Conference on Industrial Electronics and Applications (ICIEA),
Hefei, PEOPLES R CHINA, JUN 05-07, 2016},
author = {Lei, Yinjie and Feng, Siyu and Zhou, Xinzhi and Guo, Yulan},
booktitle = {PROCEEDINGS OF THE 2016 IEEE 11TH CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS (ICIEA)},
isbn = {978-1-4673-8644-9},
issn = {2156-2318},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {IEEE; IEEE Ind Elect Soc; IEEE Ind Elect Chapter; IEEE Singapore Sect; Anhui Univ},
pages = {994--999},
series = {IEEE Conference on Industrial Electronics and Applications},
title = {{An efficient 3D partial face recognition approach with single sample}},
year = {2016}
}
@article{Dutta2019175,
abstract = {In this paper, a 3D face recognition system has been developed based on the volumetric representation of 3D range image. The main approach to build this system is to calculate volume on some distinct region of 3D range face data. The system has mainly three steps. In the very first step, seven significant facial landmarks are identified on the face. Secondly, six distinct triangular regions A to F are created on the face using any three individual landmarks where nose tip is common to all regions. Further 3D volumes of all the respective triangular regions have been calculated based on plane fitting on the input range images. Finally, KNN and SVM classifiers are considered for classification. Initially, the classification and recognition are carried out on the different volumetric region, and a further combination of all the regions is considered. The proposed approach is tested on three useful challenging databases, namely Frav3D, Bosphorous, and GavabDB. {\textcopyright} Springer Nature Singapore Pte Ltd. 2019.},
annote = {cited By 1},
author = {Dutta, K and Bhattacharjee, D and Nasipuri, M and Poddar, A},
doi = {10.1007/978-981-13-3702-4_11},
journal = {Advances in Intelligent Systems and Computing},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {175--189},
title = {{3D face recognition based on volumetric representation of range image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061157145{\&}doi=10.1007{\%}2F978-981-13-3702-4{\_}11{\&}partnerID=40{\&}md5=2543d63ceec9074d39578ea3320cdfbd},
volume = {883},
year = {2019}
}
@article{ISI:000392292000002,
abstract = {3D face shape is essentially a non-rigid free-form surface, which will produce non-rigid deformation under expression variations. In terms of that problem, a promising solution named Coherent Point Drift (CPD) non-rigid registration for the non-rigid region is applied to eliminate the influence from the facial expression while guarantees 3D surface topology. In order to take full advantage of the extracted discriminative feature of the whole face under facial expression variations, the novel expression-robust 3D face recognition method using feature-level fusion and feature-region fusion is proposed. Furthermore, the Principal Component Analysis and Linear Discriminant Analysis in combination with Rotated Sparse Regression (PL-RSR) dimensionality reduction method is presented to promote the computational efficiency and provide a solution to the curse of dimensionality problem, which benefit the performance optimization. The experimental evaluation indicates that the proposed strategy has achieved the rank-1 recognition rate of 97.91 {\%} and 96.71 {\%} based on Face Recognition Grand Challenge (FRGC) v2.0 and Bosphorus respectively, which means the proposed approach outperforms state-of-the-art approach.},
author = {Deng, Xing and Da, Feipeng and Shao, Haijian},
doi = {10.1007/s11042-015-3012-8},
issn = {1380-7501},
journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {13--31},
title = {{Expression-robust 3D face recognition based on feature-level fusion and feature-region fusion}},
volume = {76},
year = {2017}
}
@inproceedings{ISI:000380429100020,
abstract = {With the increasing availability of low-cost 3D data acquisition devices, the use of 3D face data for the recognition of individuals is becoming more appealing and computationally feasible. This paper proposes a completely automatic algorithm for face registration and matching. The algorithm is based on the extraction of stable 3D facial features characterizing the face and the subsequent construction of a signature manifold. The facial features are extracted by performing a continuous-to-discrete scale-space analysis. Registration is driven from the matching of triplets of feature points and the registration error is computed as shape matching score. Conversely to most techniques in the literature, a major advantage of the proposed method is that no data pre-processing is required. Therefore all presented results have been obtained exclusively from the raw data available from the 3D acquisition device. The method has been tested on the Bosphorus 3D face database and the performances compared to the ICP baseline algorithm. Even in presence of noise in the data, the algorithm proved to be very robust and reported identification performances which are aligned to the current state of the art, but without requiring any pre-processing of the raw data.},
annote = {2015 3rd International Workshop on Biometrics and Forensics (IWBF),
Gjovik, NORWAY, MAR 03-04, 2015},
author = {Lagorio, A and Cadoni, M and Grosso, E and Tistarelli, M},
booktitle = {2015 INTERNATIONAL WORKSHOP ON BIOMETRICS AND FORENSICS (IWBF)},
isbn = {978-1-4799-8105-2},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {European Cooperat Sci {\&} Technol; IEEE; COST Act IC1106; Inst Engn {\&} Technol; European Assoc Signal Proc; European Assoc Biometr; HOGSKOLEN},
title = {{A 3D ALGORITHM FOR UNSUPERVISED FACE IDENTIFICATION}},
year = {2015}
}
@article{Zhao2018207,
abstract = {3D face similarity is a critical issue in computer vision, computer graphics and face recognition and so on. Since Fr{\'{e}}chet distance is an effective metric for measuring curve similarity, a novel 3D face similarity measure method based on Fr{\'{e}}chet distances of geodesics is proposed in this paper. In our method, the surface similarity between two 3D faces is measured by the similarity between two sets of 3D curves on them. Due to the intrinsic property of geodesics, we select geodesics as the comparison curves. Firstly, the geodesics on each 3D facial model emanating from the nose tip point are extracted in the same initial direction with equal angular increment. Secondly, the Fr{\'{e}}chet distances between the two sets of geodesics on the two compared facial models are computed. At last, the similarity between the two facial models is computed based on the Fr{\'{e}}chet distances of the geodesics obtained in the second step. We verify our method both theoretically and practically. In theory, we prove that the similarity of our method satisfies three properties: reflexivity, symmetry, and triangle inequality. And in practice, experiments are conducted on the open 3D face database GavaDB, Texas 3D Face Recognition database, and our 3D face database. After the comparison with iso-geodesic and Hausdorff distance method, the results illustrate that our method has good discrimination ability and can not only identify the facial models of the same person, but also distinguish the facial models of any two different persons. {\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
annote = {cited By 0},
author = {Zhao, J.-L. and Wu, Z.-K. and Pan, Z.-K. and Duan, F.-Q. and Li, J.-H. and Lv, Z.-H. and Wang, K and Chen, Y.-C.},
doi = {10.1007/s11390-018-1814-7},
journal = {Journal of Computer Science and Technology},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {1},
pages = {207--222},
title = {{3D Face Similarity Measure by Fr{\'{e}}chet Distances of Geodesics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041342736{\&}doi=10.1007{\%}2Fs11390-018-1814-7{\&}partnerID=40{\&}md5=8478bdecdc0eeeb6cb4dda3bb1ecda52},
volume = {33},
year = {2018}
}
@article{Sghaier:2018:NTF:3193702.3193706,
abstract = {This manuscript presents an improved system research that can detect and recognize the person in 3D space automatically and without the interaction of the people's faces. This system is based not only on a quantum computation and measurements to extract the vector features in the phase of characterization but also on learning algorithm (using SVM) to classify and recognize the person. This research presents an improved technique for automatic 3D face recognition using anthropometric proportions and measurement to detect and extract the area of interest which is unaffected by facial expression. This approach is able to treat incomplete and noisy images and reject the non-facial areas automatically. Moreover, it can deal with the presence of holes in the meshed and textured 3D image. It is also stable against small translation and rotation of the face. All the experimental tests have been done with two 3D face datasets FRAV 3D and GAVAB. Therefore, the test's results of the proposed approach are promising because they showed that it is competitive comparable to similar approaches in terms of accuracy, robustness, and flexibility. It achieves a high recognition performance rate of 95.35{\%} for faces with neutral and non-neutral expressions for the identification and 98.36{\%} for the authentification with GAVAB and 100{\%} with some gallery of FRAV 3D datasets.},
address = {Hershey, PA, USA},
annote = {02/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
02/05/2018 Exclu{\'{i}}do (etapa 1)

janeiro de 2018},
author = {Sghaier, Souhir and Farhat, Wajdi and Souani, Chokri},
doi = {10.4018/IJACI.2018010104},
issn = {1941-6237},
journal = {International Journal of Ambient Computing and Intelligence},
keywords = {3D Face,Anthropometric,Euclidean Distance,Eye Corners,Feature Extraction,Learning,Measurements,Nose Tip,acm,etapa1,gil,id431,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id431,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {60--77},
publisher = {IGI Global},
title = {{Novel Technique for 3D Face Recognition Using Anthropometric Methodology}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJACI.2018010104},
volume = {9},
year = {2018}
}
@article{ISI:000448833400016,
abstract = {In this study, a fully automatic pose and expression invariant 3D face alignment algorithm is proposed to handle frontal and profile face images which is based on a two pass course to fine alignment strategy. The first pass of the algorithm coarsely aligns the face images to an intrinsic coordinate system (ICS) through a single 3D rotation and the second pass aligns them at fine level using a minimum nose tip-scanner distance (MNSD) approach. For facial recognition, multi-view faces are synthesized to exploit real 3D information and test the efficacy of the proposed system. Due to optimal separating hyper plane (OSH), Support Vector Machine (SVM) is employed in multi-view face verification (FV) task. In addition, a multi stage unified classifier based face identification (FI) algorithm is employed which combines results from seven base classifiers, two parallel face recognition algorithms and an exponential rank combiner, all in a hierarchical manner. The performance figures of the proposed methodology are corroborated by extensive experiments performed on four benchmark datasets: GavabDB, Bosphorus, UMB-DB and FRGC v2.0. Results show mark improvement in alignment accuracy and recognition rates. Moreover, a computational complexity analysis has been carried out for the proposed algorithm which reveals its superiority in terms of computational efficiency as well.},
author = {Ratyal, Naeem and Taj, Imtiaz and Bajwa, Usama and Sajid, Muhammad},
doi = {10.3837/tiis.2018.10.016},
issn = {1976-7277},
journal = {KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {10},
pages = {4903--4929},
title = {{Pose and Expression Invariant Alignment based Multi-View 3D Face Recognition}},
volume = {12},
year = {2018}
}
@inproceedings{7387550,
abstract = {Face recognition research mainly focuses on traditional 2D color images, which is extremely susceptible to be affected by external factors such as various viewpoints and has limited recognition accuracy. In order to achieve improved recognition performance, as well as the 3D face holds more abundant information than 2D, we present a 3D human face recognition algorithm using the Microsoft's Kinect. The proposed approach integrates the depth data with the RGB data to generate 3D face raw data and then extracts feature points, identifies the target via a two-level cascade classifier. Also, we build a 3D-face database including 16 individuals captured exclusively using Kinect. The experimental results indicate that the introduced algorithm can not only achieve better recognition accuracy in comparison to existing 2D and 3D face recognition algorithms when the probe face is exactly in front of Kinect sensor, but also can increase 9.3{\%} of recognition accuracy compared to the PCA-3D algorithm when it is not confronting the camera.},
annote = {09/05/2018 Em processo de sele{\c{c}}{\~{a}}o (Etapa 1)
09/05/2018 Exclu{\'{i}}do (Etapa 1)},
author = {Zhou, Wei and Chen, Jian Xin and Wang, Lei},
booktitle = {Proceedings of 2015 IEEE International Conference on Computer and Communications, ICCC 2015},
doi = {10.1109/CompComm.2015.7387550},
isbn = {9781467381253},
keywords = {3D face recognition,Kinect,RGB-D images,XML file,artur,classifier,etapa1,id459,ieeexplore,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {artur,etapa1,id459,ieeexplore,revisao{\_}V1,revisao{\_}scopus,tutui1},
month = {oct},
pages = {109--114},
publisher = {IEEE},
title = {{A RGB-D face recognition approach without confronting the camera}},
url = {http://ieeexplore.ieee.org/document/7387550/},
year = {2016}
}
@article{ISI:000376708000002,
abstract = {In this paper, we investigate the contribution of dynamic evolution of 3D faces to identity recognition. To this end, we adopt a subspace representation of the flow of curvature-maps computed on 3D facial frames of a sequence, after normalizing their pose. Such representation allows us to embody the shape as well as its temporal evolution within the same subspace representation. Dictionary learning and sparse coding over the space of fixed-dimensional subspaces, called Grassmann manifold, have been used to perform face recognition. We have conducted extensive experiments on the BU-4DFE dataset. The obtained results of the proposed approach provide promising results. (C) 2016 Elsevier Ltd. All rights reserved.},
author = {Alashkar, Taleb and {Ben Amor}, Boulbaba and Daoudi, Mohamed and Berretti, Stefano},
doi = {10.1016/j.patcog.2016.03.013},
issn = {0031-3203},
journal = {PATTERN RECOGNITION},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {21--30},
title = {{A Grassmann framework for 4D facial shape analysis}},
volume = {57},
year = {2016}
}
@inproceedings{ISI:000400688200019,
abstract = {Landmarks are unique points that can be located on every face. Facial landmarks typically recognized by people are correlated with anthropomorphic points. Our purpose is to employ in 3D face recognition such landmarks that are easy to interpret. Face understanding is construed as identification of face characteristic points with automatic labeling of them. In this paper, we apply methods based on Self Organizing Maps to understand 3D faces.},
annote = {15th International Conference on Artificial Intelligence and Soft
Computing (ICAISC), Zakopane, POLAND, JUN 12-16, 2016},
author = {Starczewski, Janusz T and Pabiasz, Sebastian and Vladymyrska, Natalia and Marvuglia, Antonino and Napoli, Christian and Wozniak, Marcin},
booktitle = {ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING, (ICAISC 2016), PT II},
doi = {10.1007/978-3-319-39384-1_19},
editor = {{Rutkowski, L and Korytkowski, M and Scherer, R and Tadeusiewicz, R and Zadeh, LA and Zurada}, JM},
isbn = {978-3-319-39384-1},
issn = {0302-9743},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Polish Neural Network Soc; Univ Social Sci; Czestochowa Univ Technol, Inst Computat Intelligence},
pages = {210--217},
series = {Lecture Notes in Artificial Intelligence},
title = {{Self Organizing Maps for 3D Face Understanding}},
volume = {9693},
year = {2016}
}
@conference{Li2018234,
abstract = {This paper presents a straight-forward yet efficient, and expression-robust 3D face recognition approach by exploring location sensitive sparse representation of deep normal patterns (DNP). In particular, given raw 3D facial surfaces, we first run 3D face pre-processing pipeline, including nose tip detection, face region cropping, and pose normalization. The 3D coordinates of each normalized 3D facial surface are then projected into 2D plane to generate geometry images, from which three images of facial surface normal components are estimated. Each normal image is then fed into a pre-trained deep face net to generate deep representations of facial surface normals, i.e., deep normal patterns. Considering the importance of different facial locations, we propose a location sensitive sparse representation classifier (LS-SRC) for similarity measure among deep normal patterns associated with different 3D faces. Finally, simple score-level fusion of different normal components are used for the final decision. The proposed approach achieves significantly high performance, and reporting rank-one scores of 98.01{\%}, 97.60{\%}, and 96.13{\%} on the FRGC v2.0, Bosphorus, and BU-3DFE databases when only one sample per subject is used in the gallery. These experimental results reveals that the performance of 3D face recognition would be constantly improved with the aid of training deep models from massive 2D face images, which opens the door for future directions of 3D face recognition. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Li, H and Sun, J and Chen, L},
booktitle = {IEEE International Joint Conference on Biometrics, IJCB 2017},
doi = {10.1109/BTAS.2017.8272703},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {234--242},
title = {{Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046291057{\&}doi=10.1109{\%}2FBTAS.2017.8272703{\&}partnerID=40{\&}md5=e5c4065442f8bc899597efdc443ed01c},
volume = {2018-Janua},
year = {2018}
}
@article{Li:2018:EFR:3198485.3198687,
abstract = {This study proposes a 3D face recognition method using multiple subject-specific curves insensitive to intra-subject distortions caused by expression variations. Considering that most sharp variances in facial convex regions are closely related to the bone structure, the convex crest curves are first extracted as the most vital subject-specific facial curves based on the principal curvature extrema in convex local surfaces. Then, the central profile curve and the horizontal contour curve passing through the nose tip are detected by using the precise localization of the nose tip and symmetry plane. Based on their discriminative power and robustness to expression changes, the three types of curves are fused with appropriate weights at the feature-level and used for matching 3D faces with the iterative closest point algorithm. The combination of multiple expression-insensitive curves is complementary and provides sufficient and stable facial surface features for face recognition. In addition, for each convex crest curve, an expression-irrelevant factor is assigned as the adaptive weight to improve the face matching performance. The results of experiments using two public 3D databases, GavabDB and BU-3DFE, demonstrate the effectiveness of the proposed method, and its recognition rates on both databases reflect an encouraging performance.},
address = {Amsterdam, The Netherlands, The Netherlands},
annote = {29/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
29/04 Exclu{\'{i}}do (etapa 1)

Janeiro de 2018},
author = {Li, Ye and Wang, YingHui and Liu, Jing and Hao, Wen},
doi = {10.1016/j.neucom.2017.09.070},
issn = {0925-2312},
journal = {Neurocomput.},
keywords = {3D face recognition,Expression-insensitive,Feature-level,Fusion,Subject-specific curve,acm,etapa1,id395,import{\_}poly,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,id395,import{\_}poly,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {C},
pages = {1295--1307},
publisher = {Elsevier Science Publishers B. V.},
title = {{Expression-insensitive 3D Face Recognition by the Fusion of Multiple Subject-specific Curves}},
url = {https://doi.org/10.1016/j.neucom.2017.09.070},
volume = {275},
year = {2018}
}
@conference{Reji2018,
abstract = {This paper focuses on a region based methodology for expression in sensitive 3D face recognition process. Considering facial regions that are comparatively unchanging during expressions, results shows that using fifteen sub regions on the face can attain high 3D face recognition. We use a modified face recognition algorithm along with hierarchical contour based image registration for finding the similarity score. Our method operates in two modes: verification mode and confirmation mode. Crop 100 mm of frontal face region, apply preprocessing and automatically detect nose tip, translate the face image to origin and crop fifteen sub regions. The cropped sub regions are defined by cuboids which occupy more volumetric data, Nose Tip is the most projecting point of the face with the highest value along Z-axis so consider it as origin. The modified face recognition algorithm reduces the effects caused by facial expressions and artifacts. Finally a Hierarchical contour based image registration technique is applied which yields better results. The approach is applied on Bosphorus 3D datasets and achieved a verification rate of 95.3{\%} at 0.1{\%} false acceptance rate. In the identification scenario 99.3{\%} rank one recognition is achieved. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Reji, R and Sojanlal, P},
booktitle = {2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
doi = {10.1109/ICCIC.2017.8524581},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
title = {{Region Based 3D Face Recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057946157{\&}doi=10.1109{\%}2FICCIC.2017.8524581{\&}partnerID=40{\&}md5=92c092fa4e2838ab444fcc0356fcdb75},
year = {2018}
}
@article{ISI:000410465400003,
abstract = {In this paper, we introduce a novel, automatic method for 3D face recognition. A new feature called a spherical vector norms map of a 3D face is created using the normal vector of each point. This feature contains more detailed information than the original depth image in regions such as the eyes and nose. For certain flat areas of 3D face, such as the forehead and cheeks, this map could increase the distinguishability of different points. In addition, this feature is robust to facial expression due to an adjustment that is made in the mouth region. Then, the facial representations, which are based on Histograms of Oriented Gradients, are extracted from the spherical vector norms map and the original depth image. A new partitioning strategy is proposed to produce the histogram of eight patches of a given image, in which all of the pixels are binned based on the magnitude and direction of their gradients. In this study, SVNs map and depth image are represented compactly with two histograms of oriented gradients; this approach is completed by Linear Discriminant Analysis and a Nearest Neighbor classifier.},
author = {Wang, Xue-Qiao and Yuan, Jia-Zheng and Li, Qing},
doi = {10.6688/JISE.2017.33.5.3},
issn = {1016-2364},
journal = {JOURNAL OF INFORMATION SCIENCE AND ENGINEERING},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {5},
pages = {1141--1161},
title = {{3D Face Recognition Using Spherical Vector Norms Map}},
volume = {33},
year = {2017}
}
@inproceedings{ISI:000401510000148,
abstract = {Feature selection from facial regions is a well-known approach to increase the performance of 2D image-based face recognition systems. In case of 3D modality, the approach of region-based feature selection for face recognition is relatively new. In this context, this paper presents an approach to evaluate the discrimination power of different regions of a 3D facial surface for its potential use in face recognition systems. We propose the use of weighted average of unit normal vector on the facial surface as the feature for region-based face recognition from 3D point cloud data (PCD). The iterative closest point algorithm is employed for the registration of segmented regions of facial point clouds. A metric based on angular distance between normals is introduced to indicate the similarity between two surfaces of same facial region. Finally, the intra class correlation based discrimination score is formulated to find out the key facial regions such as the eyes, nose, and mouth that are significant while recognizing a person with facial surface PCD.},
annote = {9th International Conference on Electrical and Computer Engineering
(ICECE), Dhaka, BANGLADESH, DEC 20-22, 2016},
author = {Amin, Rafiul and Shams, A Farhan and Rahman, S M Mahbubur and Hatzinakos, Dimitrios},
booktitle = {2016 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE)},
isbn = {978-1-5090-2963-1},
keywords = {lerdepois,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {lerdepois,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
organization = {Bangladesh Univ Engn {\&} Technol, Dept Elect {\&} Elect Engn; Inst Elect {\&} Elect Engineers; Energypac; PARADISE Cables ltd; BTCL; Summit Communicat Ltd; Dhaka Power Distribut Co Ltd},
pages = {602--605},
series = {International Conference on Computer and Electrical Engineering ICCEE},
title = {{Evaluation of Discrimination Power of Facial Parts from 3D Point Cloud Data}},
year = {2016}
}
@article{Zhang20153357,
abstract = {Expression and pose variations are two major challenges for 3D face recognition. This paper presents a method to cope with these two challenges by fusing the matching results of adaptive multiple regions on the 3D face. First, one approach is proposed for pose correction of 3D face based on three landmark points: nose tip, nasion, and subnasale. Then multiple regions are adaptively chosen from the facial surface, which include nose, left and right eye-forehead regions, left and right cheeks, and mouth-chin region. Next, a least trimmed square Hausdorff distance method is applied for region matching. Moreover, to obtain a better overall performance, several score-level and rank-level fusion schemes are used to fuse the contribution of each region. The proposed approach is evaluated on the Bosphorus and the BU-3DFE databases, and yields good results. The study shows that the proposed algorithm is robust to expression and pose changes. {\textcopyright}, 2015, Binary Information Press. All right reserved.},
annote = {cited By 0},
author = {Zhang, C and Gu, Y and Wang, Y and Li, F and Zhan, Y and Pi, J and Qu, L},
doi = {10.12733/jcis14297},
journal = {Journal of Computational Information Systems},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {9},
pages = {3357--3369},
title = {{Adaptive multiple regions matching for 3D face recognition under expression and pose variations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938320850{\&}doi=10.12733{\%}2Fjcis14297{\&}partnerID=40{\&}md5=af76d7b96bb6eca2db8bc3e1babc780a},
volume = {11},
year = {2015}
}
@article{Emambakhsh2017,
abstract = {The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm. https://github.com/mehryaragha/NoseBiometrics},
author = {Emambakhsh, Mehryar and Evans, Adrian},
doi = {10.1109/TPAMI.2016.2565473},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Face recognition,Gabor wavelets,facial landmarking,feature selection,nose region,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,surface normals,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {may},
number = {5},
pages = {995--1007},
title = {{Nasal Patches and Curves for Expression-Robust 3D Face Recognition}},
url = {http://ieeexplore.ieee.org/document/7467565/},
volume = {39},
year = {2017}
}
@inproceedings{7988861,
abstract = {This paper presents the integration of a multiple people detection and identification system with a dynamic simultaneous localization and mapping system for an autonomous robotic platform. This integration allows the exploration and navigation of the robot considering people identification. The robotic platform consists of a Pioneer 3DX robot equipped with an RGBD camera, a Sick Lms200 sensor laser and a computer using the robot operating system (ROS). The idea is to integrate the people detection and identification system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. The people detection and identification system is performed in two steps. The first one is for detecting multiple people on scene and the other one is for an individual person identification. Both steps are implemented as ROS nodes that works integrated with the SLAM ROS node. The multiple people detection's node uses a manual feature extraction technique based on HOG (Histogram of Oriented Gradients) detectors, implemented using the PCL library (Point Cloud Library) in C ++. The person's identification node is based on a Deep Convolutional Neural Network (CNN) that are implemented using the MatLab MatConvNet library. This step receives the detected people centroid from the previous step and performs the classification of a specific person. After that, the desired person centroid is send to the SLAM node, that consider it during the mapping process. Tests were made objecting the evaluation of accurateness in the people's detection and identification process. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.},
author = {Angonese, A T and {Ferreira Rosa}, P F},
booktitle = {2017 International Conference on Military Technologies (ICMT)},
doi = {10.1109/MILTECHS.2017.7988861},
keywords = {mobile robots,neural nets,object,object detection,revisao{\_}V1,revisao{\_}etapa1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui2},
mendeley-tags = {revisao{\_}V1,revisao{\_}etapa1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui2},
pages = {779--786},
title = {{Multiple people detection and identification system integrated with a dynamic simultaneous localization and mapping system for an autonomous mobile robotic platform}},
year = {2017}
}
@inproceedings{ISI:000391534900063,
abstract = {In this paper, we present a new radial string representation and matching approach for 3D face recognition under expression variations and partial occlusions. The radial strings are an indexed collection of strings emanating from the nose tip of a face scan. The matching between two radial strings is conducted through a dynamic programming process, in which a partial matching mechanism is established to find those unoccluded substrings effectively. Moreover, the most discriminative and stable radial strings are selected optimally by the well-known AdaBoost algorithm to achieve a composite classifier for 3D face recognition under facial expression changes. Experimental results on the GavabDB and the Bosphorus databases show that the proposed approach achieves promising results for human face recognition with expressions and occlusions.},
annote = {International Conference on Digital Image Computing - Techniques and
Applications (DICTA), Gold Coast, AUSTRALIA, NOV 30-DEC 02, 2016},
author = {Yu, Xun and Gao, Yongsheng and Zhou, Jun},
booktitle = {2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA)},
editor = {{Liew, AWC and Lovell, B and Fookes, C and Zhou, J and Gao, Y and Blumenstein, M and Wang}, Z},
isbn = {978-1-5090-2896-2},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Australian Govt, Dept Defence, Defence Sci {\&} Technol Grp; IAPR; Canon Informat Syst Res Australia; IEEE; Griffith Univ; APRS},
pages = {436--441},
title = {{Boosting Radial Strings for 3D Face Recognition with Expressions and Occlusions}},
year = {2016}
}
@inproceedings{ISI:000444905600019,
abstract = {In this paper, we present an efficient method for 3D face recognition based on vector quantization of both geometrical and visual proprieties of the face. The method starts by describing each 3D face using a set of orderless features, and use then the Bag-of-Features paradigm to construct the face signature. We analyze the performance of three well-known classifiers: the Naive Bayes, the Multilayer perceptron and the Random forests. The results reported on the FRGCv2 dataset show the effectiveness of our approach and prove that the method is robust to facial expression.},
annote = {12th International Joint Conference on Computer Vision, Imaging and
Computer Graphics Theory and Applications (VISIGRAPP), Porto, PORTUGAL,
FEB 27-MAR 01, 2017},
author = {Hariri, Walid and Tabia, Hedi and Farah, Nadir and Declercq, David and Benouareth, Abdallah},
booktitle = {PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5},
doi = {10.5220/0006101701870193},
editor = {{Imai, F and Tremeau, A and Braz}, J},
isbn = {978-989-758-226-4},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Inst Syst {\&} Technologies Informat, Control {\&} Commun; ACM SIGGRAPH; AFIG; Eurographics},
pages = {187--193},
title = {{Geometrical and Visual Feature Quantization for 3D Face Recognition}},
year = {2017}
}
@inproceedings{8269662,
abstract = {Facial recognition has most significant real-life requests like investigation and access control. It is associated through the issue of appropriately verifying face pictures and transmit them person in a database. In a past years face study has been emerging active topic. Most of the face detector techniques could be classified into feature based methods and image based also. Feature based techniques adds low-level analysis, feature analysis, etc. Facial recognition is a system capable of verifying / identifying a human after 3D images. By evaluating selected facial unique features from the image and face dataset. Design from transformation method given vector dimensional illustration of individual face in a prepared set of images, Principle component analysis inclines to search a dimensional sub-space whose normal vector features correspond to the maximum variance direction in the real image space. The PCA algorithm evaluates the feature extraction, data, i.e. Eigen Values and vectors of the scatter matrix. In literature survey, Face recognition is a design recognition mission performed exactly on faces. It can be described as categorizing a facial either “known” or “unknown”, after comparing it with deposits known individuals. It is also necessary to need a system that has the capability of knowledge to recognize indefinite faces. Computational representations of facial recognition must statement various difficult issues. After existing work, we study the SIFT structures for the gratitude method. The novel technique is compared with well settled facial recognition methods, name component analysis and eigenvalues and vector. This algorithm is called PCA and ICA (Independent Component Analysis). In research work, we implement the novel approach to detect the face in minimum time and evaluate the better accuracy based on Back Propagation Neural Networks. We design the framework in face recognition using MATLAB 2013a simulation tool. Evaluate the performance parameters, i.e. the FAR (false acceptance rate), FRR (False rejection Rate) and Accuracy and compare the existing performance parameters i.e. accuracy.},
author = {Kaur, R and Sharma, D and Verma, A},
booktitle = {2017 4th International Conference on Signal Processing, Computing and Control (ISPCC)},
doi = {10.1109/ISPCC.2017.8269662},
keywords = {backpropagation,eigenvalues and eigenfunctions,fac,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
pages = {122--129},
title = {{An advance 2D face recognition by feature extraction (ICA) and optimize multilayer architecture}},
year = {2017}
}
@inproceedings{Xie:2016:IFR:3028842.3028853,
abstract = {Automatic face recognition techniques applied on particular group or mass database introduces error cases. Error prevention is crucial for the court. Reranking of recognition results based on anthropology analysis can significant improve the accuracy of automatic methods. Previous studies focused on manual facial comparison. This paper proposed a weighted facial similarity computing method based on morphological analysis of components characteristics. Search sequence of face recognition reranked according to similarity, while the interference terms can be removed. Within this research project, standardized photographs, surveillance videos, 3D face images, identity card photographs of 241 male subjects from China were acquired. Sequencing results were modified by modeling selected individual features from the DMV altas. The improved method raises the accuracy of face recognition through anthroposophic or morphologic theory.},
address = {New York, New York, USA},
author = {Xie, Lanchi and Xu, Lei and Zhang, Ning and Guo, Jingjing and Yan, Yuwen and Li, Zhihui and Li, Zhigang and Xu, Xiaojing},
booktitle = {Proceedings of the 2016 International Conference on Intelligent Information Processing - ICIIP '16},
doi = {10.1145/3028842.3028853},
isbn = {9781450347990},
keywords = {face recognition,reranking,revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,shape contexts,shape matching,similarity calculation,tutui2},
mendeley-tags = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,tutui2},
pages = {1--6},
publisher = {ACM Press},
series = {ICIIP '16},
title = {{Improved face recognition result reranking based on shape contexts}},
url = {http://doi.acm.org/10.1145/3028842.3028853 http://dl.acm.org/citation.cfm?doid=3028842.3028853},
year = {2017}
}
@article{ISI:000449193300001,
abstract = {3D face recognition is an important topic in the field of pattern recognition and computer graphic. We propose a novel approach for 3D face recognition using local conformal parameterization and iso-geodesic stripes. In our framework, the 3D facial surface is considered as a Riemannian 2-manifold. The surface is mapped into the 2D circle parameter domain using local conformal parameterization. In the parameter domain, the geometric features are extracted from the iso-geodesic stripes. Combining the relative position measure, Chain 2D Weighted Walkthroughs (C2DWW), the 3D face matching results can be obtained. The geometric features from iso-geodesic stripes in parameter domain are robust in terms of head poses, facial expressions, and some occlusions. In the experiments, our method achieves a high recognition accuracy of 3D facial data from the Texas3D and Bosphorus3D face database.},
author = {Lv, Chenlei and Zhao, Junli},
doi = {10.1155/2018/4707954},
issn = {1024-123X},
journal = {MATHEMATICAL PROBLEMS IN ENGINEERING},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
title = {{3D Face Recognition based on Local Conformal Parameterization and Iso-Geodesic Stripes Analysis}},
year = {2018}
}
@article{Deng20155509,
abstract = {In order to eliminate the impact of facial expressions and improve the efficiency of calculation, this paper proposes a novel expression-robust 3D face recognition algorithm using region-based feature fusion technique based on multiscale wavelet transformations. The discrete wavelet transformation is applied to extract frequency component features of geometric image based on the semi-rigid face region as well as the non-rigid face region in order to reduce the influence from the facial expression using the Coherent Point Drift non-rigid point set registration. The dimensionality reduction methods are utilized to promote the computational efficiency, and the experimental results show that our algorithm outperforms state-of-the-art methods based on FRGC v2.0. Copyright {\textcopyright} 2015 Binary Information Press.},
annote = {cited By 0},
author = {Deng, X and Da, F and Shao, H},
doi = {10.12733/jcis14953},
journal = {Journal of Computational Information Systems},
keywords = {fatima,lerdepois,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {fatima,lerdepois,revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {15},
pages = {5509--5517},
title = {{Expression-robust 3D face recognition using region-based multiscale wavelet feature fusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950271521{\&}doi=10.12733{\%}2Fjcis14953{\&}partnerID=40{\&}md5=da8d93edfc030808fb309b097e409e94},
volume = {11},
year = {2015}
}
@inproceedings{ISI:000390841700083,
abstract = {We propose a robust method for 3D face recognition using 3D to 2D modeling and facial curvatures detection. The 3D2D algorithm permits to transform 3D images into 3D triangular mesh, then the mesh model is deformed and fitted to the 2D space in order to obtain a 2D smoother mesh. Then, we apply Gabor wavelets to the deformed model in order to exploit surface curves in the detection of salient face features. The classification of the final Gabor facial model is performed using the support vector machines (SVM). To demonstrate the quality of our technique, we give some experiments using the 3D AJMAL faces database. The experimental results prove that the proposed method is able to give a good recognition quality and a high accuracy rate.},
annote = {2nd International Conference on Advanced Technologies for Signal and
Image Processing (ATSIP), Monastir, TUNISIA, MAR 21-23, 2016},
author = {Torkhani, Ghada and Ladgham, Anis and Mansouri, Mohamed Nejib and Sakly, Anis},
booktitle = {2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)},
isbn = {978-1-4673-8526-8},
keywords = {fatima,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {fatima,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {IEEE; IEEE Tunisia Sect; ATMS Lab; ATSI; IEEE Explore; EMB; ENIS Sch; Telecom Paris; Supelec; CESBIO; Telecom SudParis; ENIT; Univ Paris Sud; IEEE Signal Proc Soc Tunisia Chapter; ISAAM Inst; Minist Higher Educ Res; IEEE EMP Tunisia Chapter; Novartis Comp},
pages = {447--452},
title = {{Gabor-SVM Applied to 3D-2D Deformed Mesh Model}},
year = {2016}
}
@inproceedings{ISI:000364714000046,
abstract = {In this work, we take advantage of the superiority of Spectral Graph Theory in classification application and propose a novel deep learning framework for face analysis which is called Spectral Regression Discriminant Analysis Network (SRDANet). Our SRDANet model shares the same basic architecture of Convolutional Neural Network (CNN), which comprises three basic components: convolutional filter layer, nonlinear processing layer and feature pooling layer. While it is different from traditional deep learning network that in our convolutional layer, we extract the leading eigenvectors from patches in facial image which are used as filter kernels instead of randomly initializing kernels and update them by stochastic gradient descent (SGD). And the output of all cascaded convolutional filter layers is used as the input of nonlinear processing layer. In the following nonlinear processing layer, we use hashing method for nonlinear processing. In feature pooling layer, the block-based histograms are employed to pooling output features instead of max-pooling technique. At last, the output of feature pooling layer is considered as one final feature output of our model. Different from the previous single-task research for face analysis, our proposed approach demonstrates an excellent performance in face recognition and expression recognition with 2D/3D facial images simultaneously. Extensive experiments conducted on many different face analysis databases demonstrate the efficiency of our proposed SRDANet model. Databases such as Extended Yale B, PIE, ORL are used for 2D face recognition, FRGC v2 is used for 3D face recognition and BU-3DFE is used for 3D expression recognition.},
annote = {8th International Conference on Intelligent Robotics and Applications
(ICIRA), Portsmouth, ENGLAND, AUG 24-27, 2015},
author = {Tian, Lei and Fan, Chunxiao and Ming, Yue and Shi, Jiakun},
booktitle = {INTELLIGENT ROBOTICS AND APPLICATIONS, ICIRA 2015, PT I},
doi = {10.1007/978-3-319-22879-2_46},
editor = {{Liu, H and Kubota, N and Zhu, X and Dillmann, R and Zhou}, D},
isbn = {978-3-319-22879-2; 978-3-319-22878-5},
issn = {0302-9743},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {499--510},
series = {Lecture Notes in Artificial Intelligence},
title = {{SRDANet: An Efficient Deep Learning Algorithm for Face Analysis}},
volume = {9244},
year = {2015}
}
@article{ISI:000446151100037,
abstract = {Most human expression variations cause a non-rigid deformation of face scans, which is a challenge today. In this article, we present a novel framework for 3D face recognition that uses a geometry and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. This algorithm consists of four major components. First, the 3D face model is presented at different scales. Second, isometric-invariant features on each scale are extracted. Third, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Fourth, the feature vectors on each scale are concatenated with their corresponding geometric information. We conducted a number of experiments using two well-known and challenging datasets, namely, the GavabDB and Bosphorus datasets, and superior recognition performance has been achieved. The new system displays an overall rank-1 identification rate of 98.9{\%} for all faces with neutral and non-neutral expressions on the GavabDB database. (C) 2017 Elsevier Ltd. All rights reserved.},
author = {Abbad, Abdelghafour and Abbad, Khalid and Tairi, Hamid},
doi = {10.1016/j.compeleceng.2017.08.017},
issn = {0045-7906},
journal = {COMPUTERS {\&} ELECTRICAL ENGINEERING},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {525--537},
title = {{3D face recognition: Multi-scale strategy based on geometric and local descriptors}},
volume = {70},
year = {2018}
}
@article{Deng20171305,
abstract = {A novel adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition is proposed in this paper. Firstly, the novel facial coarse-to-fine landmarks localization method based on Active Shape Model and Gabor wavelets transformation is proposed to exactly and automatically locate facial landmarks in range image. Secondly, the multi-scale fusion of the pyramid local binary patterns (F-PLBP) based on the irregular segmentation associated with the located landmarks is proposed to extract the discriminative feature. Thirdly, a sparse representation-based classifier based on the adaptive feature selection (A-SRC) using the distribution of the reconstruction residual is presented to select the expression-robust feature and identify the faces. Finally, the experimental evaluation based on FRGC v2.0 indicates that the adaptive feature selection method using F-PLBP combined with the A-SRC can obtain the high recognition accuracy by performing the higher discriminative power to overcome the influence from the facial expression variations. {\textcopyright} 2017, Springer-Verlag London.},
annote = {cited By 0
01/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
01/05/2018 Exclu{\'{i}}do (etapa 1)},
author = {Deng, X and Da, F and Shao, H},
doi = {10.1007/s11760-017-1087-6},
journal = {Signal, Image and Video Processing},
keywords = {estela,etapa1,id422,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
mendeley-tags = {estela,etapa1,id422,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
number = {7},
pages = {1305--1312},
title = {{Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017095710{\&}doi=10.1007{\%}2Fs11760-017-1087-6{\&}partnerID=40{\&}md5=fc06247cc3ca7870221563a085266269},
volume = {11},
year = {2017}
}
@inproceedings{8075548,
abstract = {Developing multimedia embedded applications continues to flourish. In fact, a biometric facial recognition system can be used not only on PCs abut also in embedded systems, it is a potential enhancer to meet security and surveillance needs. The analysis of facial recognition consists offoursteps: face analysis, face expressions' recognition, missing data completion and full face recognition. This paper proposes a hardware architecture based on an adaptation approach foran algorithm which has proven good face detection and recognition in 3D space. The proposed application was tested using a co design technique based on a mixed Hardware Software architecture: the FPGA platform.},
annote = {24/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Frikha, Tarek and Chaabane, Faten and Said, Boukhchim and Drira, Hassen and Abid, Mohamed and {Ben Amar}, Chokri and Lille, Lifl},
booktitle = {2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)},
doi = {10.1109/ATSIP.2017.8075548},
isbn = {978-1-5386-0551-6},
keywords = {biometrics (access control),embedded systems,etapa1,face,id341,ieeexplore,izaias,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
mendeley-tags = {etapa1,id341,ieeexplore,izaias,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
month = {may},
pages = {1--5},
publisher = {IEEE},
title = {{Embedded approach for a Riemannian-based framework of analyzing 3D faces}},
url = {http://ieeexplore.ieee.org/document/8075548/},
year = {2017}
}
@inproceedings{ISI:000371977803154,
abstract = {A 3D face recognition method using region-based extended local binary pattern (eLBP) is proposed. First, the depth image converted from the preprocessed 3D pointclouds is normalized. Then, different regions according to their distortions under facial expressions are extracted by binary masks and represented by the uniform pattern of extended LBP. Finally, sparse representation classifier (SRC) is adopted for classification on the single region. Feature-level and score-level fusion with weight-sparse representation classifier (W-SRC) are also tested and compared, and the latter has better performance. The experiments on FRGC v2.0 database demonstrate that the proposed method is robust and efficient.},
annote = {IEEE International Conference on Image Processing (ICIP), Quebec City,
CANADA, SEP 27-30, 2015},
author = {Lv, Shiwen and Da, Feipeng and Deng, Xing},
booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)},
isbn = {978-1-4799-8339-1},
issn = {1522-4880},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Inst Elect {\&} Elect Engineers; IEEE Signal Proc Soc},
pages = {3635--3639},
series = {IEEE International Conference on Image Processing ICIP},
title = {{A 3D Face Recognition Method Using Region-Based Extended Local Binary Pattern}},
year = {2015}
}
@article{ISI:000354988900026,
abstract = {Expression, occlusion, and pose variations are three main challenges for 3D face recognition. A novel method is presented to address 3D face recognition using scale-invariant feature transform (SIFT) features on 3D meshes. After preprocessing, shape index extrema on the 3D facial surface are selected as keypoints in the difference scale space and the unstable keypoints are removed after two screening steps. Then, a local coordinate system for each keypoint is established by principal component analysis (PCA). Next, two local geometric features are extracted around each keypoint through the local coordinate system. Additionally, the features are augmented by the symmetrization according to the approximate left-right symmetry in human face. The proposed method is evaluated on the Bosphorus, BU-3DFE, and Gavab databases, respectively. Good results are achieved on these three datasets. As a result, the proposed method proves robust to facial expression variations, partial external occlusions and large pose changes. {\textcopyright} 2015, Central South University Press and Springer-Verlag Berlin Heidelberg.},
annote = {From Duplicate 1 (Face recognition using SIFT features under 3D meshes - Zhang, C; Gu, Y.-Z.; Hu, K.-L.; Wang, Y.-G.)

cited By 5

From Duplicate 3 (Face recognition using SIFT features under 3D meshes - Zhang, C; Gu, Y.-Z.; Hu, K.-L.; Wang, Y.-G.; Cheng, Zhang; Yu-zhang, Gu; Ke-li, Hu; Ying-guan, Wang)

From Duplicate 2 (Face recognition using SIFT features under 3D meshes - Zhang, C; Gu, Y.-Z.; Hu, K.-L.; Wang, Y.-G.)

cited By 5},
author = {Zhang, C and Gu, Y.-Z. and Hu, K.-L. and Wang, Y.-G. and Cheng, Zhang and Yu-zhang, Gu and Ke-li, Hu and Ying-guan, Wang and Zhang, C and Gu, Y.-Z. and Hu, K.-L. and Wang, Y.-G.},
doi = {10.1007/s11771-015-2700-x},
issn = {2095-2899},
journal = {JOURNAL OF CENTRAL SOUTH UNIVERSITY},
keywords = {revisao{\_}V1,revisao{\_}V2,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}V2,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {5},
pages = {1817--1825},
title = {{Face recognition using SIFT features under 3D meshes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930008100{\&}doi=10.1007{\%}2Fs11771-015-2700-x{\&}partnerID=40{\&}md5=569ac008f1ef201b7fcbffd9e0faa163},
volume = {22},
year = {2015}
}
