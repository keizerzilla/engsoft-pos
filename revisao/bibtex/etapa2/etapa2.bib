@inproceedings{8075548,
abstract = {Developing multimedia embedded applications continues to flourish. In fact, a biometric facial recognition system can be used not only on PCs abut also in embedded systems, it is a potential enhancer to meet security and surveillance needs. The analysis of facial recognition consists offoursteps: face analysis, face expressions' recognition, missing data completion and full face recognition. This paper proposes a hardware architecture based on an adaptation approach foran algorithm which has proven good face detection and recognition in 3D space. The proposed application was tested using a co design technique based on a mixed Hardware Software architecture: the FPGA platform.},
annote = {24/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Frikha, Tarek and Chaabane, Faten and Said, Boukhchim and Drira, Hassen and Abid, Mohamed and {Ben Amar}, Chokri and Lille, Lifl},
booktitle = {2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)},
doi = {10.1109/ATSIP.2017.8075548},
file = {:home/tutu/artigos{\_}revisao/08075548.pdf:pdf},
isbn = {978-1-5386-0551-6},
keywords = {biometrics (access control),embedded systems,etapa1,face,id341,ieeexplore,izaias,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
mendeley-tags = {etapa1,id341,ieeexplore,izaias,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
month = {may},
pages = {1--5},
publisher = {IEEE},
title = {{Embedded approach for a Riemannian-based framework of analyzing 3D faces}},
url = {http://ieeexplore.ieee.org/document/8075548/},
year = {2017}
}
@article{Zhang20153357,
abstract = {Expression and pose variations are two major challenges for 3D face recognition. This paper presents a method to cope with these two challenges by fusing the matching results of adaptive multiple regions on the 3D face. First, one approach is proposed for pose correction of 3D face based on three landmark points: nose tip, nasion, and subnasale. Then multiple regions are adaptively chosen from the facial surface, which include nose, left and right eye-forehead regions, left and right cheeks, and mouth-chin region. Next, a least trimmed square Hausdorff distance method is applied for region matching. Moreover, to obtain a better overall performance, several score-level and rank-level fusion schemes are used to fuse the contribution of each region. The proposed approach is evaluated on the Bosphorus and the BU-3DFE databases, and yields good results. The study shows that the proposed algorithm is robust to expression and pose changes. {\textcopyright}, 2015, Binary Information Press. All right reserved.},
annote = {cited By 0},
author = {Zhang, C and Gu, Y and Wang, Y and Li, F and Zhan, Y and Pi, J and Qu, L},
doi = {10.12733/jcis14297},
journal = {Journal of Computational Information Systems},
keywords = {revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {9},
pages = {3357--3369},
title = {{Adaptive multiple regions matching for 3D face recognition under expression and pose variations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938320850{\&}doi=10.12733{\%}2Fjcis14297{\&}partnerID=40{\&}md5=af76d7b96bb6eca2db8bc3e1babc780a},
volume = {11},
year = {2015}
}
@article{ISI:000392292000002,
abstract = {3D face shape is essentially a non-rigid free-form surface, which will produce non-rigid deformation under expression variations. In terms of that problem, a promising solution named Coherent Point Drift (CPD) non-rigid registration for the non-rigid region is applied to eliminate the influence from the facial expression while guarantees 3D surface topology. In order to take full advantage of the extracted discriminative feature of the whole face under facial expression variations, the novel expression-robust 3D face recognition method using feature-level fusion and feature-region fusion is proposed. Furthermore, the Principal Component Analysis and Linear Discriminant Analysis in combination with Rotated Sparse Regression (PL-RSR) dimensionality reduction method is presented to promote the computational efficiency and provide a solution to the curse of dimensionality problem, which benefit the p erformance optimization. The experimental evaluation indicates that the proposed strategy has achieved the rank-1 recognition rate of 97.91 {\%} and 96.71 {\%} based on Face Recognition Grand Challenge (FRGC) v2.0 and Bosphorus respectively, which means the proposed approach outperforms state-of-the-art approach.},
author = {Deng, Xing and Da, Feipeng and Shao, Haijian},
doi = {10.1007/s11042-015-3012-8},
file = {:home/tutu/artigos{\_}revisao/Deng2017{\_}Article{\_}Expression-robust3DFaceRecogni.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {3D face recognition,Dimensionality reduction,Feature-level fusion,Feature-region fusion,Non-rigid point set registration,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {13--31},
title = {{Expression-robust 3D face recognition based on feature-level fusion and feature-region fusion}},
volume = {76},
year = {2017}
}
@article{Belghini2015317,
abstract = {{\textcopyright} 2014 IEEE. In this paper, we propose a fuzzy similarity based classification approach for 3D face recognition. In the feature extraction method, we exploit curve concept to represent the 3D facial data, two types of curves was considered: depth-level and depth-radial curves. As the dimension of the obtained features is high, the problem 'curse of dimensionality' appears. To solve this problem, the Random Projection (RP) method was used. The proposed classifier performs Fuzzification operation using triangular membership functions for input data and ordered weighted averaging operators to measure similarity. Experiment was conducted using vrml files from 3D Database considering only one training sample per person. The obtained results are very promising for depth-level and depth-radial curves, besides the recognition rates are higher than 98{\%}.},
annote = {From Duplicate 1 (3D face recognition using facial curves, sparse random projection and fuzzy similarity measure - Belghini, N; Ezghari, S; Zahi, A)

cited By 1},
author = {Belghini, Naouar and Ezghari, Soufiane and Zahi, Azeddine},
doi = {10.1109/CIST.2014.7016639},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belghini, Ezghari, Zahi - 2015 - 3D face recognition using facial curves, sparse random projection and fuzzy similarity measure.pdf:pdf},
isbn = {9781479959792},
issn = {23271884},
journal = {Colloquium in Information Science and Technology, CIST},
keywords = {3D face recognition,OWA operator,facial curves,fuzzy logic,revisao{\_}V1,revisao{\_}scopus,similarity measure,sparse random projection,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {January},
pages = {317--322},
title = {{3D face recognition using facial curves, sparse random projection and fuzzy similarity measure}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938075627{\&}doi=10.1109{\%}2FCIST.2014.7016639{\&}partnerID=40{\&}md5=bca04cb8b40640821dbbc277a0cf6e71},
volume = {2015-Janua},
year = {2015}
}
@inproceedings{ISI:000374793400004,
abstract = {This paper proposes a 3D face recognition approach using sphere depth
image, which is robust to pose variations in unconstrained environments.
The input 3D face point clouds is first transformed into sphere depth
images, and then represented as a 3DLBP image to enhance the
distinctiveness of smooth and similar facial depth images. An improved
SIFT algorithm is applied in the following matching process. The
improved SIFT algorithm employs the learning to rank approach to select
the keypoints with higher stability and repeatability instead of
manually rule-based method used by the original SIFT algorithm. The
proposed face recognition method is evaluated on CASIA 3D face database.
And the experimental results show our approach has superior performance
than many existing methods for 3D face recognition and handles pose
variations quite well.},
annote = {10th Chinese Conference on Biometric Recognition (CCBR), Tianjin,
PEOPLES R CHINA, NOV 13-15, 2015},
author = {Wang, Hanchao and Mu, Zhichun and Zeng, Hui and Huang, Mingming},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-25417-3_4},
editor = {{Yang, J and Yang, J and Sun, Z and Shan, S and Zheng, W and Feng}, J},
file = {:home/tutu/artigos{\_}revisao/1aea7e6aea20a283b83accdd43ef6537-wang2015.pdf:pdf},
isbn = {9783319254166},
issn = {16113349},
keywords = {3D face recognition,Learning to rank,Local binary patterns,Sphere depth image,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Chinese Assoc Artificial Intelligence; Springer; Civil Aviat Univ China; Tianjin Univ Sci {\&} Technol; CASIA, Inst Intelligent Recognit},
pages = {27--34},
series = {Lecture Notes in Computer Science},
title = {{3D face recognition using local features matching on sphere depth representation}},
volume = {9428},
year = {2015}
}
@article{ISI:000376708000002,
abstract = {In this paper, we investigate the contribution of dynamic evolution of 3D faces to identity recognition. To this end, we adopt a subspace representation of the flow of curvature-maps computed on 3D facial frames of a sequence, after normalizing their pose. Such representation allows us to embody the shape as well as its temporal evolution within the same subspace representation. Dictionary learning and sparse coding over the space of fixed-dimensional subspaces, called Grassmann manifold, have been used to perform face recognition. We have conducted extensive experiments on the BU-4DFE dataset. The obtained results of the proposed approach provide promising results.},
author = {Alashkar, Taleb and {Ben Amor}, Boulbaba and Daoudi, Mohamed and Berretti, Stefano},
doi = {10.1016/j.patcog.2016.03.013},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alashkar et al. - 2016 - A Grassmann framework for 4D facial shape analysis.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {4D face recognition,Curvature-maps,Dictionary learning,Grassmann manifold,Sparse coding,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutux10},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutux10},
pages = {21--30},
title = {{A Grassmann framework for 4D facial shape analysis}},
volume = {57},
year = {2016}
}
@inproceedings{ISI:000391534900063,
abstract = {{\textcopyright} 2016 IEEE. In this paper, we present a new radial string representation and matching approach for 3D face recognition under expression variations and partial occlusions. The radial strings are an indexed collection of strings emanating from the nose tip of a face scan. The matching between two radial strings is conducted through a dynamic programming process, in which a partial matching mechanism is established to effectively find those un-occluded substrings. Moreover, the most discriminative and stable radial strings are selected optimally by the well-known AdaBoost algorithm to achieve a composite classifier for 3D face recognition under facial expression changes. Experimental results on the GavabDB and the Bosphorus databases show that the proposed approach achieves promising results for human face recognition with expressions and occlusions.},
annote = {International Conference on Digital Image Computing - Techniques and
Applications (DICTA), Gold Coast, AUSTRALIA, NOV 30-DEC 02, 2016},
author = {Yu, Xun and Gao, Yongsheng and Zhou, Jun},
booktitle = {2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016},
doi = {10.1109/DICTA.2016.7797014},
editor = {{Liew, AWC and Lovell, B and Fookes, C and Zhou, J and Gao, Y and Blumenstein, M and Wang}, Z},
file = {:home/tutu/artigos{\_}revisao/07797014.pdf:pdf},
isbn = {9781509028962},
keywords = {face recognition,facial curves,feature selection,machine learning,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,string matching,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
organization = {Australian Govt, Dept Defence, Defence Sci {\&} Technol Grp; IAPR; Canon Informat Syst Res Australia; IEEE; Griffith Univ; APRS},
pages = {1--6},
publisher = {IEEE},
title = {{Boosting Radial Strings for 3D Face Recognition with Expressions and Occlusions}},
url = {http://ieeexplore.ieee.org/document/7797014/},
year = {2016}
}
@article{Guo2016403,
abstract = {This paper presents a local feature based shape matching algorithm for expression-invariant 3D face recognition. Each 3D face is first automatically detected from a raw 3D data and normalized to achieve pose invariance. The 3D face is then represented by a set of keypoints and their associated local feature descriptors to achieve robustness to expression variations. During face recognition, a probe face is compared against each gallery face using both local feature matching and 3D point cloud registration. The number of feature matches, the average distance of matched features, and the number of closest point pairs after registration are used to measure the similarity between two 3D faces. These similarity metrics are then fused to obtain the final results. The proposed algorithm has been tested on the FRGC v2 benchmark and a high recognition performance has been achieved. It obtained the state-of-the-art results by achieving an overall rank-1 identification rate of 97.0{\%} and an average verification rate of 99.01{\%} at 0.001 false acceptance rate for all faces with neutral and non-neutral expressions. Further, the robustness of our algorithm under different occlusions has been demonstrated on the Bosphorus dataset.},
annote = {cited By 7
28/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
28/04 Exclu{\'{i}}do (etapa 1)},
author = {Guo, Yulan and Lei, Yinjie and Liu, Li and Wang, Yan and Bennamoun, Mohammed and Sohel, Ferdous},
doi = {10.1016/j.patrec.2016.04.003},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2016 - EI3D Expression-invariant 3D face recognition based on feature and shape matching.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {3D face recognition,Face identification,Facial expression,Keypoint detection,Local feature,Shape matching,etapa1,id384,isi,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
mendeley-tags = {etapa1,id384,isi,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
pages = {403--412},
title = {{EI3D: Expression-invariant 3D face recognition based on feature and shape matching}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966659227{\&}doi=10.1016{\%}2Fj.patrec.2016.04.003{\&}partnerID=40{\&}md5=b09b19b7a5436b53278c02d001e93910},
volume = {83},
year = {2016}
}
@inproceedings{ISI:000390782003008,
abstract = {3D face recognition with partial occlusions is a highly challenging
problem. In this paper, we propose a novel radial string representation
and matching approach to recognize 3D facial scans in the presence of
partial occlusions. Here we encode 3D facial surfaces into an indexed
collection of radial strings emanating from the nosetips and Dynamic
Programming (DP) is then used to measure the similarity between two
radial strings. In order to address the recognition problems with
partial occlusions, a partial matching mechanism is established in our
approach that effectively eliminates those occluded parts and finds the
most discriminative parts during the matching process. Experimental
results on the Bosphorus database demonstrate that the proposed approach
yields superior performance on partially occluded data.},
annote = {From Duplicate 1 (3D face recognition under partial occlusions using radial strings - Yu, Xun; Gao, Yongsheng; Zhou, Jun)

From Duplicate 1 (3D face recognition under partial occlusions using radial strings - Yu, Xun; Gao, Yongsheng; Zhou, Jun)

23rd IEEE International Conference on Image Processing (ICIP), Phoenix,
AZ, SEP 25-28, 2016

From Duplicate 2 (3D face recognition under partial occlusions using radial strings - Yu, Xun; Gao, Yongsheng; Zhou, Jun)

23rd IEEE International Conference on Image Processing (ICIP), Phoenix,
AZ, SEP 25-28, 2016},
author = {Yu, Xun and Gao, Yongsheng and Zhou, Jun},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2016.7532913},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Gao, Zhou - 2016 - 3D face recognition under partial occlusions using radial strings.pdf:pdf},
isbn = {9781467399616},
issn = {15224880},
keywords = {3D face recognition,Partial occlusions,Radial string matching,Structural recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {sep},
organization = {Inst Elect {\&} Elect Engineers; Inst Elect {\&} Elect Engineers, Signal Proc Soc},
pages = {3016--3020},
publisher = {IEEE},
series = {IEEE International Conference on Image Processing ICIP},
title = {{3D face recognition under partial occlusions using radial strings}},
url = {http://ieeexplore.ieee.org/document/7532913/},
volume = {2016-Augus},
year = {2016}
}
@inproceedings{7797090,
abstract = {3D face recognition holds great promise in achieving robustness to pose, expressions and occlusions. However, 3D face recognition algorithms are still far behind their 2D counterparts due to the lack of large-scale datasets. We present a model based algorithm for 3D face recognition and test its performance by combining two large public datasets of 3D faces. We propose a Fully Convolutional Deep Network (FCDN) to initialize our algorithm. Reliable seed points are then extracted from each 3D face by evolving level set curves with a single curvature dependent adaptive speed function. We then establish dense correspondence between the faces in the training set by matching the surface around the seed points on a template face to the ones on the target faces. A morphable model is then fitted to probe faces and face recognition is performed by matching the parameters of the probe and gallery faces. Our algorithm achieves state of the art landmark localization results. Face recognition results on the combined FRGCv2 and Bosphorus datasets show that our method is effective in recognizing query faces with real world variations in pose and expression, and with occlusion and missing data despite a huge gallery. Comparing results of individual and combined datasets show that the recognition accuracy drops when the size of the gallery increases.},
annote = {23/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
23/04/2018 Exclu{\'{i}}do (etapa 1)
04/05/2018 Revisado (etapa 1)},
author = {Gilani, S Z and Mian, A},
booktitle = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
doi = {10.1109/DICTA.2016.7797090},
file = {:home/tutu/artigos{\_}revisao/07797090.pdf:pdf},
keywords = {convolution,estela,etapa1,face recognition,feature extraction,id181,ieeexplore,im,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {estela,etapa1,id181,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
pages = {1--8},
title = {{Towards Large-Scale 3D Face Recognition}},
year = {2016}
}
@article{ISI:000449193300001,
abstract = {3D face recognition is an important topic in the field of pattern recognition and computer graphic. We propose a novel approach for 3D face recognition using local conformal parameterization and iso-geodesic stripes. In our framework, the 3D facial surface is considered as a Riemannian 2-manifold. The surface is mapped into the 2D circle parameter domain using local conformal parameterization. In the parameter domain, the geometric features are extracted from the iso-geodesic stripes. Combining the relative position measure, Chain 2D Weighted Walkthroughs (C2DWW), the 3D face matching results can be obtained. The geometric features from iso-geodesic stripes in parameter domain are robust in terms of head poses, facial expressions, and some occlusions. In the experiments, our method achieves a high recognition accuracy of 3D facial data from the Texas3D and Bosphorus3D face database.},
author = {Lv, Chenlei and Zhao, Junli},
doi = {10.1155/2018/4707954},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lv, Zhao - 2018 - 3D Face Recognition based on Local Conformal Parameterization and Iso-Geodesic Stripes Analysis.pdf:pdf},
issn = {1024-123X},
journal = {Mathematical Problems in Engineering},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {1--10},
title = {{3D Face Recognition based on Local Conformal Parameterization and Iso-Geodesic Stripes Analysis}},
volume = {2018},
year = {2018}
}
@article{Liang:2015:BMD:2805325.2805648,
abstract = {Due to the difficulties associated with the collection of 3D samples, 3D face recognition technologies often have to work with smaller than desirable sample sizes. With the aim of enlarging the training number for each subject, we divide each training image into several patches. However, this immediately introduces two further problems for 3D models: high computational cost and dispersive features caused by the divided 3D image patches. We therefore first map 3D face images into 2D depth images, which greatly reduces the dimension of the samples. Though the depth images retain most of the robust features of 3D images, such as pose and illumination invariance, they lose many discriminative features of the original 3D samples. In this study, we propose a Bayesian learning framework to extract the discriminative features from the depth images. Specifically, we concentrate the features of the intra-class patches to a mean feature by maximizing the multivariate Gaussian likelihood function, and, simultaneously, enlarge the distances between the inter-class mean features by maximizing the exponential priori distribution of the mean features. For classification, we use the nearest neighbor classifier combined with the Mahalanobis distance to calculate the distance between the features of the test image and items in the training set. Experiments on two widely-used 3D face databases demonstrate the efficiency and accuracy of our proposed method compared to relevant state-of-the-art methods.},
address = {New York, NY, USA},
annote = {26/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Liang, Ronghua and Shen, Wenjia and Li, Xiao Xin and Wang, Haixia},
doi = {10.1016/j.ins.2015.03.063},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2015 - Bayesian multi-distribution-based discriminative feature extraction for 3D face recognition.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {3D face recognition,Bayesian learning,Depth image,Single training sample per person,acm,estela,etapa1,id283,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id283,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
number = {C},
pages = {406--417},
publisher = {Elsevier Science Inc.},
title = {{Bayesian multi-distribution-based discriminative feature extraction for 3D face recognition}},
url = {http://dx.doi.org/10.1016/j.ins.2015.03.063 http://linkinghub.elsevier.com/retrieve/pii/S0020025515002364},
volume = {320},
year = {2015}
}
@inproceedings{ISI:000386931400187,
abstract = {{\textcopyright} 2016 IEEE. 3D partial face recognition under missing parts, occlusions and data corruptions is a major challenge for the practical application of the techniques of 3D face recognition. Moreover, one individual can only provide one sample for training in most practical scenarios, and thus the face recognition with single sample problem is another highly challenging task. We propose an efficient framework for 3D partial face recognition with single sample addressing both of the two problems. First, we represent a facial scan with a set of keypoint based local geometrical descriptors, which gains sufficient robustness to partial facial data along with expression/pose variations. Then, a two-step modified collaborative representation classification scheme is proposed to address the single sample recognition problem. A class-based probability estimation is given during the first classification step, and the obtained result is then incorporated into the modified collaborative representation classification as a locality constraint to improve its classification performance. Extensive experiments on the Bosphorus and FRGC v2.0 datasets demonstrate the efficiency of the proposed approach when addressing the problem of 3D partial face recognition with single sample.},
annote = {IEEE 11th Conference on Industrial Electronics and Applications (ICIEA),
Hefei, PEOPLES R CHINA, JUN 05-07, 2016},
author = {Lei, Yinjie and Feng, Siyu and Zhou, Xinzhi and Guo, Yulan},
booktitle = {Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016},
doi = {10.1109/ICIEA.2016.7603727},
file = {:home/tutu/artigos{\_}revisao/07603727.pdf:pdf},
isbn = {9781509026050},
issn = {2156-2318},
keywords = {3D facial representation,3D partial face recognition,collaborative representation,locality constraint,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,single sample problem,tutux6},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutux6},
month = {jun},
organization = {IEEE; IEEE Ind Elect Soc; IEEE Ind Elect Chapter; IEEE Singapore Sect; Anhui Univ},
pages = {994--999},
publisher = {IEEE},
series = {IEEE Conference on Industrial Electronics and Applications},
title = {{An efficient 3D partial face recognition approach with single sample}},
url = {http://ieeexplore.ieee.org/document/7603727/},
year = {2016}
}
@article{Sghaier:2018:NTF:3193702.3193706,
abstract = {This manuscript presents an improved system research that can detect and recognize the person in 3D space automatically and without the interaction of the people's faces. This system is based not only on a quantum computation and measurements to extract the vector features in the phase of characterization but also on learning algorithm (using SVM) to classify and recognize the person. This research presents an improved technique for automatic 3D face recognition using anthropometric proportions and measurement to detect and extract the area of interest which is unaffected by facial expression. This approach is able to treat incomplete and noisy images and reject the non-facial areas automatically. Moreover, it can deal with the presence of holes in the meshed and textured 3D image. It is also stable against small translation and rotation of the face. All the experimental tests have been done with two 3D face datasets FRAV 3D and GAVAB. Therefore, the test's results of the proposed approach are promising because they showed that it is competitive comparable to similar approaches in terms of accuracy, robustness, and flexibility. It achieves a high recognition performance rate of 95.35{\%} for faces with neutral and non-neutral expressions for the identification and 98.36{\%} for the authentification with GAVAB and 100{\%} with some gallery of FRAV 3D datasets.},
address = {Hershey, PA, USA},
annote = {02/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
02/05/2018 Exclu{\'{i}}do (etapa 1)

janeiro de 2018},
author = {Sghaier, Souhir and Farhat, Wajdi and Souani, Chokri},
doi = {10.4018/ijaci.2018010104},
issn = {1941-6237},
journal = {International Journal of Ambient Computing and Intelligence},
keywords = {3D Face,Anthropometric,Euclidean Distance,Eye Corners,Feature Extraction,Learning,Measurements,Nose Tip,acm,etapa1,gil,id431,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id431,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {60--77},
publisher = {IGI Global},
title = {{Novel Technique for 3D Face Recognition Using Anthropometric Methodology}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJACI.2018010104},
volume = {9},
year = {2017}
}
@article{Deng20171305,
abstract = {A novel adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition is proposed in this paper. Firstly, the novel facial coarse-to-fine landmarks localization method based on Active Shape Model and Gabor wavelets transformation is proposed to exactly and automatically locate facial landmarks in range image. Secondly, the multi-scale fusion of the pyramid local binary patterns (F-PLBP) based on the irregular segmentation associated with the located landmarks is proposed to extract the discriminative feature. Thirdly, a sparse representation-based classifier based on the adaptive feature selection (A-SRC) using the distribution of the reconstruction residual is presented to select the expression-robust feature and identify the faces. Finally, the experimental evaluation based on FRGC v2.0 indicates that the adaptive feature selection method using F-PLBP combined with the A-SRC can obtain the high recognition accuracy by performing the higher discriminative power to overcome the influence from the facial expression variations.},
annote = {cited By 0
01/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
01/05/2018 Exclu{\'{i}}do (etapa 1)},
author = {Deng, Xing and Da, Feipeng and Shao, Haijian},
doi = {10.1007/s11760-017-1087-6},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Da, Shao - 2017 - Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robu.pdf:pdf},
issn = {18631711},
journal = {Signal, Image and Video Processing},
keywords = {3D face recognition,Adaptive feature selection,Facial landmark localization,Multi-scale fusion,estela,etapa1,id422,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
mendeley-tags = {estela,etapa1,id422,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,scopus,tutui1},
number = {7},
pages = {1305--1312},
title = {{Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017095710{\&}doi=10.1007{\%}2Fs11760-017-1087-6{\&}partnerID=40{\&}md5=fc06247cc3ca7870221563a085266269},
volume = {11},
year = {2017}
}
@article{Peter201977,
abstract = {Face recognition is commonly used for biometric security purposes in video surveillance and user authentications. The nature of face exhibits non-linear shapes due to appearance deformations, and face variations presented by facial expressions. Recognizing faces reliably across changes in facial expression has proved to be a more difficult problem leading to low recognition rates in many face recognition experiments. This is mainly due to the tens degree-of-freedom in a non-linear space. Recently, non-linear PCA has been revived as it posed a significant advantage for data representation in high dimensionality space. In this paper, we experimented the use of non-linear kernel approach in 3D face recognition and the results of the recognition rates have shown that the kernel method outperformed the standard PCA. {\textcopyright} Springer Nature Singapore Pte Ltd. 2019.},
annote = {cited By 0},
author = {Peter, Marcella and Minoi, Jacey Lynn and Hipiny, Irwandi Hipni Mohamad},
doi = {10.1007/978-981-13-2622-6_8},
file = {:home/tutu/artigos{\_}revisao/55e48f9de70a93e32edc3f1ed2f2bb70-peter2018.pdf:pdf},
isbn = {9789811326219},
issn = {18761119},
journal = {Lecture Notes in Electrical Engineering},
keywords = {3D face,Facial recognition,Kernel PCA,revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {77--86},
title = {{3D face recognition using kernel-based PCA approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053242189{\&}doi=10.1007{\%}2F978-981-13-2622-6{\_}8{\&}partnerID=40{\&}md5=c4b90626b4453034107d227cbd63ef3d},
volume = {481},
year = {2019}
}
@inproceedings{Ahdid201873,
abstract = {In this paper, we present an automatic 3D face recognition system. This system is based on the representation of human faces surfaces as collections of Iso-Geodesic Curves (IGC) using 3D Fast Marching algorithm. To compare two facial surfaces, we compute a geodesic distance between a pair of facial curves using a Riemannian geometry. In the classifying step, we use: Neural Networks (NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this method and evaluate its performance, a simulation series of experiments were performed on 3D Shape REtrieval Contest 2008 database (SHREC2008).},
annote = {cited By 0},
author = {Ahdid, Rachid and Taifi, Khaddouj and Said, Said and Fakir, Mohamed and Manaut, Bouzid},
booktitle = {Proceedings - 2017 14th International Conference on Computer Graphics, Imaging and Visualization, CGiV 2017},
doi = {10.1109/CGiV.2017.25},
file = {:home/tutu/artigos{\_}revisao/08361546.pdf:pdf},
isbn = {9781538608524},
keywords = {3D face recognition,Riemannian geometry,facial surfaces,geodesic distance,iso-geodesic curves,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {73--78},
title = {{Automatic face recognition system using iso-geodesic curves in riemanian manifold}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048323921{\&}doi=10.1109{\%}2FCGiV.2017.25{\&}partnerID=40{\&}md5=73b9e65d367cee00cdcb28e7b5ef55cb},
year = {2018}
}
@inproceedings{ISI:000460471100001,
abstract = {This paper presents an efficient 3D face recognition method to handle facial expression. The proposed method uses the Surfaces Empirical Mode Decomposition (SEMD), facial curves and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. The basic idea is that, the face is presented at different scales by SEMD. Then the isometric-invariant features on each scale are extracted. After that, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Finally, the feature vectors on each scale are associated with their corresponding geometric information. The presented method is validated on GavabDB database resulting a rank 1 recognition rate (RR) of 98.9{\%} for all faces with neutral and non-neutral expressions. This result outperforms other 3D expression-invariant face recognition methods on the same database.},
annote = {2nd Mediterranean Conference on Pattern Recognition and Artificial
Intelligence (MedPRAI), Ibn Tofail Univ, Rabat, MOROCCO, MAR 27-28, 2018},
author = {Abbad, Abdelghafour and Abbad, Khalid and Tairi, Hamid},
booktitle = {PROCEEDINGS OF THE 2ND MEDITERRANEAN CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (MEDPRAI-2018)},
doi = {10.1145/3177148.3180087},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbad, Abbad, Tairi - 2018 - 3D face recognition in the presence of facial expressions based on empirical mode decomposition.pdf:pdf},
isbn = {978-1-4503-5290-1},
keywords = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Bahria Univ; Univ Larbi Tebessi Tebessa; OCP; ENSIAS; Int Assoc Pattern Recognit},
pages = {1--6},
title = {{3D face recognition in the presence of facial expressions based on empirical mode decomposition}},
year = {2018}
}
@inproceedings{ISI:000390782003007,
abstract = {We propose a 3D face modeling and recognition system using an RGB-D stream in the presence of large pose changes. In the previous work, all facial data points are registered with a reference to improve the accuracy of 3D face model from a low-resolution depth sequence. This registration often fails when applied to non-frontal faces. It causes inaccurate 3D face models and poor performance of matching. We address this problem by pre-aligning each input face ('frontalization') before the registration, which avoids registration failures. For each frame, our method estimates the 3D face pose, assesses the quality of data, segments the facial region, frontalizes it. and performs an accurate registration with the previous 3D model. The 3D 3D recognition system using accurate 3D models from our method outperforms other face recognition systems and shows 100{\%} rank 1 recognition accuracy on a dataset with 30 subjects.},
annote = {23rd IEEE International Conference on Image Processing (ICIP), Phoenix,
AZ, SEP 25-28, 2016},
author = {Kim, Donghyun and Choi, Jongmoo and Leksut, Jatuporn Toy and Medioni, Gerard},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2016.7532912},
file = {:home/tutu/artigos{\_}revisao/07532912.pdf:pdf},
isbn = {9781467399616},
issn = {15224880},
keywords = {3D Face Modeling,3D Face Recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutux10},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutux10},
month = {sep},
organization = {Inst Elect {\&} Elect Engineers; Inst Elect {\&} Elect Engineers, Signal Proc Soc},
pages = {3011--3015},
publisher = {IEEE},
series = {IEEE International Conference on Image Processing ICIP},
title = {{Accurate 3D face modeling and recognition from RGB-D stream in the presence of large pose changes}},
url = {http://ieeexplore.ieee.org/document/7532912/},
volume = {2016-Augus},
year = {2016}
}
@article{Zhao2018207,
abstract = {{\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature. 3D face similarity is a critical issue in computer vision, computer graphics and face recognition and so on. Since Fr{\'{e}}chet distance is an effective metric for measuring curve similarity, a novel 3D face similarity measure method based on Fr{\'{e}}chet distances of geodesics is proposed in this paper. In our method, the surface similarity between two 3D faces is measured by the similarity between two sets of 3D curves on them. Due to the intrinsic property of geodesics, we select geodesics as the comparison curves. Firstly, the geodesics on each 3D facial model emanating from the nose tip point are extracted in the same initial direction with equal angular increment. Secondly, the Fr{\'{e}}chet distances between the two sets of geodesics on the two compared facial models are computed. At last, the similarity between the two facial models is computed based on the Fr{\'{e}}chet distances of the geodesics obtained in the second step. We verify our method both theoretically and practically. In theory, we prove that the similarity of our method satisfies three properties: reflexivity, symmetry, and triangle inequality. And in practice, experiments are conducted on the open 3D face database GavaDB, Texas 3D Face Recognition database, and our 3D face database. After the comparison with iso-geodesic and Hausdorff distance method, the results illustrate that our method has good discrimination ability and can not only identify the facial models of the same person, but also distinguish the facial models of any two different persons.},
annote = {cited By 0},
author = {Zhao, Jun Li and Wu, Zhong Ke and Pan, Zhen Kuan and Duan, Fu Qing and Li, Jin Hua and Lv, Zhi Han and Wang, Kang and Chen, Yu Cong},
doi = {10.1007/s11390-018-1814-7},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2018 - 3D Face Similarity Measure by Fr{\'{e}}chet Distances of Geodesics.pdf:pdf},
issn = {18604749},
journal = {Journal of Computer Science and Technology},
keywords = {3D face,Fr{\'{e}}chet distance,geodesic,revisao{\_}V1,revisao{\_}scopus,similarity measure,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {1},
pages = {207--222},
title = {{3D Face Similarity Measure by Fr{\'{e}}chet Distances of Geodesics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041342736{\&}doi=10.1007{\%}2Fs11390-018-1814-7{\&}partnerID=40{\&}md5=8478bdecdc0eeeb6cb4dda3bb1ecda52},
volume = {33},
year = {2018}
}
@inproceedings{ISI:000400688200019,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2016. Landmarks are unique points that can be located on every face. Facial landmarks typically recognized by people are correlated with anthropomorphic points. Our purpose is to employ in 3D face recognition such landmarks that are easy to interpret. Face understanding is construed as identification of face characteristic points with automatic labeling of them. In this paper, we apply methods based on Self Organizing Maps to understand 3D faces.},
annote = {15th International Conference on Artificial Intelligence and Soft
Computing (ICAISC), Zakopane, POLAND, JUN 12-16, 2016},
author = {Starczewski, Janusz T. and Pabiasz, Sebastian and Vladymyrska, Natalia and Marvuglia, Antonino and Napoli, Christian and W{\'{o}}zniak, Marcin},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-39384-1_19},
editor = {{Rutkowski, L and Korytkowski, M and Scherer, R and Tadeusiewicz, R and Zadeh, LA and Zurada}, JM},
isbn = {9783319393834},
issn = {16113349},
keywords = {3D face recognition,Self organizing maps,Understanding of images,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Polish Neural Network Soc; Univ Social Sci; Czestochowa Univ Technol, Inst Computat Intelligence},
pages = {210--217},
series = {Lecture Notes in Artificial Intelligence},
title = {{Self organizing maps for 3D face understanding}},
volume = {9693},
year = {2016}
}
@article{Dutta2019175,
abstract = {In this paper, a 3D face recognition system has been developed based on the volumetric representation of 3D range image. The main approach to build this system is to calculate volume on some distinct region of 3D range face data. The system has mainly three steps. In the very first step, seven significant facial landmarks are identified on the face. Secondly, six distinct triangular regions A to F are created on the face using any three individual landmarks where nose tip is common to all regions. Further 3D volumes of all the respective triangular regions have been calculated based on plane fitting on the input range images. Finally, KNN and SVM classifiers are considered for classification. Initially, the classification and recognition are carried out on the different volumetric region, and a further combination of all the regions is considered. The proposed approach is tested on three useful challenging databases, namely Frav3D, Bosphorous, and GavabDB.},
annote = {cited By 1},
author = {Dutta, Koushik and Bhattacharjee, Debotosh and Nasipuri, Mita and Poddar, Anik},
doi = {10.1007/978-981-13-3702-4_11},
file = {:home/tutu/artigos{\_}revisao/d1ccc7669cac94b04182f44edc5e57cd-dutta2019.pdf:pdf},
isbn = {9789811337017},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {3D range image,Classification,Facial landmark,Plane fitting,Volumetric representation,revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {175--189},
title = {{3D face recognition based on volumetric representation of range image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061157145{\&}doi=10.1007{\%}2F978-981-13-3702-4{\_}11{\&}partnerID=40{\&}md5=2543d63ceec9074d39578ea3320cdfbd},
volume = {883},
year = {2019}
}
@article{Zhang20151817,
abstract = {Expression, occlusion, and pose variations are three main challenges for 3D face recognition. A novel method is presented to address 3D face recognition using scale-invariant feature transform (SIFT) features on 3D meshes. After preprocessing, shape index extrema on the 3D facial surface are selected as keypoints in the difference scale space and the unstable keypoints are removed after two screening steps. Then, a local coordinate system for each keypoint is established by principal component analysis (PCA). Next, two local geometric features are extracted around each keypoint through the local coordinate system. Additionally, the features are augmented by the symmetrization according to the approximate left-right symmetry in human face. The proposed method is evaluated on the Bosphorus, BU-3DFE, and Gavab databases, respectively. Good results are achieved on these three datasets. As a result, the proposed method proves robust to facial expression variations, partial external occlusions and large pose changes. {\textcopyright} 2015, Central South University Press and Springer-Verlag Berlin Heidelberg.},
annote = {cited By 5},
author = {Zhang, Cheng and zhang Gu, Yu and li Hu, Ke and guan Wang, Ying},
doi = {10.1007/s11771-015-2700-x},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2015 - Face recognition using SIFT features under 3D meshes.pdf:pdf},
issn = {22275223},
journal = {Journal of Central South University},
keywords = {3D face recognition,3D meshes,expression,large pose changes,occlusion,revisao{\_}scopus,scale-invariant feature transform (SIFT)},
mendeley-tags = {revisao{\_}scopus},
number = {5},
pages = {1817--1825},
title = {{Face recognition using SIFT features under 3D meshes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930008100{\&}doi=10.1007{\%}2Fs11771-015-2700-x{\&}partnerID=40{\&}md5=569ac008f1ef201b7fcbffd9e0faa163},
volume = {22},
year = {2015}
}
@incollection{Quan2015199,
abstract = {We propose an unsupervised online learning method based on the “growing neural gas” algorithm (GNG), for a data-stream configuration where each incoming data is visited only once and used to incrementally update the learned model as soon as it is available. The method maintains a model as a dynamically evolving graph topology of data-representatives that we call neurons. Unlike usual incremental learning methods, it avoids the sensitivity to initialization parameters by using an adaptive parameter-free distance threshold to produce new neurons. More-over, the proposed method performs a merging process which uses a distance-based probabilistic criterion to eventually merge neurons. This allows the algorithm to preserve a good computational efficiency over infinite time. Experiments on different real datasets, show that the proposed method is competitive with existing algorithms of the same family, while being independent of sensitive parameters and being able to maintain fewer neurons, which makes it convenient for learning from infinite data-streams.},
annote = {cited By 0},
author = {Quan, Wei and Matuszewski, Bogdan J. and Shark, Lik Kwan},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-27677-9_13},
isbn = {9783319276762},
issn = {16113349},
keywords = {3-D face recognition,Geodesic-map representation,Non-rigid deformation,Shape modeling,revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {199--212},
title = {{3-D Face Recognition Using Geodesic-Map Representation and Statistical Shape Modelling}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955314982{\&}doi=10.1007{\%}2F978-3-319-27677-9{\_}13{\&}partnerID=40{\&}md5=e85737d15347f5ea197969c838869be9 http://link.springer.com/10.1007/978-3-319-27677-9{\_}13},
volume = {9493},
year = {2015}
}
@inproceedings{ISI:000401510000148,
abstract = {{\textcopyright} 2016 IEEE. Feature selection from facial regions is a well-known approach to increase the performance of 2D image-based face recognition systems. In case of 3D modality, the approach of region-based feature selection for face recognition is relatively new. In this context, this paper presents an approach to evaluate the discrimination power of different regions of a 3D facial surface for its potential use in face recognition systems. We propose the use of weighted average of unit normal vector on the facial surface as the feature for region-based face recognition from 3D point cloud data (PCD). The iterative closest point algorithm is employed for the registration of segmented regions of facial point clouds. A metric based on angular distance between normals is introduced to indicate the similarity between two surfaces of same facial region. Finally, the intra class correlation based discrimination score is formulated to find out the key facial regions such as the eyes, nose, and mouth that are significant while recognizing a person with facial surface PCD.},
annote = {From Duplicate 1 (Evaluation of Discrimination power of facial parts from 3D point cloud data - Amin, Rafiul; Shams, A. Farhan; Rahman, S. M.Mahbubur; Hatzinakos, Dimitrios)

9th International Conference on Electrical and Computer Engineering
(ICECE), Dhaka, BANGLADESH, DEC 20-22, 2016},
author = {Amin, Rafiul and Shams, A. Farhan and Rahman, S. M.Mahbubur and Hatzinakos, Dimitrios},
booktitle = {Proceedings of 9th International Conference on Electrical and Computer Engineering, ICECE 2016},
doi = {10.1109/ICECE.2016.7853992},
file = {:home/tutu/artigos{\_}revisao/07853992.pdf:pdf},
isbn = {9781509029631},
keywords = {lerdepois,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {lerdepois,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
month = {dec},
organization = {Bangladesh Univ Engn {\&} Technol, Dept Elect {\&} Elect Engn; Inst Elect {\&} Elect Engineers; Energypac; PARADISE Cables ltd; BTCL; Summit Communicat Ltd; Dhaka Power Distribut Co Ltd},
pages = {602--605},
publisher = {IEEE},
series = {International Conference on Computer and Electrical Engineering ICCEE},
title = {{Evaluation of Discrimination power of facial parts from 3D point cloud data}},
url = {http://ieeexplore.ieee.org/document/7853992/},
year = {2017}
}
@article{Gaonkar201615,
abstract = {3D face recognition has gain a paramount importance over 2D due to its potential to address the limitations of 2D face recognition against the variation in facial poses, angles, occlusions etc. Research in 3D face recognition has accelerated in recent years due to the development of low cost 3D Kinect camera sensor. This has leads to the development of few RGB-D database across the world. Here in this paper we introduce the base results of our 3D facial database (GU-RGBD database) comprising variation in pose (0°, 45°, 90°, −45°, −90°), expression (smile, eyes closed), occlusion (half face covered with paper) and illumination variation using Kinect. We present a proposed noise removal non-linear interpolation filter for the patches present in the depth images. The results were obtained on three face recognition algorithms and fusion at matching score level for recognition and verification rate. The obtained results indicated that the performance with our proposed filter shows improvement over pose with score level fusion using sum rule. {\textcopyright} Springer International Publishing AG 2017.},
annote = {cited By 0},
author = {Gaonkar, A. A. and Gad, M. D. and Vetrekar, N. T. and Tilve, Vithal Shet and Gad, R. S.},
doi = {10.1007/978-3-319-68124-5_2},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {lerdepois,revisao{\_}V2,revisao{\_}scopus,tutui2},
mendeley-tags = {lerdepois,revisao{\_}V2,revisao{\_}scopus,tutui2},
pages = {15--26},
title = {{Experimental evaluation of 3D kinect face database}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057824711{\&}doi=10.1007{\%}2F978-3-319-68124-5{\_}2{\&}partnerID=40{\&}md5=3a104665aebdb39c053c8b83ce35c8fb},
volume = {10481 LNCS},
year = {2016}
}
@inproceedings{7387550,
abstract = {Face recognition research mainly focuses on traditional 2D color images, which is extremely susceptible to be affected by external factors such as various viewpoints and has limited recognition accuracy. In order to achieve improved recognition performance, as well as the 3D face holds more abundant information than 2D, we present a 3D human face recognition algorithm using the Microsoft's Kinect. The proposed approach integrates the depth data with the RGB data to generate 3D face raw data and then extracts feature points, identifies the target via a two-level cascade classifier. Also, we build a 3D-face database including 16 individuals captured exclusively using Kinect. The experimental results indicate that the introduced algorithm can not only achieve better recognition accuracy in comparison to existing 2D and 3D face recognition algorithms when the probe face is exactly in front of Kinect sensor, but also can increase 9.3{\%} of recognition accuracy compared to the PCA-3D algorithm when it is not confronting the camera.},
annote = {09/05/2018 Em processo de sele{\c{c}}{\~{a}}o (Etapa 1)
09/05/2018 Exclu{\'{i}}do (Etapa 1)},
author = {Zhou, Wei and Chen, Jian Xin and Wang, Lei},
booktitle = {Proceedings of 2015 IEEE International Conference on Computer and Communications, ICCC 2015},
doi = {10.1109/CompComm.2015.7387550},
file = {:home/tutu/artigos{\_}revisao/07387550.pdf:pdf},
isbn = {9781467381253},
keywords = {3D face recognition,Kinect,RGB-D images,XML file,artur,classifier,etapa1,id459,ieeexplore,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {artur,etapa1,id459,ieeexplore,revisao{\_}V1,revisao{\_}scopus,tutui1},
month = {oct},
pages = {109--114},
publisher = {IEEE},
title = {{A RGB-D face recognition approach without confronting the camera}},
url = {http://ieeexplore.ieee.org/document/7387550/},
year = {2016}
}
@inproceedings{ISI:000390841700083,
abstract = {We propose a robust method for 3D face recognition using 3D to 2D modeling and facial curvatures detection. The 3D-2D algorithm permits to transform 3D images into 3D triangular mesh, then the mesh model is deformed and fitted to the 2D space in order to obtain a 2D smoother mesh. Then, we apply Gabor wavelets to the deformed model in order to exploit surface curves in the detection of salient face features. The classification of the final Gabor facial model is performed using the support vector machines (SVM). To demonstrate the quality of our technique, we give some experiments using the 3D AJMAL faces database. The experimental results prove that the proposed method is able to give a good recognition quality and a high accuracy rate.},
annote = {2nd International Conference on Advanced Technologies for Signal and
Image Processing (ATSIP), Monastir, TUNISIA, MAR 21-23, 2016},
author = {Torkhani, Ghada and Ladgham, Anis and Mansouri, Mohamed Nejib and Sakly, Anis},
booktitle = {2nd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2016},
doi = {10.1109/ATSIP.2016.7523133},
file = {:home/tutu/artigos{\_}revisao/07523133.pdf:pdf},
isbn = {9781467385268},
keywords = {3D face recognition,Gabor wavelet,SVM,deformed mesh model,facial curvatures,fatima,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,salient points,tutui1},
mendeley-tags = {fatima,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {mar},
organization = {IEEE; IEEE Tunisia Sect; ATMS Lab; ATSI; IEEE Explore; EMB; ENIS Sch; Telecom Paris; Supelec; CESBIO; Telecom SudParis; ENIT; Univ Paris Sud; IEEE Signal Proc Soc Tunisia Chapter; ISAAM Inst; Minist Higher Educ Res; IEEE EMP Tunisia Chapter; Novartis Comp},
pages = {447--452},
publisher = {IEEE},
title = {{Gabor-SVM applied to 3D-2D deformed mesh model}},
url = {http://ieeexplore.ieee.org/document/7523133/},
year = {2016}
}
@article{ISI:000370290900001,
abstract = {Curvelet transform can describe the signal by multiple scales, and multiple directions. In order to improve the performance of 3D face recognition algorithm, we proposed an Anthropometric and Curvelet features fusion-based algorithm for 3D face recognition (Anthropometric Curvelet Fusion Face Recognition, ACFFR). First, the eyes, nose, and mouth feature regions are extracted by the Anthropometric characteristics and curvature features of the human face. Second, Curvelet energy features of the facial feature regions at different scales and different directions are extracted by Curvelet transform. At last, Euclidean distance is used as the similarity between template and objectives. To verify the performance, the proposed algorithm is compared with Anthroface3D and Curveletface3D on the Texas 3D FR database. The experimental results have shown that the proposed algorithm performs well, with equal error rate of 1.75{\%} and accuracy of 97.0{\%}. The algorithm we proposed in this paper has better robustness to expression and light changes than Anthroface3D and Curveletface3D.},
author = {Song, Dan and Luo, Jing and Zi, Chunyuan and Tian, Huixin},
doi = {10.1155/2016/6859364},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2016 - 3D Face Recognition Using Anthropometric and Curvelet Features Fusion.pdf:pdf},
issn = {16877268},
journal = {Journal of Sensors},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
title = {{3D Face Recognition Using Anthropometric and Curvelet Features Fusion}},
volume = {2016},
year = {2016}
}
@article{ISI:000448833400016,
abstract = {In this study, a fully automatic pose and expression invariant 3D face
alignment algorithm is proposed to handle frontal and profile face
images which is based on a two pass course to fine alignment strategy.
The first pass of the algorithm coarsely aligns the face images to an
intrinsic coordinate system (ICS) through a single 3D rotation and the
second pass aligns them at fine level using a minimum nose tip-scanner
distance (MNSD) approach. For facial recognition, multi-view faces are
synthesized to exploit real 3D information and test the efficacy of the
proposed system. Due to optimal separating hyper plane (OSH), Support
Vector Machine (SVM) is employed in multi-view face verification (FV)
task. In addition, a multi stage unified classifier based face
identification (FI) algorithm is employed which combines results from
seven base classifiers, two parallel face recognition algorithms and an
exponential rank combiner, all in a hierarchical manner. The performance
figures of the proposed methodology are corroborated by extensive
experiments performed on four benchmark datasets: GavabDB, Bosphorus,
UMB-DB and FRGC v2.0. Results show mark improvement in alignment
accuracy and recognition rates. Moreover, a computational complexity
analysis has been carried out for the proposed algorithm which reveals
its superiority in terms of computational efficiency as well.},
author = {Ratyal, Naeem and Taj, Imtiaz and Bajwa, Usama and Sajid, Muhammad},
doi = {10.3837/tiis.2018.10.016},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratyal et al. - 2018 - Pose and Expression Invariant Alignment based Multi-View 3D Face Recognition.pdf:pdf},
issn = {22881468},
journal = {KSII Transactions on Internet and Information Systems},
keywords = {3D FR,3D alignment,Profile face,SVM,Unified classifier,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {10},
pages = {4903--4929},
title = {{Pose and expression invariant alignment based multi-view 3d face recognition}},
volume = {12},
year = {2018}
}
@article{ISI:000408398200010,
abstract = {Recognition of faces typically occurs via holistic processing where individual features are combined to provide an overall facial representation. However, when faces are inverted, there is greater reliance on featural processing where faces are recognized based on their individual features. These findings are based on a substantial number of studies using 2-dimensional (2D) faces and it is unknown whether these results can be extended to 3-dimensional (3D) faces, which have more depth information that is absent in the typical 2D stimuli used in face recognition literature. The current study used the face inversion paradigm as a means to investigate how holistic and featural processing are differentially influenced by 2D and 3D faces. Twenty-five participants completed a delayed face-matching task consisting of upright and inverted faces that were presented as both 2D and 3D stereoscopic images. Recognition accuracy was significantly higher for 3D upright faces compared to 2D upright faces, providing support that the enriched visual information in 3D stereoscopic images facilitates holistic processing that is essential for the recognition of upright faces. Typical face inversion effects were also obtained, regardless of whether the faces were presented in 2D or 3D. Moreover, recognition performances for 2D inverted and 3D inverted faces did not differ. Taken together, these results demonstrated that 3D stereoscopic effects influence face recognition during holistic processing but not during featural processing. Our findings therefore provide a novel perspective that furthers our understanding of face recognition mechanisms, shedding light on how the integration of stereoscopic information in 3D faces influences face recognition processes.},
author = {Eng, Z. H.D. and Yick, Y. Y. and Guo, Y. and Xu, H. and Reiner, M. and Cham, T. J. and Chen, S. H.A.},
doi = {10.1016/j.visres.2017.06.004},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eng et al. - 2017 - 3D faces are recognized more accurately and faster than 2D faces, but with similar inversion effects.pdf:pdf},
issn = {18785646},
journal = {Vision Research},
keywords = {2D,3D,Face inversion effect,Face recognition,Featural processing,Holistic processing,Stereoscopic images,revisao{\_}V1,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
pages = {78--85},
title = {{3D faces are recognized more accurately and faster than 2D faces, but with similar inversion effects}},
volume = {138},
year = {2017}
}
@article{Deng20155509,
abstract = {Copyright {\textcopyright} 2015 Binary Information Press. In order to eliminate the impact of facial expressions and improve the efficiency of calculation, this paper proposes a novel expression-robust 3D face recognition algorithm using region-based feature fusion technique based on multiscale wavelet transformations. The discrete wavelet transformation is applied to extract frequency component features of geometric image based on the semi-rigid face region as well as the non-rigid face region in order to reduce the influence from the facial expression using the Coherent Point Drift non-rigid point set registration. The dimensionality reduction methods are utilized to promote the computational efficiency, and the experimental results show that our algorithm outperforms state-of-the-art methods based on FRGC v2.0.},
annote = {cited By 0},
author = {Deng, X and Da, F and Shao, H},
doi = {10.12733/jcis14953},
journal = {Journal of Computational Information Systems},
keywords = {fatima,lerdepois,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {fatima,lerdepois,revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {15},
pages = {5509--5517},
title = {{Expression-robust 3D face recognition using region-based multiscale wavelet feature fusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950271521{\&}doi=10.12733{\%}2Fjcis14953{\&}partnerID=40{\&}md5=da8d93edfc030808fb309b097e409e94},
volume = {11},
year = {2015}
}
@article{Chouchane2015,
abstract = {{\textcopyright} 2014 IEEE. Face recognition in an uncontrolled condition such as illumination and expression variations is a challenging task. Local descriptor is one of the most efficient methods used to deal with these problems. In this paper, we present an automatic 3D face recognition approach based on three local descriptors, local phase quantization (LPQ), Three-Patch Local Binary Patterns (TPLBP) and Four-Patch Local Binary Patterns (TPLBP). Facial images are passing through one of the three descriptors and divided into sub-regions or rectangular blocks. The histogram of each sub-region is extracted and concatenated into a single feature vector. PCA (Principal Component Analysis) and EFM (Enhanced Fisher linear discriminant Model) are used to reduce the dimensionality of the resulting feature vectors. Finally, these vectors are sent to the classification step, when we use two methods; SVM (Support Victor Machine) and similarity measures. CASIA 3D face database is introduced to experimental evaluation. The experimental results illustrate a high recognition performance of the proposed approach.},
annote = {From Duplicate 2 (3D face recognition based on histograms of local descriptors - Chouchane, A; Belahcene, M; Ouamane, A; Bourennane, S)

cited By 4},
author = {Chouchane, A. and Belahcene, M. and Ouamane, A. and Bourennane, S.},
doi = {10.1109/IPTA.2014.7001925},
file = {:home/tutu/artigos{\_}revisao/07001925.pdf:pdf},
isbn = {9781479964611},
journal = {2014 4th International Conference on Image Processing Theory, Tools and Applications, IPTA 2014},
keywords = {3D face recognition,FPLBP,Local phase quantization,Locale descriptors,Support vector machines,TPLBP,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
title = {{3D face recognition based on histograms of local descriptors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921721830{\&}doi=10.1109{\%}2FIPTA.2014.7001925{\&}partnerID=40{\&}md5=4bbf52130cd2484d05cce4611c376687},
year = {2015}
}
@inproceedings{8122665,
abstract = {3D face recognition is a popular research area due to its vast application in biometrics and security. Local featurebased methods gain importance in the recent years due to their robustness under degradation conditions. In this paper, a novel high-order local pattern descriptor in combination with sparse representation based classifier (SRC) is proposed for expression robust 3D face recognition. 3D point clouds are converted to depth maps after preprocessing. Multi-directional derivatives are applied in spatial space to encode the depth maps based on the local derivative pattern (LDP) scheme. Directional pattern features are calculated according to local derivative variations. Since LDP computes spatial relationship of neighbors in a local region, it extracts distinct information from the depth map. Multiscale depth-LDP is presented as a novel descriptor for 3D face recognition. The descriptor is employed along with the SRC to increase the range data distinctiveness. A histogram on the derivative pattern creates a spatial feature descriptor that represents the distinctive micro-patterns from 3D data. We evaluate the proposed algorithm on two famous 3D face databases, FRGC v2.0 and Bosphorus. The experimental results demonstrate that the proposed approach achieves acceptable performance under facial expression.},
annote = {15/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
15/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Soltanpour, Sima and Wu, Q. M.Jonathan},
booktitle = {2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017},
doi = {10.1109/SMC.2017.8122665},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soltanpour, Wu - 2017 - Multiscale depth local derivative pattern for sparse representation based 3D face recognition.pdf:pdf},
isbn = {9781538616451},
keywords = {emotion recognition,etapa1,face recognition,feature extra,gil,id54,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {etapa1,gil,id54,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {oct},
pages = {560--565},
publisher = {IEEE},
title = {{Multiscale depth local derivative pattern for sparse representation based 3D face recognition}},
url = {http://ieeexplore.ieee.org/document/8122665/},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{ISI:000374793400019,
abstract = {Face recognition in unconstrained environments is often influenced by pose variations. And the problem is basically the identification that uses partial data. In this paper, a method fusing structure and texture information is proposed to solve the problem. In the register phase, the approximate 180 degree information of face is acquired, and the data used to identify individual is obtained from a random single view. Pure face is extracted from 3D data first, then convert the original data to the form of spherical depth map (SDM) and spherical texture map (STM), which are invariant to out-plane rotation, subsequently facilitating the successive alignment-free identification that is robust to pose variations. We make identification through sparse representation for its well performance with the two maps. Experiments show that our proposed method gets a high recognition rate with pose and expression variations.},
annote = {- interessante a parte 3D, mas ele usa informa{\c{c}}{\~{a}}o de textura},
author = {Liu, Shuai and Mu, Zhichun and Huang, Hongbo},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-25417-3_19},
editor = {{Yang, J and Yang, J and Sun, Z and Shan, S and Zheng, W and Feng}, J},
file = {:home/tutu/artigos{\_}revisao/96d0de48ff0343e2beba214a7471fd14-liu2015.pdf:pdf},
isbn = {9783319254166},
issn = {16113349},
keywords = {Face recognition,Sparse representation,Spherical Depth Map,Spherical Texture Map,lerdepois,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutuix5},
mendeley-tags = {lerdepois,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutuix5},
organization = {Chinese Assoc Artificial Intelligence; Springer; Civil Aviat Univ China; Tianjin Univ Sci {\&} Technol; CASIA, Inst Intelligent Recognit},
pages = {151--159},
series = {Lecture Notes in Computer Science},
title = {{3D face recognition fusing spherical depth map and spherical texture map}},
volume = {9428},
year = {2015}
}
@inproceedings{Ganguly2016275,
abstract = {Face and facial attributes represent meaningful definition about a variety of information to discriminate an individual from others and for developing a computational model for automatic face recognition purpose. However, in this work, selection of relevant features from newly created face space is the pivotal contribution of the authors. Here, authors have demonstrated a new face space 'Complement Component' that have been used to extract the four basic components along X, and Y axes in four directions. Later, authors have experimented the discriminative attributes from these face spaces for recognition purpose. Here, comparison of the proposed method has been reported by examining its success on two well accepted 3D face databases, namely: Frav3D and Texas3D. In case of 2D face images, it does not contain depth like information i.e. Z-values in X-Y plane through intensity values. Therefore, it has not been undertaken during this investigation.},
annote = {cited By 1},
author = {Ganguly, Suranjan and Bhattachaijee, Debotosh and Nasipuri, Mita},
booktitle = {2015 IEEE International Conference on Computer Graphics, Vision and Information Security, CGVIS 2015},
doi = {10.1109/CGVIS.2015.7449936},
file = {:home/tutu/artigos{\_}revisao/07449936.pdf:pdf},
isbn = {9781467374378},
keywords = {3D face image,Complement Component,Face recognition,range face image,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {275--278},
title = {{3D face recognition from complement component range face images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966632732{\&}doi=10.1109{\%}2FCGVIS.2015.7449936{\&}partnerID=40{\&}md5=ac5698f1d98fa8b29941ffc837f84a7b},
year = {2016}
}
@article{Li:2018:EFR:3198485.3198687,
abstract = {This study proposes a 3D face recognition method using multiple subject-specific curves insensitive to intra-subject distortions caused by expression variations. Considering that most sharp variances in facial convex regions are closely related to the bone structure, the convex crest curves are first extracted as the most vital subject-specific facial curves based on the principal curvature extrema in convex local surfaces. Then, the central profile curve and the horizontal contour curve passing through the nose tip are detected by using the precise localization of the nose tip and symmetry plane. Based on their discriminative power and robustness to expression changes, the three types of curves are fused with appropriate weights at the feature-level and used for matching 3D faces with the iterative closest point algorithm. The combination of multiple expression-insensitive curves is complementary and provides sufficient and stable facial surface features for face recognition. In addition, for each convex crest curve, an expression-irrelevant factor is assigned as the adaptive weight to improve the face matching performance. The results of experiments using two public 3D databases, GavabDB and BU-3DFE, demonstrate the effectiveness of the proposed method, and its recognition rates on both databases reflect an encouraging performance.},
address = {Amsterdam, The Netherlands, The Netherlands},
annote = {29/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
29/04 Exclu{\'{i}}do (etapa 1)

Janeiro de 2018},
author = {Li, Ye and Wang, Ying Hui and Liu, Jing and Hao, Wen},
doi = {10.1016/j.neucom.2017.09.070},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Expression-insensitive 3D face recognition by the fusion of multiple subject-specific curves.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {3D face recognition,Expression-insensitive,Feature-level,Fusion,Subject-specific curve,acm,etapa1,id395,import{\_}poly,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,id395,import{\_}poly,poly,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {C},
pages = {1295--1307},
publisher = {Elsevier Science Publishers B. V.},
title = {{Expression-insensitive 3D face recognition by the fusion of multiple subject-specific curves}},
url = {https://doi.org/10.1016/j.neucom.2017.09.070},
volume = {275},
year = {2018}
}
@inproceedings{Li2018234,
abstract = {This paper presents a straight-forward yet efficient, and expression-robust 3D face recognition approach by explor- ing location sensitive sparse representation of deep normal patterns (DNP). In particular, given raw 3D facial surfaces, we first run 3D face pre-processing pipeline, including nose tip detection, face region cropping, and pose normaliza- tion. The 3D coordinates of each normalized 3D facial sur- face are then projected into 2D plane to generate geometry images, from which three images of facial surface normal components are estimated. Each normal image is then fed into a pre-trained deep face net to generate deep represen- tations of facial surface normals, i.e., deep normal pattern- s. Considering the importance of different facial locations, we propose a location sensitive sparse representation clas- sifier (LS-SRC) for similarity measure among deep normal patterns associated with different 3D faces. Finally, sim- ple score-level fusion of different normal components are used for the final decision. The proposed approach achieves significantly high performance, and reporting rank-one s- cores of 98.01{\%}, 97.60{\%}, and 96.13{\%} on the FRGC v2.0, Bosphorus, and BU-3DFE databases when only one sam- ple per subject is used in the gallery. These experimental results reveals that the performance of 3D face recognition would be constantly improved with the aid of training deep models from massive 2D face images, which opens the door for future directions of 3D face recognition.},
annote = {From Duplicate 1 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, Huibin; Sun, Jian; Chen, Liming)

From Duplicate 1 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, Huibin; Sun, Jian; Chen, Liming)

From Duplicate 1 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, H; Sun, J; Chen, L)

cited By 1

From Duplicate 2 (Location-Sensitive Sparse Representation of Deep Normal Patterns for Expression-robust 3D Face Recognition - Li, Huibin; Sun, Jian; Chen, Liming)

IEEE International Joint Conference on Biometrics (IJCB), Denver, CO,
OCT 01-04, 2017

From Duplicate 2 (Location-Sensitive Sparse Representation of Deep Normal Patterns for Expression-robust 3D Face Recognition - Li, Huibin; Sun, Jian; Chen, Liming)

IEEE International Joint Conference on Biometrics (IJCB), Denver, CO,
OCT 01-04, 2017

From Duplicate 2 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, H; Sun, J; Chen, L)

cited By 1

From Duplicate 3 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, Huibin; Sun, Jian; Chen, Liming)

IEEE International Joint Conference on Biometrics (IJCB), Denver, CO,
OCT 01-04, 2017

From Duplicate 4 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, Huibin; Sun, Jian; Chen, Liming)

From Duplicate 1 (Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition - Li, H; Sun, J; Chen, L)

cited By 1

From Duplicate 2 (Location-Sensitive Sparse Representation of Deep Normal Patterns for Expression-robust 3D Face Recognition - Li, Huibin; Sun, Jian; Chen, Liming)

IEEE International Joint Conference on Biometrics (IJCB), Denver, CO,
OCT 01-04, 2017},
author = {Li, Huibin and Sun, Jian and Chen, Liming},
booktitle = {IEEE International Joint Conference on Biometrics, IJCB 2017},
doi = {10.1109/BTAS.2017.8272703},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Sun, Chen - 2017 - Location-Sensitive Sparse Representation of Deep Normal Patterns for Expression-robust 3D Face Recognition.pdf:pdf},
isbn = {9781538611241},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {IEEE},
pages = {234--242},
title = {{Location-sensitive sparse representation of deep normal patterns for expression-robust 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046291057{\&}doi=10.1109{\%}2FBTAS.2017.8272703{\&}partnerID=40{\&}md5=e5c4065442f8bc899597efdc443ed01c},
volume = {2018-Janua},
year = {2018}
}
@article{Bellil:2016:GWN:2877705.2877756,
abstract = {{\textcopyright} 2014, Springer Science+Business Media New York. The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 {\%} which represents a competitive result compared to the state of the art.},
address = {Hingham, MA, USA},
annote = {22/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
22/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Bellil, Wajdi and Brahim, Hajer and {Ben Amar}, Chokri},
doi = {10.1007/s11042-014-2294-6},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellil, Brahim, Ben Amar - 2016 - Gappy wavelet neural network for 3D occluded faces detection and recognition.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {3D face recognition; Wavelets,Gappy data,Occlusion detection,Wavelet neural network,acm,etapa1,gil,id125,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id125,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {jan},
number = {1},
pages = {365--380},
publisher = {Kluwer Academic Publishers},
title = {{Gappy wavelet neural network for 3D occluded faces: detection and recognition}},
url = {http://dx.doi.org/10.1007/s11042-014-2294-6 http://link.springer.com/10.1007/s11042-014-2294-6},
volume = {75},
year = {2016}
}
@inproceedings{Galbally:2016:BSI:2982636.2982657,
abstract = {Biometric systems typically suffer a significant loss of performance when the acquisition sensor is changed between enrolment and authentication. Such a problem, commonly known as sensor interoperability, poses a serious challenge to the accuracy of matching algorithms. The present work addresses for the first time the sensor interoperability issue in 3D face recognition systems, analysing the performance of two popular and well known techniques for 3D facial authentication. For this purpose, a new gender-balanced database comprising 3D data of 26 subjects has been acquired using two devices belonging to the new generation of low-cost 3D sensors. The results show the high sensor-dependency of the tested systems and the need to develop matching algorithms robust to the variation in the sensor resolution.},
address = {Portugal},
annote = {13/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
13/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Galbally, Javier and Satta, Riccardo},
booktitle = {Proceedings of the 5th International Conference on Pattern Recognition Applications and Methods},
doi = {10.5220/0005682501990204},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galbally, Satta - 2016 - Biometric Sensor Interoperability A Case Study in 3D Face Recognition.pdf:pdf},
isbn = {978-989-758-173-1},
keywords = {3D Face Database.,3D Face Recognition,Interoperability,acm,etapa1,gil,id51,revisao{\_}V1,revisao{\_}scopus,tutui2},
mendeley-tags = {acm,etapa1,gil,id51,revisao{\_}V1,revisao{\_}scopus,tutui2},
pages = {199--204},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
series = {ICPRAM 2016},
title = {{Biometric Sensor Interoperability: A Case Study in 3D Face Recognition}},
url = {http://dx.doi.org/10.5220/0005682501990204},
year = {2016}
}
@article{Wei201766,
abstract = {In this paper, we propose a general 3D face recognition framework by combining the idea of surface harmonic mapping and deep learning. In particular, given a 3D face scan, we first run the pre-processing pipeline and detect three main facial landmarks (i.e., nose tip and two inner eye corners). Then, harmonic mapping is employed to map the 3D coordinates and differential geometry quantities (e.g., normal vectors, curvatures) of each 3D face scan to a 2D unit disc domain, generating a group of 2D harmonic shape images (HSI). The 2D rotation of the harmonic shape images are removed by using the three detected landmarks. All these pose normalized harmonic shape images are fed into a pre-trained deep convolutional neural network (DCNN) to generate their deep representations. Finally, sparse representation classifier with score-level fusion is used for face similarity measurement and the final decision. The advantage of our method is twofold: (i) it is a general framework and can be easily extended to other surface mapping and deep learning algorithms. (ii) it is registration-free and only needs three landmarks. The effectiveness of the proposed framework was demonstrated on the BU-3DFE database, and reporting a rank-one recognition rate of 89.38{\%} on the whole database. {\textcopyright} 2017, Springer International Publishing AG.},
annote = {cited By 0},
author = {Wei, Xiaofan and Li, Huibin and Gu, Xianfeng David},
doi = {10.1007/978-3-319-69923-3_8},
isbn = {9783319699226},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3D face recognition,Deep learning,Surface harmonic mapping,revisao{\_}V2,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutui1},
pages = {66--76},
title = {{Three Dimensional Face Recognition via Surface Harmonic Mapping and Deep Learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032656852{\&}doi=10.1007{\%}2F978-3-319-69923-3{\_}8{\&}partnerID=40{\&}md5=598d2aabb96d1b2d7f9963542a2fcddf},
volume = {10568 LNCS},
year = {2017}
}
@article{Emambakhsh2017,
abstract = {The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm. https://github.com/mehryaragha/NoseBiometrics},
author = {Emambakhsh, Mehryar and Evans, Adrian},
doi = {10.1109/TPAMI.2016.2565473},
file = {:home/tutu/artigos{\_}revisao/07467565.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Face recognition,Gabor wavelets,facial landmarking,feature selection,nose region,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,surface normals,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {may},
number = {5},
pages = {995--1007},
title = {{Nasal Patches and Curves for Expression-Robust 3D Face Recognition}},
url = {http://ieeexplore.ieee.org/document/7467565/},
volume = {39},
year = {2017}
}
@inproceedings{Soltanpour20182811,
abstract = {{\textcopyright} 2017 IEEE. This paper proposes a novel descriptor based on the local derivative pattern (LDP) for 3D face recognition. Compared to the local binary pattern (LBP), LDP can capture more detailed information by encoding directional pattern features. It is based on the local derivative variations that extract high-order local information. We propose a novel discriminative facial shape descriptor, local normal derivative pattern (LNDP) that extracts LDP from the surface normal. Using surface normal, the orientation of a surface at each point is determined as a first-order surface differential. Three normal component images are extracted by estimating three components of normal vectors in x, y, and z channels. Each normal component is divided into several patches and encoded using LDP. The final descriptor is created by concatenating histograms of the LNDP on each patch. Experimental results on two famous 3D face databases, FRGC v2.0 and Bosphorus illustrate the effectiveness of the proposed descriptor.},
annote = {cited By 1},
author = {Soltanpour, Sima and Wu, Q. M.Jonathan},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2017.8296795},
isbn = {9781509021758},
issn = {15224880},
keywords = {3D face,High-order local pattern,Local derivative pattern,Surface normal,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
pages = {2811--2815},
title = {{High-order local normal derivative pattern (LNDP) for 3D face recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045292850{\&}doi=10.1109{\%}2FICIP.2017.8296795{\&}partnerID=40{\&}md5=12c33512c432220af4c4c49f5116433e},
volume = {2017-Septe},
year = {2018}
}
@article{ISI:000410465400003,
abstract = {In this paper, we introduce a novel, automatic method for 3D face
recognition. A new feature called a spherical vector norms map of a 3D
face is created using the normal vector of each point. This feature
contains more detailed information than the original depth image in
regions such as the eyes and nose. For certain flat areas of 3D face,
such as the forehead and cheeks, this map could increase the
distinguishability of different points. In addition, this feature is
robust to facial expression due to an adjustment that is made in the
mouth region. Then, the facial representations, which are based on
Histograms of Oriented Gradients, are extracted from the spherical
vector norms map and the original depth image. A new partitioning
strategy is proposed to produce the histogram of eight patches of a
given image, in which all of the pixels are binned based on the
magnitude and direction of their gradients. In this study, SVNs map and
depth image are represented compactly with two histograms of oriented
gradients; this approach is completed by Linear Discriminant Analysis
and a Nearest Neighbor classifier.},
author = {Wang, Xue Qiao and Yuan, Jia Zheng and Li, Qing},
doi = {10.6688/JISE.2017.33.5.3},
issn = {10162364},
journal = {Journal of Information Science and Engineering},
keywords = {3D face recognition,Face recognition grand challenge database,Histograms of oriented gradients,Linear discriminant analysis,Spherical vector norms map,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {5},
pages = {1141--1161},
title = {{3D face recognition using spherical vector norms map}},
volume = {33},
year = {2017}
}
@inproceedings{8227850,
abstract = {Face recognition remains a challenge today as recognition performance is strongly affected by variability such as illumination, expressions and poses. In this work we apply Convolutional Neural Networks (CNNs) on the challenging task of both 2D and 3D face recognition. We constructed two CNN models, namely CNN-1 (two convolutional layers) and CNN-2 (one convolutional layer) for testing on 2D and 3D dataset. A comprehensive parametric study of two CNN models on face recognition is represented in which different combinations of activation function, learning rate and filter size are investigated. We find that CNN-2 has a better accuracy performance on both 2D and 3D face recognition. Our experimental results show that an accuracy of 85.15{\%} was accomplished using CNN-2 on depth images with FRGCv2.0 dataset (4950 images with 557 objectives). An accuracy of 95{\%} was achieved using CNN-2 on 2D raw image with the AT{\&}T dataset (400 images with 40 objectives). The results indicate that the proposed CNN model is capable to handle complex information from facial images in different dimensions. These results provide valuable insights into further application of CNN on 3D face recognition.},
annote = {26/04 em processo
26/04 exclus{\~{a}}o},
author = {Hu, Huiying and Shah, Syed Afaq Ali and Bennamoun, Mohammed and Molton, Michael},
booktitle = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
doi = {10.1109/TENCON.2017.8227850},
file = {:home/tutu/artigos{\_}revisao/08227850.pdf:pdf},
isbn = {9781509011339},
issn = {21593450},
keywords = {Convolutional Neural Networks,Depth Image,Face Recognition,etapa1,id314,ieeexplore,poly,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {etapa1,id314,ieeexplore,poly,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {nov},
pages = {133--138},
title = {{2D and 3D face recognition using convolutional neural network}},
volume = {2017-Decem},
year = {2017}
}
@inproceedings{ISI:000367310300024,
abstract = {Expression change is the major cause of local plastic deformation of the facial surface. The intra-class differences with large expression change somehow are larger than the inter-class differences as it's difficult to distinguish the same individual with facial expression change. In this paper, an expression-robust 3D face recognition method is proposed by learning expression deformation model. The expression of the individuals on the training set is modeled by principal component analysis, the main components are retained to construct the facial deformation model. For the test 3D face, the shape difference between the test and the neutral face in training set is used for reconstructing the expression change by the constructed deformation model. The reconstruction residual error is used for face recognition. The average recognition rate on GavabDB and self-built database reaches 85.1{\%} and 83{\%}, respectively, which shows strong robustness for expression changes.},
annote = {7th International Conference on Graphic and Image Processing (ICGIP),
Singapore, SINGAPORE, OCT 23-25, 2015},
author = {Guo, Zhe and Liu, Shu and Wang, Yi and Lei, Tao},
booktitle = {Seventh International Conference on Graphic and Image Processing (ICGIP 2015)},
doi = {10.1117/12.2228002},
editor = {{Wang, Y and Jiang}, X},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2015 - Learning deformation model for expression-robust 3D face recognition.pdf:pdf},
isbn = {978-1-5106-0058-4},
issn = {0277-786X},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Wuhan Univ; Int Assoc Comp Sci {\&} Informat Technol},
pages = {98170O},
series = {Proceedings of SPIE},
title = {{Learning deformation model for expression-robust 3D face recognition}},
volume = {9817},
year = {2015}
}
@article{Gilani:2017:DDA:3103259.3103504,
abstract = {We present a multilinear algorithm to automatically establish dense point-to-point correspondence over an arbitrarily large number of population specific 3D faces across identities, facial expressions and poses. The algorithm is initialized with a subset of anthropometric landmarks detected by our proposed Deep Landmark Identification Network which is trained on synthetic images. The landmarks are used to segment the 3D face into Voronoi regions by evolving geodesic level set curves. Exploiting the intrinsic features of these regions, we extract discriminative keypoints on the facial manifold to elastically match the regions across faces for establishing dense correspondence. Finally, we generate a Region based 3D Deformable Model which is fitted to unseen faces to transfer the correspondences. We evaluate our algorithm on the tasks of facial landmark detection and recognition using two benchmark datasets. Comparison with thirteen state-of-the-art techniques shows the efficacy of our algorithm.},
address = {New York, NY, USA},
annote = {18/05/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
18/05/2018 Exclu{\'{i}}do (etapa 1)},
author = {Gilani, Syed Zulqarnain and Mian, Ajmal and Eastwood, Peter},
doi = {10.1016/j.patcog.2017.04.013},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilani, Mian, Eastwood - 2017 - Deep, dense and accurate 3D face correspondence for generating population specific deformable models.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D face morphing,Deep learning,Dense 3D face correspondence,Face recognition,Keypoint detection,Landmark identification,Shape descriptor,acm,estela,etapa1,id488,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id488,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {sep},
number = {C},
pages = {238--250},
publisher = {Elsevier Science Inc.},
title = {{Deep, dense and accurate 3D face correspondence for generating population specific deformable models}},
url = {https://doi.org/10.1016/j.patcog.2017.04.013 http://linkinghub.elsevier.com/retrieve/pii/S0031320317301644},
volume = {69},
year = {2017}
}
@inproceedings{ISI:000444905600019,
abstract = {In this paper, we present an efficient method for 3D face recognition based on vector quantization of both geometrical and visual proprieties of the face. The method starts by describing each 3D face using a set of orderless features, and use then the Bag-of-Features paradigm to construct the face signature. We analyze the performance of three well-known classifiers: the Naive Bayes, the Multilayer perceptron and the Random forests. The results reported on the FRGCv2 dataset show the effectiveness of our approach and prove that the method is robust to facial expression.},
annote = {12th International Joint Conference on Computer Vision, Imaging and
Computer Graphics Theory and Applications (VISIGRAPP), Porto, PORTUGAL,
FEB 27-MAR 01, 2017},
author = {Hariri, Walid and Tabia, Hedi and Farah, Nadir and Declercq, David and Benouareth, Abdallah},
booktitle = {PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5},
doi = {10.5220/0006101701870193},
editor = {{Imai, F and Tremeau, A and Braz}, J},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hariri et al. - 2017 - Geometrical and Visual Feature Quantization for 3D Face Recognition.pdf:pdf},
isbn = {978-989-758-226-4},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {Inst Syst {\&} Technologies Informat, Control {\&} Commun; ACM SIGGRAPH; AFIG; Eurographics},
pages = {187--193},
title = {{Geometrical and Visual Feature Quantization for 3D Face Recognition}},
year = {2017}
}
@inproceedings{ISI:000371977803154,
abstract = {A 3D face recognition method using region-based extended local binary pattern (eLBP) is proposed. First, the depth image converted from the preprocessed 3D pointclouds is normalized. Then, different regions according to their distortions under facial expressions are extracted by binary masks and represented by the uniform pattern of extended LBP. Finally, sparse representation classifier (SRC) is adopted for classification on the single region. Feature-level and score-level fusion with weight-sparse representation classifier (W-SRC) are also tested and compared, and the latter has better performance. The experiments on FRGC v2.0 database demonstrate that the proposed method is robust and efficient.},
annote = {IEEE International Conference on Image Processing (ICIP), Quebec City,
CANADA, SEP 27-30, 2015},
author = {Lv, Shiwen and Da, Feipeng and Deng, Xing},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2015.7351482},
file = {:home/tutu/artigos{\_}revisao/07351482.pdf:pdf},
isbn = {9781479983391},
issn = {15224880},
keywords = {3D face recognition,binary mask,depth image,extended local binary pattern,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1,weight-sparse representation classifier},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {sep},
organization = {Inst Elect {\&} Elect Engineers; IEEE Signal Proc Soc},
pages = {3635--3639},
publisher = {IEEE},
series = {IEEE International Conference on Image Processing ICIP},
title = {{A 3D face recognition method using region-based extended local binary pattern}},
url = {http://ieeexplore.ieee.org/document/7351482/},
volume = {2015-Decem},
year = {2015}
}
@article{Hajati2019936,
abstract = {{\textcopyright} 2019, Springer Nature Switzerland AG. We propose Polar Topographic Derivatives (PTD) to fuse the shape and texture information of a facial surface for 3D face recognition. Polar Average Absolute Deviations (PAADs) of the Gabor topography maps are extracted as features. High-order polar derivative patterns are obtained by encoding texture variations in a polar neighborhood. By using the and Bosphorus 3D face database, our method shows that it is robust to expression and pose variations comparing to existing state-of-the-art benchmark approaches.},
annote = {cited By 0},
author = {Hajati, Farshid and Cheraghian, Ali and {Ameri Sianaki}, Omid and Zeinali, Behnam and Gheisari, Soheila},
doi = {10.1007/978-3-030-15035-8_92},
isbn = {9783030150341},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {revisao{\_}V2,revisao{\_}scopus,tutux5},
mendeley-tags = {revisao{\_}V2,revisao{\_}scopus,tutux5},
pages = {936--945},
title = {{Polar Topographic Derivatives for 3D Face Recognition: Application to Internet of Things Security}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064875340{\&}doi=10.1007{\%}2F978-3-030-15035-8{\_}92{\&}partnerID=40{\&}md5=a1997efd234042ace42c04b05607ab05},
volume = {927},
year = {2019}
}
@inproceedings{Xie:2016:IFR:3028842.3028853,
abstract = {Automatic face recognition techniques applied on particular group or mass database introduces error cases. Error prevention is crucial for the court. Reranking of recognition results based on anthropology analysis can significant improve the accuracy of automatic methods. Previous studies focused on manual facial comparison. This paper proposed a weighted facial similarity computing method based on morphological analysis of components characteristics. Search sequence of face recognition reranked according to similarity, while the interference terms can be removed. Within this research project, standardized photographs, surveillance videos, 3D face images, identity card photographs of 241 male subjects from China were acquired. Sequencing results were modified by modeling selected individual features from the DMV altas. The improved method raises the accuracy of face recognition through anthroposophic or morphologic theory.},
address = {New York, New York, USA},
author = {Xie, Lanchi and Xu, Lei and Zhang, Ning and Guo, Jingjing and Yan, Yuwen and Li, Zhihui and Li, Zhigang and Xu, Xiaojing},
booktitle = {Proceedings of the 2016 International Conference on Intelligent Information Processing - ICIIP '16},
doi = {10.1145/3028842.3028853},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2017 - Improved face recognition result reranking based on shape contexts.pdf:pdf},
isbn = {9781450347990},
keywords = {face recognition,reranking,revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,shape contexts,shape matching,similarity calculation,tutux3,tutux5},
mendeley-tags = {revisao{\_}V1,revisao{\_}acm,revisao{\_}scopus,tutux3,tutux5},
pages = {1--6},
publisher = {ACM Press},
series = {ICIIP '16},
title = {{Improved face recognition result reranking based on shape contexts}},
url = {http://doi.acm.org/10.1145/3028842.3028853 http://dl.acm.org/citation.cfm?doid=3028842.3028853},
year = {2017}
}
@inproceedings{ISI:000380429100020,
abstract = {? 2015 IEEE.With the increasing availability of low-cost 3D data acquisition devices, the use of 3D face data for the recognition of individuals is becoming more appealing and computationally feasible. This paper proposes a completely automatic algorithm for face registration and matching. The algorithm is based on the extraction of stable 3D facial features characterizing the face and the subsequent construction of a signature manifold. The facial features are extracted by performing a continuous-to-discrete scale-space analysis. Registration is driven from the matching of triplets of feature points and the registration error is computed as shape matching score. Conversely to most techniques in the literature, a major advantage of the proposed method is that no data pre-processing is required. Therefore all presented results have been obtained exclusively from the raw data available from the 3D acquisition device. The method has been tested on the Bosphorus 3D face database and the performances compared to the ICP baseline algorithm. Even in presence of noise in the data, the algorithm proved to be very robust and reported identification performances which are aligned to the current state of the art, but without requiring any pre-processing of the raw data.},
annote = {2015 3rd International Workshop on Biometrics and Forensics (IWBF),
Gjovik, NORWAY, MAR 03-04, 2015},
author = {Lagorio, A. and Cadoni, M. and Grosso, E. and Tistarelli, M.},
booktitle = {3rd International Workshop on Biometrics and Forensics, IWBF 2015},
doi = {10.1109/IWBF.2015.7110239},
file = {:home/tutu/artigos{\_}revisao/07110239.pdf:pdf},
isbn = {9781479981052},
keywords = {3D Face recognition,Face recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {mar},
organization = {European Cooperat Sci {\&} Technol; IEEE; COST Act IC1106; Inst Engn {\&} Technol; European Assoc Signal Proc; European Assoc Biometr; HOGSKOLEN},
pages = {1--7},
publisher = {IEEE},
title = {{A 3D algorithm for unsupervised face identification}},
url = {http://ieeexplore.ieee.org/document/7110239/},
year = {2015}
}
@inproceedings{8269662,
abstract = {Facial recognition has most significant real-life requests like investigation and access control. It is associated through the issue of appropriately verifying face pictures and transmit them person in a database. In a past years face study has been emerging active topic. Most of the face detector techniques could be classified into feature based methods and image based also. Feature based techniques adds low-level analysis, feature analysis, etc. Facial recognition is a system capable of verifying / identifying a human after 3D images. By evaluating selected facial unique features from the image and face dataset. Design from transformation method given vector dimensional illustration of individual face in a prepared set of images, Principle component analysis inclines to search a dimensional sub-space whose normal vector features correspond to the maximum variance direction in the real image space. The PCA algorithm evaluates the feature extraction, data, i.e. Eigen Values and vectors of the scatter matrix. In literature survey, Face recognition is a design recognition mission performed exactly on faces. It can be described as categorizing a facial either “known” or “unknown”, after comparing it with deposits known individuals. It is also necessary to need a system that has the capability of knowledge to recognize indefinite faces. Computational representations of facial recognition must statement various difficult issues. After existing work, we study the SIFT structures for the gratitude method. The novel technique is compared with well settled facial recognition methods, name component analysis and eigenvalues and vector. This algorithm is called PCA and ICA (Independent Component Analysis). In research work, we implement the novel approach to detect the face in minimum time and evaluate the better accuracy based on Back Propagation Neural Networks. We design the framework in face recognition using MATLAB 2013a simulation tool. Evaluate the performance parameters, i.e. the FAR (false acceptance rate), FRR (False rejection Rate) and Accuracy and compare the existing performance parameters i.e. accuracy.},
author = {Kaur, Rajwant and Sharma, Dolly and Verma, Amit},
booktitle = {4th IEEE International Conference on Signal Processing, Computing and Control, ISPCC 2017},
doi = {10.1109/ISPCC.2017.8269662},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaur, Sharma, Verma - 2017 - An advance 2D face recognition by feature extraction (ICA) and optimize multilayer architecture.pdf:pdf},
isbn = {9781509058389},
keywords = {Eigen values and Vectors,Face recognition,Features of face,Neural Network,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
pages = {122--129},
title = {{An advance 2D face recognition by feature extraction (ICA) and optimize multilayer architecture}},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Reji2018,
abstract = {This paper focuses on a region based methodology for expression in
sensitive 3D face recognition process. Considering facial regions that
are comparatively unchanging during expressions, results shows that
using fifteen sub regions on the face can attain high 3D face
recognition. We use a modified face recognition algorithm along with
hierarchical contour based image registration for finding the similarity
score. Our method operates in two modes: verification mode and
confirmation mode. Crop 100 mm of frontal face region, apply
preprocessing and automatically detect nose tip, translate the face
image to origin and crop fifteen sub regions. The cropped sub regions
are defined by cuboids which occupy more volumetric data, Nose Tip is
the most projecting point of the face with the highest value along
Z-axis so consider it as origin. The modified face recognition algorithm
reduces the effects caused by facial expressions and artifacts. Finally
a Hierarchical contour based image registration technique is applied
which yields better results. The approach is applied on Bosphorus 3D
datasets and achieved a verification rate of 95.3{\%} at 0.1{\%} false
acceptance rate. In the identification scenario 99.3{\%} rank one
recognition is achieved.},
annote = {cited By 0},
author = {Reji, R. and Sojanlal, P.},
booktitle = {2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
doi = {10.1109/ICCIC.2017.8524581},
file = {:home/tutu/artigos{\_}revisao/08524581.pdf:pdf},
isbn = {9781509066209},
keywords = {3D face recognition,Biometrics,Contour based image registration,MFRA,Rank based Score,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
title = {{Region Based 3D Face Recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057946157{\&}doi=10.1109{\%}2FICCIC.2017.8524581{\&}partnerID=40{\&}md5=92c092fa4e2838ab444fcc0356fcdb75},
year = {2018}
}
@article{Siqueira2018,
abstract = {una propuesta did{\'{a}}ctica fundamentara para la educacion cient{\'{i}}ficas de jovenes de 15 a 18 a{\~{n}}os},
author = {Siqueira, Robson S. and Alexandre, Gilderlane R. and Soares, Jose M. and The, George A. P.},
doi = {10.1109/lra.2018.2854295},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siqueira et al. - 2018 - Triaxial Slicing for 3-D Face Recognition From Adapted Rotational Invariants Spatial Moments and Minimal Keypoi.pdf:pdf},
issn = {2377-3766},
journal = {IEEE Robotics and Automation Letters},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {oct},
number = {4},
pages = {3513--3520},
title = {{Triaxial Slicing for 3-D Face Recognition From Adapted Rotational Invariants Spatial Moments and Minimal Keypoints Dependence}},
url = {https://ieeexplore.ieee.org/document/8408720/},
volume = {3},
year = {2018}
}
@inproceedings{7453907,
abstract = {In this paper, we introduce a new feature named spherical vector norms for 3D face recognition. The proposed feature is efficient, insensitive to facial expression and contains discriminatory information of 3D face. The feature extraction method is firstly finding a set of the points with the closest distance to the standard face, denoted as closest point coordinates, and then extracting the spherical vector norms of these points. This paper combines point coordinates and spherical vector norms for improving recognition. Finally this approach is finished by Linear Discriminant Analysis (LDA) and Nearest Neighbor classifier. We have performed different experiments on the Face Recognition Grand Challenge database. It achieves the verification rate of 97.11{\%} on All vs. All experiment at 0.1{\%} FAR and 96.64{\%} verification rate on Neutral vs. Expression experiment.},
annote = {28/04 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
28/04 Exclu{\'{i}}do (etapa 1)},
author = {{Gaoyun An} and {Yi Jin} and {Xueqiao Wang} and {Qiuqi Ruan}},
booktitle = {6th International Conference on Wireless, Mobile and Multi-Media (ICWMMN 2015)},
doi = {10.1049/cp.2015.0943},
isbn = {978-1-78561-046-2},
keywords = {etapa1,face recognition,feature extraction,id356,ieeexplore,image classifi,poly,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {etapa1,id356,ieeexplore,poly,revisao{\_}V1,revisao{\_}scopus,tutui1},
month = {nov},
pages = {5 .--5 .},
publisher = {Institution of Engineering and Technology},
title = {{3D face recognition using closest point coordinates and spherical vector norms}},
url = {https://digital-library.theiet.org/content/conferences/10.1049/cp.2015.0943},
year = {2016}
}
@inproceedings{8314888,
abstract = {This manuscript introduces a novel 3D face authentication system inspired from the advantageous capacities of Gabor-Edge filters. The approach studies 3D face difficulties such as expression variety, different rotations and exposure to illuminations. The proposed systems starts by preprocessing the 3D face images to resolve acquisition problems. Then, a filtering process is performed by implanting our 3D Gabor-Edge technique extended based on the classic 3D Gabor masks. The next step is to achieve the classification of facial features from the edge saliency by the artificial Neural Network Classifier (NNC). The evaluation of the adopted system is achieved by exporting common datasets from GavabDB database. Experimental results are reported to prove the high accuracy rates of our method compared to the recent researches in the same biometric field.},
annote = {05/06/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
05/06/2018 Exclu{\'{i}}do (etapa 1)},
author = {Torkhani, Ghada and Ladgham, Anis and Sakly, Anis},
booktitle = {2017 18th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering, STA 2017 - Proceedings},
doi = {10.1109/STA.2017.8314888},
file = {:home/tutu/artigos{\_}revisao/08314888.pdf:pdf},
isbn = {9781538610848},
keywords = {3D images,Face authentication,Gabor filtering,Saliency,estela,etapa1,fatima,id511,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {estela,etapa1,fatima,id511,ieeexplore,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
pages = {578--582},
title = {{3D gabor-edge filters applied to face depth images}},
volume = {2018-Janua},
year = {2018}
}
@article{ISI:000463462600049,
abstract = {Extracting efficient features from the large volume of 3D facial data directly is extremely difficult in 3D face recognition (3D-FR) with the latest methods, which mostly require heavy computations and manual processing steps. This paper presents a computationally efficient 3D-FR system based on a novel Frenet frame-based feature that is derived from the 3D facial iso-geodesic curves. In terms of the evaluation of the proposed method, we conducted a number of experiments on the CASIA 3D face database, and a superior recognition performance has been achieved. The performance evaluation suggests that the pose invariance attribute of the features relieves the need of an expensive 3D face registration in the face preprocessing procedure, where we take less time to process conversely. Our experiments further demonstrate that the proposed method not only achieves competitive recognition performance when compared with some existing techniques for 3D-FR, but also is computationally efficient.},
author = {Shi, Biao and Zang, Huaijuan and Zheng, Rongsheng and Zhan, Shu},
doi = {10.1016/j.jvcir.2019.02.002},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi et al. - 2019 - An efficient 3D face recognition approach using Frenet feature of iso-geodesic curves.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {3D face recognition,Facial curves,Frenet framework,Iso-geodesic,Pose invariant,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui2},
pages = {455--460},
title = {{An efficient 3D face recognition approach using Frenet feature of iso-geodesic curves}},
volume = {59},
year = {2019}
}
@article{ISI:000351796000002,
abstract = {3D face recognition and emotion analysis play important roles in many fields of communication and edutainment. An effective facial descriptor, with higher discriminating capability for face recognition and higher descriptiveness for facial emotion analysis, is a challenging issue. However, in the practical applications, the descriptiveness and discrimination are independent and contradictory to each other. 3D facial data provide a promising way to balance these two aspects. In this paper, a robust regional bounding spherical descriptor (RBSR) is proposed to facilitate 3D face recognition and emotion analysis. In our framework, we first segment a group of regions on each 3D facial point cloud by shape index and spherical bands on the human face. Then the corresponding facial areas are projected to regional bounding spheres to obtain our regional descriptor. Finally, a regional and global regression mapping (RGRM) technique is employed to the weighted regional descriptor for boosting the classification accuracy. Three largest available databases, FRGC v2, CASIA and BU-3DFE, are contributed to the performance comparison and the experimental results show a consistently better performance for 3D face recognition and emotion analysis.},
author = {Ming, Yue},
doi = {10.1016/j.imavis.2014.12.003},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ming - 2015 - Robust regional bounding spherical descriptor for 3D face recognition and emotion analysis.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {3D face recognition,Emotion analysis,Kullback-Leiber divergence (KLD),Regional and global regression,Regional bounding spherical descriptor,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {mar},
pages = {14--22},
title = {{Robust regional bounding spherical descriptor for 3D face recognition and emotion analysis}},
volume = {35},
year = {2015}
}
@article{ISI:000395034500021,
abstract = {{\textcopyright} 2016 American Academy of Forensic SciencesTechniques of 2D–3D superimposition are widely used in cases of personal identification from video surveillance systems. However, the progressive improvement of 3D image acquisition technology will enable operators to perform also 3D–3D facial superimposition. This study aims at analyzing the possible applications of 3D–3D superimposition to personal identification, although from a theoretical point of view. Twenty subjects underwent a facial 3D scan by stereophotogrammetry twice at different time periods. Scans were superimposed two by two according to nine landmarks, and root-mean-square (RMS) value of point-to-point distances was calculated. When the two superimposed models belonged to the same individual, RMS value was 2.10 mm, while it was 4.47 mm in mismatches with a statistically significant difference (p {\textless} 0.0001). This experiment shows the potential of 3D–3D superimposition: Further studies are needed to ascertain technical limits which may occur in practice and to improve methods useful in the forensic practice.},
author = {Gibelli, Daniele and {De Angelis}, Danilo and Poppa, Pasquale and Sforza, Chiarella and Cattaneo, Cristina},
doi = {10.1111/1556-4029.13290},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gibelli et al. - 2017 - A View to the Future A Novel Approach for 3D–3D Superimposition and Quantification of Differences for Identifi.pdf:pdf},
issn = {15564029},
journal = {Journal of Forensic Sciences},
keywords = {forensic anatomy,forensic anthropology,forensic science,personal identification,revisao{\_}V2,revisao{\_}webofscience,stereophotogrammetry,tutux9,video surveillance system},
mendeley-tags = {revisao{\_}V2,revisao{\_}webofscience,tutux9},
month = {mar},
number = {2},
pages = {457--461},
title = {{A View to the Future: A Novel Approach for 3D-3D Superimposition and Quantification of Differences for Identification from Next-Generation Video Surveillance Systems}},
volume = {62},
year = {2017}
}
@inproceedings{7424213,
abstract = {This work proposes a new algorithm for 3D face recognition. The algorithm uses 3D shape data without color or texture information and exploits local curvature information which is a measure with high discriminant capability and robust to deformations such as rotation and scaling. In order to reduce high dimensionality of typical face surfaces our approach uses a conformal parameterization, preserving angles of original faces and simplifies the correspondence problem. Experimental results are presented and discussed using CASIA and Gavab databases.},
annote = {From Duplicate 2 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

From Duplicate 1 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

cited By 20

From Duplicate 2 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

From Duplicate 1 (Conformal parameterization and curvature analysis for 3D facial recognition - Echeagaray-Patron, B A; Miramontes-Jaramillo, D; Kober, V)

cited By 20},
author = {Echeagaray-Patron, B A and Miramontes-Jaramillo, D and Kober, V},
booktitle = {2015 International Conference on Computational Science and Computational Intelligence (CSCI)},
doi = {10.1109/CSCI.2015.133},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Echeagaray-Patron, Miramontes-Jaramillo, Kober - 2015 - Conformal Parameterization and Curvature Analysis for 3D Facial Recognition.pdf:pdf},
keywords = {3D facial recogn,face recognition,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1,visual databases},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
pages = {843--844},
title = {{Conformal Parameterization and Curvature Analysis for 3D Facial Recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964412211{\&}doi=10.1109{\%}2FCSCI.2015.133{\&}partnerID=40{\&}md5=6a3fc9e7dac95a6f25aacc425aa40af5},
year = {2016}
}
@article{ISI:000457666900036,
abstract = {We propose a novel method for measuring the nasal similarity among 3D faces. Firstly, we construct a representation for the nose shape, which is composed of a set of geodesic curves, each crosses the bridge of the nose. Next, using these geodesic curves, we formulate a similarity measure to compare among noses in the curve shape space. Under the Riemannian framework, the shape space is a quotient space for which the scaling, translation and rotation are removed. Since the nose similarity measure is based on the shape comparison, the proposed method has the following advantages: (1) the similarity measure is robust to facial expressions since the nose is not affected by facial expressions; (2) the geometric features of the nose shape match well with the human perception; (3) the similarity measure is independent of the mesh grid because the chosen nose curves are not sensitive to the triangular mesh model. We construct a nasal hierarchical structure for noses organization which is based on nose similarity measure results. In our experiments, we evaluate the performance of the proposed method and compare it with competing methods on three public face databases namely, FRGC2.0, Texas3D and BosphorusDB. The results show superiority of the proposed method in terms of both the speed and the accuracy when the nasal measurements are processed in the nasal hierarchical structure and the nasal samples with low sampling rate (5{\%}-25{\%} of original point cloud).},
author = {Lv, Chenlei and Wu, Zhongke and Wang, Xingce and Zhou, Mingquan and Toh, Kar Ann},
doi = {10.1016/j.patcog.2018.12.006},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lv et al. - 2019 - Nasal similarity measure of 3D faces based on curve shape space.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Nose similarity measure,Riemannian manifold,Shape space,revisao{\_}V1,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}webofscience,tutui1},
pages = {458--469},
title = {{Nasal similarity measure of 3D faces based on curve shape space}},
volume = {88},
year = {2019}
}
@inproceedings{7443802,
abstract = {Face recognition has broad excitement in the latest trend in image processing. Face recognition refers to identify a specific individual in digital image by analyzing and comparing patterns. It has numerous benefits which attract every sector but there are some issues such as more time consumption and lesser accuracy which degrade the user services. To solve this problem we proposed a highly accurate and fast method to reduce the execution time. The proposed method uses average half face approach because overall system's accuracy is better in it rather than using the original full face image. The proposed method can be used to recognize both 2D and 3D images. It mainly includes the average half face creation, feature detection, full face recognition through average half face using distance metrics and finally checking system's accuracy along with time consumption. The proposed method is based on eye, nose and mouth detection.},
author = {Arora, Sourabh and Chawla, Shikha},
booktitle = {12th IEEE International Conference Electronics, Energy, Environment, Communication, Computer, Control: (E3-C3), INDICON 2015},
doi = {10.1109/INDICON.2015.7443802},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora, Chawla - 2015 - An intensified approach to face recognition through average half face.pdf:pdf},
isbn = {9781467373999},
issn = {2325-9418},
keywords = {Accuracy,Average half face,Distance metrics,Face recognition,Image processing,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}webofscience,tutui1},
month = {dec},
pages = {1--6},
title = {{An intensified approach to face recognition through average half face}},
year = {2016}
}
@inproceedings{ISI:000364714000046,
abstract = {In this work, we take advantage of the superiority of Spectral Graph
Theory in classification application and propose a novel deep learning
framework for face analysis which is called Spectral Regression
Discriminant Analysis Network (SRDANet). Our SRDANet model shares the
same basic architecture of Convolutional Neural Network (CNN), which
comprises three basic components: convolutional filter layer, nonlinear
processing layer and feature pooling layer. While it is different from
traditional deep learning network that in our convolutional layer, we
extract the leading eigenvectors from patches in facial image which are
used as filter kernels instead of randomly initializing kernels and
update them by stochastic gradient descent (SGD). And the output of all
cascaded convolutional filter layers is used as the input of nonlinear
processing layer. In the following nonlinear processing layer, we use
hashing method for nonlinear processing. In feature pooling layer, the
block-based histograms are employed to pooling output features instead
of max-pooling technique. At last, the output of feature pooling layer
is considered as one final feature output of our model. Different from
the previous single-task research for face analysis, our proposed
approach demonstrates an excellent performance in face recognition and
expression recognition with 2D/3D facial images simultaneously.
Extensive experiments conducted on many different face analysis
databases demonstrate the efficiency of our proposed SRDANet model.
Databases such as Extended Yale B, PIE, ORL are used for 2D face
recognition, FRGC v2 is used for 3D face recognition and BU-3DFE is used
for 3D expression recognition.},
annote = {8th International Conference on Intelligent Robotics and Applications
(ICIRA), Portsmouth, ENGLAND, AUG 24-27, 2015},
author = {Tian, Lei and Fan, Chunxiao and Ming, Yue and Shi, Jiakun},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-22879-2_46},
editor = {{Liu, H and Kubota, N and Zhu, X and Dillmann, R and Zhou}, D},
file = {:home/tutu/artigos{\_}revisao/2e5dfc3fcd722a16a71b8b2b2afa5cfe-tian2015.pdf:pdf},
isbn = {978-3-319-22879-2; 978-3-319-22878-5},
issn = {16113349},
keywords = {Deep learning,Expression recognition,Face recognition,SRDA network,Spectral regression discriminant analysis,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {499--510},
series = {Lecture Notes in Artificial Intelligence},
title = {{SRDANet: An efficient deep learning algorithm for face analysis}},
volume = {9244},
year = {2015}
}
@inproceedings{Echeagaray-Patrón2015,
abstract = {Face recognition is an important task in pattern recognition and computer vision. In this work a method for 3D face recognition in the presence of facial expression and poses variations is proposed. The method uses 3D shape data without color or texture information. A new matching algorithm based on conformal mapping of original facial surfaces onto a Riemannian manifold followed by comparison of conformal and isometric invariants computed in the manifold is suggested. Experimental results are presented using common 3D face databases that contain significant amount of expression and pose variations.},
annote = {From Duplicate 1 (3D face recognition based on matching of facial surfaces - Echeagaray-Patr{\'{o}}n, Beatriz A.; Kober, Vitaly)

From Duplicate 2 (3D face recognition based on matching of facial surfaces - Echeagaray-Patr{\'{o}}n, B A; Kober, V)

cited By 14

From Duplicate 2 (3D face recognition based on matching of facial surfaces - Echeagaray-Patr{\'{o}}n, Beatriz A.; Kober, Vitaly)

cited By 14},
author = {Echeagaray-Patr{\'{o}}n, Beatriz A. and Kober, Vitaly},
booktitle = {Optics and Photonics for Information Processing IX},
doi = {10.1117/12.2186695},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Echeagaray-Patr{\'{o}}n, Kober - 2015 - 3D face recognition based on matching of facial surfaces(2).pdf:pdf},
keywords = {3d face recognition,3d facial shape analysis,conformal mapping,revisao{\_}V1,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,tutui1},
number = {September 2015},
pages = {95980V},
title = {{3D face recognition based on matching of facial surfaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951325808{\&}doi=10.1117{\%}2F12.2186695{\&}partnerID=40{\&}md5=cb5a757e08c6a66683fc0706f09faf95},
volume = {9598},
year = {2015}
}
@inproceedings{ISI:000380516600072,
abstract = {The classical curvatures of smooth surfaces (Gaussian, mean and
principal curvatures) have been widely used in 3D face recognition (FR).
However, facial surfaces resulting from 3D sensors are discrete meshes.
In this paper, we present a general framework and define three principal
curvatures on discrete surfaces for the purpose of 3D FR. These
principal curvatures are derived from the construction of asymptotic
cones associated to any Borel subset of the discrete surface. They
describe the local geometry of the underlying mesh. First two of them
correspond to the classical principal curvatures in the smooth case. We
isolate the third principal curvature that carries out meaningful
geometric shape information. The three principal curvatures in different
Borel subsets scales give multi-scale local facial surface descriptors.
We combine the proposed principal curvatures with the LNP-based facial
descriptor and SRC for recognition. The identification and verification
experiments demonstrate the practicability and accuracy of the third
principal curvature and the fusion of multi-scale Borel subset
descriptors on 3D face from FRGC v2.0.},
author = {Tang, Yinhang and Sun, Xiang and Huang, Di and Morvan, Jean Marie and Wang, Yunhong and Chen, Liming},
booktitle = {Proceedings of 2015 International Conference on Biometrics, ICB 2015},
doi = {10.1109/ICB.2015.7139111},
file = {:home/tutu/artigos{\_}revisao/07139111.pdf:pdf},
isbn = {9781479978243},
issn = {2376-4201},
keywords = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {may},
organization = {SIEW-SNGIEM AWARD; Kasetsart Univ; CHANWANICH; ST Elect; SAFRAN Morpho},
pages = {466--472},
publisher = {IEEE},
series = {International Conference on Biometrics},
title = {{3D face recognition with asymptotic cones based principal curvatures}},
url = {http://ieeexplore.ieee.org/document/7139111/},
year = {2015}
}
@incollection{Ming:2015:RLS:2940229.2940265,
abstract = {In this paper, a robust 3D local SIFT feature is proposed for 3D face recognition. For preprocessing the original 3D face data, facial regional segmentation is first employed by fusing curvature characteristics and shape band mechanism. Then, we design a new local descriptor for the extracted regions, called 3D local Scale-Invariant Feature Transform (3D LSIFT). The key point detection based on 3D LSIFT can effectively reflect the geometric characteristic of 3D facial surface by encoding the gray and depth information captured by 3D face data. Then, 3D LSIFT descriptor extends to describe the discrimination on 3D faces. Experimental results based on the common international 3D face databases demonstrate the higher-qualified performance of our proposed algorithm with effectiveness, robustness, and universality.},
address = {New York, NY, USA},
annote = {From Duplicate 1 (Robust 3D local SIFT features for 3D face recognition - Ming, Yue; Jin, Yi)

From Duplicate 2 (Robust 3D Local SIFT Features for 3D Face Recognition - Ming, Yue; Jin, Yi)

26/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)

From Duplicate 2 (Robust 3D Local SIFT Features for 3D Face Recognition - Ming, Yue; Jin, Yi)

26/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
26/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Ming, Yue and Jin, Yi},
booktitle = {Proceedings of the 8th International Conference on Intelligent Robotics and Applications - Volume 9246},
doi = {10.1007/978-3-319-22873-0_31},
file = {:home/tutu/artigos{\_}revisao/a7043849b25b35f527aaefae13f9ee2d-ming2015.pdf:pdf},
isbn = {978-3-319-22872-3},
issn = {16113349},
keywords = {3D Local Scale-Invariant Feature Transform,3D face recognition,3D local Scale-Invariant feature transform,Depth information,Facial region segmentation,acm,estela,etapa1,id278,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,estela,etapa1,id278,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {352--359},
publisher = {Springer-Verlag New York, Inc.},
series = {ICIRA 2015},
title = {{Robust 3D Local SIFT Features for 3D Face Recognition}},
url = {http://dx.doi.org/10.1007/978-3-319-22873-0{\_}31 http://link.springer.com/10.1007/978-3-319-22873-0{\_}31},
volume = {9246},
year = {2015}
}
@inproceedings{8578301,
abstract = {Deep networks trained on millions of facial images are believed to be closely approaching human-level performance in face recognition. However, open world face recognition still remains a challenge. Although, 3D face recognition has an inherent edge over its 2D counterpart, it has not benefited from the recent developments in deep learning due to the unavailability of large training as well as large test datasets. Recognition accuracies have already saturated on existing 3D face datasets due to their small gallery sizes. Unlike 2D photographs, 3D facial scans cannot be sourced from the web causing a bottleneck in the development of deep 3D face recognition networks and datasets. In this backdrop, we propose a method for generating a large corpus of labeled 3D face identities and their multiple instances for training and a protocol for merging the most challenging existing 3D datasets for testing. We also propose the first deep CNN model designed specifically for 3D face recognition and trained on 3.1 Million 3D facial scans of 100K identities. Our test dataset comprises 1,853 identities with a single 3D scan in the gallery and another 31K scans as probes, which is several orders of magnitude larger than existing ones. Without fine tuning on this dataset, our network already outperforms state of the art face recognition by over 10{\%}. We fine tune our network on the gallery set to perform end-to-end large scale 3D face recognition which further improves accuracy. Finally, we show the efficacy of our method for the open world face recognition problem.},
author = {{Zulqarnain Gilani}, Syed and Mian, Ajmal},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00203},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zulqarnain Gilani, Mian - 2018 - Learning from Millions of 3D Scans for Large-Scale 3D Face Recognition.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
keywords = {convolutional neural nets,face recognition,learnin,revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
pages = {1896--1905},
title = {{Learning from Millions of 3D Scans for Large-Scale 3D Face Recognition}},
year = {2018}
}
@inproceedings{ISI:000402657200006,
abstract = {{\textcopyright} Springer International Publishing AG 2017. Using of 3D images for the identification was in a field of the interest of many researchers which developed a few methods offering good results. However, there are few techniques exploiting the 3D asymmetry amongst these methods. We propose fast algorithm for rough extraction face asymmetry that is used to 3D face recognition with hidden Markov models. This paper presents conception of fast method for determine 3D face asymmetry. The research results indicate that face recognition with 3D face asymmetry may be used in biometrics systems.},
annote = {From Duplicate 1 (Face recognition with 3D face asymmetry - Bobulski, Janusz)

8th International Conference on Image Processing and Communications
(IP{\&}C), UTP Univ Technol {\&} Sci, Inst Telecommunicat {\&} Comp Sci,
Bydgoszcz, POLAND, SEP 07-09, 2016

From Duplicate 2 (Face recognition with 3D face asymmetry - Bobulski, Janusz)

From Duplicate 1 (Face Recognition with 3D Face Asymmetry - Bobulski, Janusz)

8th International Conference on Image Processing and Communications
(IP{\&}C), UTP Univ Technol {\&} Sci, Inst Telecommunicat {\&} Comp Sci,
Bydgoszcz, POLAND, SEP 07-09, 2016},
author = {Bobulski, Janusz},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-319-47274-4_6},
editor = {Choras, RS},
file = {:home/tutu/artigos{\_}revisao/99346aa27359933f6bf1fc817356e3ed-bobulski2016.pdf:pdf},
isbn = {9783319472737},
issn = {21945357},
keywords = {Face asymmetry,Face recognition,Hidden Markov models,Identity verification,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
organization = {UTP Univ Technol {\&} Sci},
pages = {53--60},
series = {Advances in Intelligent Systems and Computing},
title = {{Face recognition with 3D face asymmetry}},
volume = {525},
year = {2017}
}
@article{Ratyal2015241,
abstract = {In this paper we present a novel pose and expression invariant approach for 3D face registration based on intrinsic coordinate system characterized by nose tip, horizontal nose plane and vertical symmetry plane of the face. It is observed that distance of nose tip from 3D scanner is reduced after pose correction which is presented as a quantifying heuristic for proposed registration scheme. In addition, motivated by the fact that a single classifier cannot be generally efficient against all face regions, a two tier ensemble classifier based 3D face recognition approach is presented which employs Principal Component Analysis (PCA) for feature extraction and Mahalanobis Cosine (MahCos) matching score for classification of facial regions with weighted Borda Count (WBC) based combination and a re-ranking stage. The performance of proposed approach is corroborated by extensive experiments performed on two databases: GavabDB and FRGC v2.0, confirming effectiveness of fusion strategies to improve performance. {\^{A}}{\textcopyright} 2015 Elsevier Ltd. All rights reserved.},
annote = {cited By 5
24/04/2018 Em processo de sele{\c{c}}{\~{a}}o (Etapa 1)
24/04/2018 Exclu{\'{i}}do (Etapa 1)},
author = {Ratyal, N I and Taj, I A and Bajwa, U I and Sajid, M},
doi = {10.1016/j.compeleceng.2015.06.007},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratyal et al. - 2015 - 3D face recognition based on pose and expression invariant alignment.pdf:pdf},
journal = {Computers and Electrical Engineering},
keywords = {acm,artur,etapa1,id183,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,robson,scopus,tutui1},
mendeley-tags = {acm,artur,etapa1,id183,isi,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,robson,scopus,tutui1},
pages = {241--255},
title = {{3D face recognition based on pose and expression invariant alignment}},
volume = {46},
year = {2015}
}
@inproceedings{7988861,
abstract = {This paper presents the integration of a multiple people detection and identification system with a dynamic simultaneous localization and mapping system for an autonomous robotic platform. This integration allows the exploration and navigation of the robot considering people identification. The robotic platform consists of a Pioneer 3DX robot equipped with an RGBD camera, a Sick Lms200 sensor laser and a computer using the robot operating system (ROS). The idea is to integrate the people detection and identification system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. The people detection and identification system is performed in two steps. The first one is for detecting multiple people on scene and the other one is for an individual person identification. Both steps are implemented as ROS nodes that works integrated with the SLAM ROS node. The multiple people detection's node uses a manual feature extraction technique based on HOG (Histogram of Oriented Gradients) detectors, implemented using the PCL library (Point Cloud Library) in C ++. The person's identification node is based on a Deep Convolutional Neural Network (CNN) that are implemented using the MatLab MatConvNet library. This step receives the detected people centroid from the previous step and performs the classification of a specific person. After that, the desired person centroid is send to the SLAM node, that consider it during the mapping process. Tests were made objecting the evaluation of accurateness in the people's detection and identification process. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.},
author = {Angonese, Alberto Torres and {Ferreira Rosa}, Paulo Fernando},
booktitle = {ICMT 2017 - 6th International Conference on Military Technologies},
doi = {10.1109/MILTECHS.2017.7988861},
file = {:home/tutu/artigos{\_}revisao/07988861.pdf:pdf},
isbn = {9781538619889},
keywords = {CNN,Deep Learning,HOG,People Detection,Simultaneous Localization and Mapping (SLAM),revisao{\_}V1,revisao{\_}etapa1,revisao{\_}ieeexplore,revisao{\_}scopus,robot operating system ROS,tutux9},
mendeley-tags = {revisao{\_}V1,revisao{\_}etapa1,revisao{\_}ieeexplore,revisao{\_}scopus,tutux9},
pages = {779--786},
title = {{Multiple people detection and identification system integrated with a dynamic simultaneous localization and mapping system for an autonomous mobile robotic platform}},
year = {2017}
}
@article{Lei:2016:TWC:2875518.2875660,
abstract = {3D face recognition with the availability of only partial data (missing parts, occlusions and data corruptions) and single training sample is a highly challenging task. This paper presents an efficient 3D face recognition approach to address this challenge. We represent a facial scan with a set of local Keypoint-based Multiple Triangle Statistics (KMTS), which is robust to partial facial data, large facial expressions and pose variations. To address the single sample problem, we then propose a Two-Phase Weighted Collaborative Representation Classification (TPWCRC) framework. A class-based probability estimation is first calculated based on the extracted local descriptors as a prior knowledge. The resulting class-based probability estimation is then incorporated into the proposed classification framework as a locality constraint to further enhance its discriminating power. Experimental results on six challenging 3D facial datasets show that the proposed KMTS-TPWCRC framework achieves promising results for human face recognition with missing parts, occlusions, data corruptions, expressions and pose variations.},
address = {New York, NY, USA},
annote = {21/04/2018 Em processo de sele{\c{c}}{\~{a}}o (etapa 1)
21/04/2018 Exclu{\'{i}}do (etapa 1)},
author = {Lei, Yinjie and Guo, Yulan and Hayat, Munawar and Bennamoun, Mohammed and Zhou, Xinzhi},
doi = {10.1016/j.patcog.2015.09.035},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lei et al. - 2016 - A Two-Phase Weighted Collaborative Representation for 3D partial face recognition with single sample.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D face recognition,3D representation,Partial facial data,Single sample problem,Sparse representation,acm,etapa1,gil,id111,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {acm,etapa1,gil,id111,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
month = {apr},
number = {C},
pages = {218--237},
publisher = {Elsevier Science Inc.},
title = {{A Two-Phase Weighted Collaborative Representation for 3D partial face recognition with single sample}},
url = {http://dx.doi.org/10.1016/j.patcog.2015.09.035 http://linkinghub.elsevier.com/retrieve/pii/S0031320315003660},
volume = {52},
year = {2016}
}
@article{ISI:000446151100037,
abstract = {Most human expression variations cause a non-rigid deformation of face scans, which is a challenge today. In this article, we present a novel framework for 3D face recognition that uses a geometry and local shape descriptor in a matching process to overcome the distortions caused by expressions in faces. This algorithm consists of four major components. First, the 3D face model is presented at different scales. Second, isometric-invariant features on each scale are extracted. Third, the geometric information is obtained on the 3D surface in terms of radial and level facial curves. Fourth, the feature vectors on each scale are concatenated with their corresponding geometric information. We conducted a number of experiments using two well-known and challenging datasets, namely, the GavabDB and Bosphorus datasets, and superior recognition performance has been achieved. The new system displays an overall rank-1 identification rate of 98.9{\%} for all faces with neutral and non-neutral expressions on the GavabDB database. (C) 2017 Elsevier Ltd. All rights reserved.},
author = {Abbad, Abdelghafour and Abbad, Khalid and Tairi, Hamid},
doi = {10.1016/j.compeleceng.2017.08.017},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbad, Abbad, Tairi - 2018 - 3D face recognition Multi-scale strategy based on geometric and local descriptors.pdf:pdf},
issn = {0045-7906},
journal = {COMPUTERS {\&} ELECTRICAL ENGINEERING},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {525--537},
title = {{3D face recognition: Multi-scale strategy based on geometric and local descriptors}},
volume = {70},
year = {2018}
}
@article{ISI:000412265100009,
abstract = {Pose variations are still challenging problems in 3D face recognition because large pose variations will cause self-occlusion and result in missing data. In this paper, a new method for pose-invariant 3D face recognition is proposed to handle significant pose variations. For pose estimation and registration, a coarse-to-fine strategy is proposed to detect landmarks under large yaw variations. At the coarse search step, candidate landmarks are detected using HK curvature analysis and subdivided according to a facial geometrical structure-based classification strategy. At the fine search step, candidate landmarks are identified and labeled by comparing with a Facial Landmark Model. By using the half face matching, we perform the matching step with respect to frontal scans and side scans. Experiments carried out on the Bosphorus and UND/FRGC v2.0 databases show that our method has high accuracy and robustness to pose variations. (C) 2017 Elsevier B.V. All rights reserved.},
author = {Liang, Yan and Zhang, Yun and Zeng, Xian-Xian},
doi = {10.1016/j.image.2017.05.004},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, Zhang, Zeng - 2017 - Pose-invariant 3D face recognition using half face.pdf:pdf},
issn = {0923-5965},
journal = {SIGNAL PROCESSING-IMAGE COMMUNICATION},
keywords = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
pages = {84--90},
title = {{Pose-invariant 3D face recognition using half face}},
volume = {57},
year = {2017}
}
@article{ISI:000368591300013,
abstract = {In last years, the emergence of 3D shape in face recognition is due to its robustness to pose and illumination changes. These attractive benefits are not all the challenges to achieve satisfactory recognition rate. Other challenges such as facial expressions and computing time of matching algorithms remain to be explored. In this context, we propose our 3D face recognition approach using 3D wavelet networks. Our approach contains two stages: learning stage and recognition stage. For the training we propose a novel algorithm based on 3D fast wavelet transform. From 3D coordinates of the face (x,y,z), we proceed to voxelization to get a 3D volume which will be decomposed by 3D fast wavelet transform and modeled after that with a wavelet network, then their associated weights are considered as vector features to represent each training face. For the recognition stage, an unknown identity face is projected on all the training WN to obtain a new vector features after every projection. A similarity score is computed between the old and the obtained vector features. To show the efficiency of our approach, experimental results were performed on all the FRGC v.2 benchmark.},
annote = {From Duplicate 1 (3D fast wavelet network model-assisted 3D face recognition - Said, Salwa; Jemai, Olfa; Zaied, Mourad; Ben Amar, Chokri)

- galera curte usar gallery/probe ao inves de train/test;
- identification me parece melhor que recognition (fica mais atrelado a natureza biometrica do problema);
- nao necessita de registro;
-

From Duplicate 2 (3D fast wavelet network model-assisted 3D face recognition - Said, Salwa; Jemai, Olfa; Zaied, Mourad; Ben Amar, Chokri)

From Duplicate 1 (3D fast wavelet network model-assisted 3D face recognition - Said, Salwa; Jemai, Olfa; Zaied, Mourad; Ben Amar, Chokri)

8th International Conference on Machine Vision (ICMV), Barcelona, SPAIN,
NOV 19-21, 2015

From Duplicate 2 (3D fast wavelet network model-assisted 3D face recognition - Said, Salwa; Jemai, Olfa; Zaied, Mourad; Ben Amar, Chokri)

From Duplicate 1 (3D Fast Wavelet Network Model-Assisted 3D Face Recognition - Said, Salwa; Jemai, Olfa; Zaied, Mourad; Ben Amar, Chokri)

8th International Conference on Machine Vision (ICMV), Barcelona, SPAIN,
NOV 19-21, 2015},
author = {Said, Salwa and Jemai, Olfa and Zaied, Mourad and {Ben Amar}, Chokri},
doi = {10.1117/12.2228368},
editor = {{Verikas, A and Radeva, P and Nikolaev}, D},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Said et al. - 2015 - 3D fast wavelet network model-assisted 3D face recognition.pdf:pdf},
isbn = {978-1-5106-0116-1},
issn = {0277-786X},
journal = {Eighth International Conference on Machine Vision (ICMV 2015)},
keywords = {3d face recognition,fast wavelet transform,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1,wavelet network},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutui1},
number = {December 2015},
pages = {98750E},
series = {Proceedings of SPIE},
title = {{3D fast wavelet network model-assisted 3D face recognition}},
volume = {9875},
year = {2015}
}
@inproceedings{8389776,
abstract = {Face Recognition is one of the biometric technique to vestige the given faces. We present a 3D face recognition method using Hadoop to recognize 3D faces under varying expressions, lighting and different poses to overcome the challenges of the 2D face recognition. In this paper, a threshold facial region of an image is detected and preprocessing is done based through the image excellence. If the selected face is frontal face with good lighting, extract the prerequisite features and do the necessary comparison steps to recognize the faces. In case, if the selected face is in bad lighting, then perform histogram equalization and normalization to increase the contrast. Different Poses and expressions are the very challenging zones which require surplus pre-processing to improve the performance of the face recognition system. Hence an enhanced normalization method called 3D Morphable Model are used as a pre- processing technique to create a frontal view from a non-frontal view and also merge images with different views in to a single frontal view. Next to diminish the number of features used for recognition process; we emulate the linear discriminant analysis method for further classification. Eventually, we used an open-source Hadoop Image Processing Interface (HIPI) to act as an interface for MapReduce technology for recognition. {\textcopyright} 2017 IEEE.},
annote = {From Duplicate 1 (3D face recognition using Hadoop - Geetha, G.; Safa, M.; Fancy, C.; Chittal, K.)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 2 (3D face recognition using Hadoop - Geetha, G.; Safa, M.; Fancy, C.; Chittal, K.)

From Duplicate 2 (3D face recognition using Hadoop - Geetha, G.; Safa, M.; Fancy, C.; Chittal, K.)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 2 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 2 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0

From Duplicate 3 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

From Duplicate 1 (3D face recognition using Hadoop - Geetha, G; Safa, M; Fancy, C; Chittal, K)

cited By 0},
author = {Geetha, G. and Safa, M. and Fancy, C. and Chittal, K.},
booktitle = {2017 International Conference on Energy, Communication, Data Analytics and Soft Computing, ICECDS 2017},
doi = {10.1109/ICECDS.2017.8389776},
file = {:home/tutu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geetha et al. - 2017 - 3D face recognition using Hadoop.pdf:pdf},
isbn = {9781538618868},
keywords = {Hadoop,Image Processing,Linear Discriminant analysis,Map Reduce,biometrics (access control),face recognition,featu,revisao{\_}V1,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
mendeley-tags = {revisao{\_}V1,revisao{\_}V2,revisao{\_}ieeexplore,revisao{\_}scopus,tutui1},
month = {aug},
pages = {1882--1885},
publisher = {IEEE},
title = {{3D face recognition using Hadoop}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050073609{\&}doi=10.1109{\%}2FICECDS.2017.8389776{\&}partnerID=40{\&}md5=426f7e7f8b23f4019df744e279422d63 https://ieeexplore.ieee.org/document/8389776/},
year = {2017}
}
@inproceedings{ISI:000446968900004,
abstract = {With the growth of face recognition, the spoofing mask attacks attract more attention in biometrics research area. In recent years, the countermeasures based on the texture and depth image against spoofing mask attacks have been reported, but the research based on 3D meshed sample has not been studied yet. In this paper, we propose to apply 3D shape analysis based on principal curvature measures to describe the meshed facial surface. Meanwhile, a verification protocol based on this feature descriptor is designed to verify person identity and to evaluate the anti-spoofing performance on Morpho database. Furthermore, for simulating a real-life testing scenario, FRGCv2 database is enrolled as an extension of face scans to augment the ratio of genuine face samples to fraud mask samples. The experimental results show that our system can guarantee a high verification rate for genuine faces and the satisfactory anti-spoofing performance against spoofing mask attacks in parallel.},
annote = {From Duplicate 1 (Shape analysis based anti-spoofing 3D face recognition with mask attacks - Tang, Yinhang; Chen, Liming)

6th International Workshop on Representations, Analysis and Recognition
of Shape and Motion from Imaging Data (RFMI), Sidi Bou Said, TUNISIA,
OCT 27-29, 2016

From Duplicate 2 (Shape Analysis Based Anti-spoofing 3D Face Recognition with Mask Attacks - Tang, Yinhang; Chen, Liming; B, Yinhang Tang; Chen, Liming)

From Duplicate 2 (Shape Analysis Based Anti-spoofing 3D Face Recognition with Mask Attacks - Tang, Yinhang; Chen, Liming)

6th International Workshop on Representations, Analysis and Recognition
of Shape and Motion from Imaging Data (RFMI), Sidi Bou Said, TUNISIA,
OCT 27-29, 2016},
author = {Tang, Yinhang and Chen, Liming and B, Yinhang Tang and Chen, Liming},
booktitle = {Communications in Computer and Information Science},
doi = {10.1007/978-3-319-60654-5_4},
editor = {{BenAmor, B and Chaieb, F and Ghorbel}, F},
file = {:home/tutu/artigos{\_}revisao/0ffc4a681b88886e4d0518882f592e51-tang2017.pdf:pdf},
isbn = {9783319606538},
issn = {18650929},
keywords = {,revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutux11},
mendeley-tags = {revisao{\_}V1,revisao{\_}scopus,revisao{\_}webofscience,tutux11},
pages = {41--55},
series = {Communications in Computer and Information Science},
title = {{Shape analysis based anti-spoofing 3D face recognition with mask attacks}},
volume = {684},
year = {2017}
}
